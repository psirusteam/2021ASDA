```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, 
                      message = FALSE,
                      cache = TRUE)
```

## Modelos de regresi√≥n en encuestas de hogares

La regresi√≥n estad√≠stica constituye una t√©cnica fundamental para examinar los v√≠nculos entre variables en el marco de los datos muestrales obtenidos mediante encuestas. A trav√©s de este procedimiento, es posible determinar la forma en que una o varias variables de respuesta (dependientes) se relacionan con una o varias variables explicativas (independientes). Tal como exponen Nolan y Speed (2000) y Freedman (2005), la validez de los resultados depende de una adecuada formulaci√≥n del modelo.

Un ejemplo ilustrativo ser√≠a la estimaci√≥n del ingreso de los hogares (variable dependiente) en funci√≥n del nivel educativo alcanzado y de la situaci√≥n laboral de sus miembros (variables independientes), empleando datos provenientes de encuestas de hogares. Estos an√°lisis permiten identificar patrones, cuantificar efectos y generar evidencia √∫til para la formulaci√≥n de pol√≠ticas p√∫blicas.

No obstante, dado que estas encuestas suelen estar sustentadas en **dise√±os muestrales complejos**, los enfoques tradicionales de regresi√≥n resultan insuficientes. Ignorar los pesos muestrales, la estratificaci√≥n o la conglomeraci√≥n puede derivar en sesgos en los coeficientes estimados y, sobre todo, en una subestimaci√≥n de sus varianzas, lo cual compromete la validez de las inferencias. Por esta raz√≥n, los modelos de regresi√≥n aplicados a encuestas deben ser modificados y ajustados para garantizar resultados representativos y robustos.

En este sentido, el an√°lisis de datos provenientes de encuestas exige una atenci√≥n detallada al dise√±o de muestreo. La incorporaci√≥n de los **pesos de la encuesta** y de los ajustes correspondientes a la estratificaci√≥n y a la conglomeraci√≥n permite obtener inferencias v√°lidas y precisas. Adem√°s, en algunos casos se han planteado alternativas simplificadas, como el uso de pesos normalizados o enfoques de ponderaci√≥n aproximada, que buscan balancear la complejidad metodol√≥gica con la factibilidad pr√°ctica del an√°lisis.

### Antecedentes hist√≥ricos y desarrollos metodol√≥gicos

El estudio de la regresi√≥n bajo dise√±os de muestreo complejos tiene una trayectoria bien documentada. De manera emp√≠rica, **Kish y Frankel (1974)** fueron de los primeros en discutir el impacto de estos dise√±os en las inferencias derivadas de modelos de regresi√≥n. Posteriormente, **Fuller (1975)** desarroll√≥ un estimador de varianza apoyado en t√©cnicas de linealizaci√≥n para modelos de regresi√≥n lineal m√∫ltiple con ponderaci√≥n desigual, e introdujo m√©todos espec√≠ficos para dise√±os estratificados y de dos etapas.

M√°s adelante, **Sha et al. (1977)** abordaron el problema de las violaciones a los supuestos cl√°sicos de los modelos de regresi√≥n al trabajar con datos de encuestas, proponiendo alternativas de inferencia robusta para los par√°metros. En paralelo, **Binder (1983)** se enfoc√≥ en las distribuciones muestrales de los estimadores de regresi√≥n en poblaciones finitas, definiendo procedimientos para estimar varianzas bajo esquemas complejos.

En los a√±os siguientes, **Skinner et al. (1989)** ampliaron estos aportes al trabajar con estimadores de varianza para los coeficientes de regresi√≥n que contemplaban la estratificaci√≥n y la conglomeraci√≥n, recomendando expl√≠citamente el uso de m√©todos de linealizaci√≥n o t√©cnicas alternativas para la estimaci√≥n de la varianza. Avanzando en la l√≠nea de tiempo, **Fuller (2002)** realiz√≥ un compendio de los m√©todos de estimaci√≥n aplicables a modelos de regresi√≥n en encuestas complejas, mientras que **Pfeffermann (2011)** discuti√≥ enfoques m√°s recientes, como los m√©todos de ponderaci√≥n ‚Äúq-weighted‚Äù, mostrando evidencia emp√≠rica de su utilidad.

### Relevancia pr√°ctica

En la actualidad, los modelos de regresi√≥n bajo dise√±os de muestreo complejos representan una herramienta esencial para el an√°lisis de encuestas de hogares. Estos modelos permiten ir m√°s all√° de las estad√≠sticas descriptivas y aproximarse a explicaciones causales o predictivas, siempre que se reconozcan y se ajusten las particularidades del dise√±o muestral. Su correcta aplicaci√≥n abre la posibilidad de analizar c√≥mo las caracter√≠sticas sociodemogr√°ficas y econ√≥micas se asocian con distintos resultados de inter√©s, aportando evidencia clave para la formulaci√≥n de pol√≠ticas p√∫blicas.

En las siguientes secciones se mostrar√° c√≥mo implementar estos modelos en `R`, utilizando la librer√≠a `survey`. Se abordar√° la especificaci√≥n del dise√±o muestral, la estimaci√≥n de modelos lineales y log√≠sticos, as√≠ como la obtenci√≥n de errores est√°ndar y pruebas de hip√≥tesis ajustadas al dise√±o. De este modo, se integrar√°n los fundamentos te√≥ricos con ejemplos pr√°cticos en un flujo de trabajo reproducible.

Un primer paso consiste en comprender la estructura b√°sica de los modelos de regresi√≥n. El modelo de regresi√≥n lineal simple se define como

$$
y = \beta_{0} + \beta_{1}x + \varepsilon,
$$

donde $y$ es la variable dependiente, $x$ la variable independiente, $\beta_{0}$ y $\beta_{1}$ los par√°metros del modelo, y $\varepsilon$ el error aleatorio, definido como la diferencia entre el valor observado y el valor ajustado del modelo:

$$
\varepsilon = y - \hat{y} = y - (\beta_{0} + \beta_{1}x).
$$

Generalizando este planteamiento, los modelos de regresi√≥n lineal m√∫ltiple incorporan varias covariables:

$$
y = \beta_{0} + \beta_{1}x_{1} + \cdots + \beta_{p}x_{p} + \varepsilon,
$$

lo cual puede expresarse en notaci√≥n matricial como

$$
y_{i} = x_{i}\boldsymbol{\beta} + \varepsilon_{i}, \quad i=1,\ldots,n,
$$

donde $x_{i} = [1, x_{1i}, \ldots, x_{pi}]$ corresponde al vector de covariables del individuo $i$, y $\boldsymbol{\beta}^{T} = [\beta_{0}, \beta_{1}, \ldots, \beta_{p}]$ es el vector de par√°metros.

En este contexto, el valor esperado de la variable respuesta condicionado a las covariables puede escribirse como:

$$
E(y \mid x) = \hat{\beta}_{0} + \hat{\beta}_{1}x_{1} + \cdots + \hat{\beta}_{p}x_{p}.
$$

Para que estos modelos sean v√°lidos, es necesario que se cumplan ciertos **supuestos cl√°sicos**, recogidos en la literatura (Heeringa, West y Berglund, 2017), entre los que destacan:

* **Esperanza nula de los residuos**: $E(\varepsilon_{i} \mid x_{i}) = 0$.
* **Homogeneidad de varianza**: $Var(\varepsilon_{i} \mid x_{i}) = \sigma^2$.
* **Normalidad de los errores**: $\varepsilon_{i} \mid x_{i} \sim N(0,\sigma^2)$.
* **Independencia de los residuos**: $cov(\varepsilon_{i},\varepsilon_{j}\mid x_{i},x_{j})=0$.

Estos supuestos permiten garantizar que los estimadores obtenidos tengan buenas propiedades estad√≠sticas (insesgamiento, eficiencia y consistencia). Sin embargo, al trabajar con encuestas bajo **dise√±os complejos**, estas condiciones rara vez se cumplen de manera estricta, por lo que se requieren adaptaciones que ser√°n abordadas en las pr√≥ximas secciones.


Una vez definido el modelo de regresi√≥n lineal y sus supuestos, se puede deducir los siguiente:


$$
\hat{y}  =  E\left(y\mid x\right)
 =  E\left(\boldsymbol{x}\boldsymbol{\beta}\right)+E\left(\varepsilon\right)
=  \boldsymbol{x}\boldsymbol{\beta}+0
  =  \beta_{0}+\beta_{1}x_{1}+\cdots+\beta_{p}x_{p}
$$

y Adicionalmente,

$$
var\left(y_{i}\mid x_{i}\right)  =  \sigma_{y,x}^{2}
$$

$$
cov\left(y_{i},y_{j}\mid x_{i},x_{j}\right)  = 0
$$

$$
y_{i}  \sim  N\left(x_{i}\boldsymbol{\beta},\sigma_{y,x}^{2}\right)
$$


### ¬øAplicar o no aplicar ponderaciones?


Heeringa, West y Berglund (2017) examinan el desaf√≠o de determinar c√≥mo utilizar adecuadamente los pesos en modelos de regresi√≥n y si conviene emplear factores de expansi√≥n al estimar coeficientes de regresi√≥n en encuestas con dise√±os complejos. En este marco, se distinguen dos enfoques principales para incorporar los pesos en los modelos:

* **Enfoque orientado al dise√±o**: busca realizar inferencias v√°lidas sobre la poblaci√≥n total. Los pesos de la encuesta resultan indispensables para obtener estimaciones insesgadas de los coeficientes, ya que corrigen las probabilidades desiguales de selecci√≥n derivadas del dise√±o muestral. No obstante, este m√©todo no protege frente a la mala especificaci√≥n del modelo: si la relaci√≥n planteada no refleja adecuadamente lo que ocurre en la poblaci√≥n, los coeficientes estimados, aunque insesgados en el marco del dise√±o, pueden carecer de utilidad sustantiva.

* **Enfoque orientado al modelo**: sostiene que los pesos no son necesarios siempre que el modelo est√© correctamente formulado y el muestreo sea no informativo, es decir, que el modelo v√°lido para la muestra coincida con el de la poblaci√≥n. En este escenario, se asume que las relaciones entre variables est√°n bien descritas por el modelo independientemente del dise√±o muestral, y que la utilizaci√≥n de ponderaciones podr√≠a incrementar innecesariamente la variabilidad de las estimaciones, elevando los errores est√°ndar.



La decisi√≥n entre utilizar o no ponderaciones en los modelos de regresi√≥n depende tanto del contexto como de la sensibilidad de los resultados a su inclusi√≥n. Autores como **Skinner, Holt y Smith (1989)** y **Pfeffermann (2011)** han debatido ampliamente sobre la pertinencia de incorporar los pesos muestrales en la estimaci√≥n de los par√°metros de regresi√≥n y en sus errores est√°ndar.

Una recomendaci√≥n metodol√≥gica ampliamente aceptada es estimar los modelos con y sin ponderaciones y comparar los resultados. Si al incluir los pesos se observan variaciones significativas en los coeficientes o en las conclusiones, ello indica que el muestreo fue informativo o que el modelo presenta deficiencias de especificaci√≥n, por lo que conviene utilizar estimaciones ponderadas. En cambio, si los pesos solo aumentan los errores est√°ndar sin modificar sustancialmente los coeficientes, se puede asumir que el modelo est√° bien planteado y que no es indispensable ponderar.

En t√©rminos pr√°cticos, la decisi√≥n puede resumirse en dos escenarios:

* **Inferencia descriptiva**: es obligatorio aplicar ponderaciones, ya que el objetivo es reflejar con precisi√≥n la estructura de la poblaci√≥n.

* **Inferencia anal√≠tica**: es posible recurrir a modelos no ponderados o ajustados por pesos. En este caso, si la meta es analizar relaciones o verificar hip√≥tesis, la ponderaci√≥n no siempre es necesaria, especialmente cuando el modelo incluye variables del dise√±o muestral (estratos o conglomerados). Sin embargo, el uso de modelos sin ponderar debe justificarse de forma expl√≠cita, pues implica supuestos m√°s restrictivos que los modelos ponderados.


El uso de ponderaciones en encuestas permite asegurar que los modelos de regresi√≥n sean representativos de la poblaci√≥n, ya que corrigen posibles sesgos de sobre o subrepresentaci√≥n de determinados grupos y garantizan que la distribuci√≥n poblacional se refleje adecuadamente. Asimismo, las ponderaciones contribuyen a obtener estimaciones de varianza m√°s exactas, pues consideran la estratificaci√≥n, el agrupamiento y las probabilidades desiguales de selecci√≥n, lo cual genera errores est√°ndar, intervalos de confianza y pruebas estad√≠sticas m√°s confiables.

Dentro del enfoque basado en el dise√±o, los coeficientes de regresi√≥n se estiman a partir de ecuaciones poblacionales ajustadas con ponderaciones. Esto permite que los resultados ponderados se aproximen a valores insesgados comparables a los que se obtendr√≠an en un censo completo, incluso cuando el modelo estad√≠stico no est√© formulado de manera √≥ptima.


Un aspecto que no debe pasarse por alto es que el uso de ponderaciones puede aumentar la varianza de las estimaciones de los par√°metros, en especial cuando los pesos presentan gran dispersi√≥n. En situaciones donde existen valores extremos o muy variables, las estimaciones tienden a volverse inestables, ya que ciertas observaciones llegan a ejercer una influencia desproporcionada sobre el ajuste del modelo. En este sentido, cuando el prop√≥sito es explicativo o anal√≠tico (como en el an√°lisis de relaciones entre variables), los modelos sin ponderar pueden, en ocasiones, generar resultados m√°s consistentes y eficientes.



No obstante, cuando el modelo est√° mal especificado, la regresi√≥n sin ponderaciones puede producir estimaciones poco √∫tiles o carentes de validez. Por ello, resulta fundamental que los analistas seleccionen e incorporen las variables pertinentes para lograr una especificaci√≥n adecuada. Incluso en los casos en que el modelo est√© correctamente definido, es indispensable tener en cuenta la estratificaci√≥n y la conglomeraci√≥n del dise√±o muestral al calcular los errores est√°ndar bajo un enfoque no ponderado.

En definitiva, la decisi√≥n sobre **aplicar o no ponderaciones** no puede basarse √∫nicamente en una regla r√≠gida, sino que exige un an√°lisis cr√≠tico de los objetivos del estudio, del dise√±o de la encuesta y de la robustez de los modelos estimados. Asimismo, un an√°lisis diagn√≥stico riguroso resulta esencial para validar las inferencias y garantizar que los resultados reflejen de manera adecuada la realidad poblacional (v√©ase la Subsecci√≥n 9.6.4).


### Enfoques inferenciales para el an√°lisis de datos

En el an√°lisis de encuestas, uno de los principales retos consiste en manejar adecuadamente la variabilidad de los datos. Esta proviene de dos fuentes fundamentales: el dise√±o muestral, que determina c√≥mo se recolecta la informaci√≥n, y el modelo estad√≠stico, que define c√≥mo se interpreta dicha informaci√≥n para inferir propiedades de la poblaci√≥n. Ignorar cualquiera de estas dimensiones puede comprometer la validez de los resultados.

Por ello, se han desarrollado metodolog√≠as inferenciales avanzadas que permiten integrar ambas fuentes de incertidumbre en un mismo marco anal√≠tico. Estas t√©cnicas buscan reflejar tanto la estructura del dise√±o como los supuestos y limitaciones del modelo. Entre las aproximaciones m√°s relevantes se encuentran la seudo-verosimilitud (Molina & Skinner, 1992) y la inferencia combinada (Binder, 2011).


El m√©todo de seudo-verosimilitud extiende las t√©cnicas tradicionales de m√°xima verosimilitud para ajustarlas a las particularidades de los dise√±os muestrales complejos. En este enfoque, la distribuci√≥n de muestreo definida por el dise√±o tiene un rol central, mientras que la distribuci√≥n del modelo ocupa un lugar secundario. Si bien, en contextos de modelos bien especificados, los estimadores basados en seudo-verosimilitud tienden a ser insesgados o consistentes, lo crucial es que este procedimiento evita sesgos que se originar√≠an si se ignorara el dise√±o muestral. En t√©rminos pr√°cticos, la seudo-verosimilitud traduce el modelo tradicional en uno que respete la forma en que los datos fueron obtenidos, garantizando inferencias m√°s s√≥lidas.


En contraste, la inferencia combinada propone un marco unificado en el que se integran simult√°neamente la variabilidad del muestreo y la incertidumbre del modelo. Al considerar ambas fuentes, este enfoque ofrece una visi√≥n m√°s completa de la variabilidad y permite obtener estimaciones m√°s precisas y confiables. Su principal aporte radica en que evita sesgos que pueden aparecer cuando se analiza √∫nicamente desde la perspectiva del dise√±o o del modelo. De esta manera, la inferencia combinada resulta especialmente √∫til en aplicaciones donde se requiere un balance entre representatividad poblacional y solidez estad√≠stica de los modelos ajustados.

## Estimaci√≥n de los par√°metros en un modelo de regresi√≥n con muestras complejas

Una vez se establecen los supuestos del modelo y las caracter√≠sticas distribucionales de los errores, el paso siguiente es el proceso de estimaci√≥n de los par√°metros. A modo ilustrativo, si en lugar de observar una muestra de tama√±o $n$ de los $N$ elementos de la poblaci√≥n se hubiera realizado un censo completo, el par√°metro de regresi√≥n de poblaci√≥n finita $\beta_{1}$ podr√≠a calcularse como sigue **(T√©llez et al., 2016)**:

$$
\beta_{1}  =  \frac{\sum_{i=1}^{N}\left(X_{i}-\bar{X}\right)\left(Y_{i}-\bar{Y}\right)}{\sum_{i=1}^{N}\left(X_{i}-\bar{X}\right)^{2}}
$$

Sin embargo, cuando se desea estimar los par√°metros de un modelo de regresi√≥n lineal utilizando informaci√≥n proveniente de encuestas con dise√±os complejos, el enfoque est√°ndar cambia. La principal raz√≥n es que los datos no cumplen con los supuestos cl√°sicos de independencia e id√©ntica distribuci√≥n, ya que el dise√±o muestral introduce elementos como estratificaci√≥n, conglomerados o probabilidades de selecci√≥n desiguales. En consecuencia, los estimadores tradicionales (como los obtenidos por m√°xima verosimilitud o m√≠nimos cuadrados) pueden resultar sesgados y sus errores est√°ndar poco confiables.

En este contexto, **Wolter (2007)** propone el uso de m√©todos no param√©tricos robustos, como la linealizaci√≥n de Taylor o los procedimientos de replicaci√≥n (Jackknife, Bootstrap, Balanced Repeated Replication, entre otros), para estimar varianzas y obtener inferencias v√°lidas.

### Estimaci√≥n de par√°metros


En el caso de un modelo de regresi√≥n lineal simple, la estimaci√≥n de la pendiente $(\beta_1)$ bajo un esquema de encuesta compleja se realiza mediante un estimador ponderado, que puede expresarse de la siguiente forma:

$$
\hat{\beta_{1}}  =  
\frac{\sum_{h=1}^H \sum_{\alpha=1}^{a_h} \sum_{i=1}^{n_{h\alpha}} \omega_{h\alpha i}\,(y_{h\alpha i}-\bar{y}_{\omega})(x_{h\alpha i}-\bar{x}_{\omega})}
{\sum_{h=1}^H \sum_{\alpha=1}^{a_h} \sum_{i=1}^{n_{h\alpha}} \omega_{h\alpha i}\,(x_{h\alpha i}-\bar{x}_{\omega})^{2}}
= \frac{t_{xy}}{t_{x^{2}}}
$$

donde $\omega_{h\alpha i}$ representa los pesos de muestreo. La principal diferencia respecto al estimador cl√°sico es la incorporaci√≥n expl√≠cita de dichos pesos, que corrigen las probabilidades desiguales de selecci√≥n y aseguran la representatividad de las estimaciones.


La varianza del estimador $\hat{\beta_1}$ puede expresarse como:

$$
var\left(\hat{\beta_{1}}\right)  
=  \frac{var(t_{xy})+\hat{\beta}_{1}^{2}var(t_{x^{2}})-2\hat{\beta}_{1}cov(t_{xy},t_{x^{2}})}{(t_{x^{2}})^{2}}
$$

Este enfoque permite cuantificar la precisi√≥n del coeficiente considerando tanto los pesos como la estructura del dise√±o muestral.


En el caso de la regresi√≥n m√∫ltiple, el c√°lculo de la varianza de cada coeficiente se realiza considerando su interdependencia con los dem√°s. Esto se refleja en la construcci√≥n de una **matriz de varianza-covarianza**, que recoge tanto la variabilidad individual como las covarianzas entre todos los par√°metros. De acuerdo con **Kish y Frankel (1974)**, esta estimaci√≥n requiere utilizar totales ponderados de cuadrados y productos cruzados de todas las combinaciones entre la variable dependiente $y$ y el conjunto de predictores $x = {1, x_1, ‚Ä¶, x_p}$. En t√©rminos generales:

$$
var(\hat{\beta}) = \hat{\Sigma}(\hat{\beta}) =
\begin{bmatrix}
var(\hat{\beta}_{0}) & cov(\hat{\beta}_{0},\hat{\beta}_{1}) & \cdots & cov(\hat{\beta}_{0},\hat{\beta}_{p}) \\
cov(\hat{\beta}_{0},\hat{\beta}_{1}) & var(\hat{\beta}_{1}) & \cdots & cov(\hat{\beta}_{1},\hat{\beta}_{p}) \\
\vdots & \vdots & \ddots & \vdots \\
cov(\hat{\beta}_{0},\hat{\beta}_{p}) & cov(\hat{\beta}_{1},\hat{\beta}_{p}) & \cdots & var(\hat{\beta}_{p})
\end{bmatrix}
$$

Este marco permite evaluar la estabilidad y precisi√≥n de los par√°metros en modelos m√°s complejos, garantizando que las inferencias reflejen adecuadamente tanto el dise√±o de la encuesta como la relaci√≥n entre las variables.


Para ejemplificar los conceptos trabajados hasta este momento, se tomar√° la misma base que se ha venido trabajando durante todo el desarrollo de este libro. Se inicia con el cargue de las librer√≠as, la base de datos y la definici√≥n del dise√±o de muestreo:


```{r setup2, eval=TRUE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, error = FALSE)
options(digits = 4)
options(tinytex.verbose = TRUE)
library (survey)
library(srvyr)
library(convey)
library(TeachingSampling)
library(printr)
library(stargazer)
library(jtools)
library(broom)
```


Cargue de la base y definici√≥n del dise√±o muestral:

```{r, eval=TRUE}
data(BigCity, package = "TeachingSampling")
library(tidyverse)

encuesta <- readRDS("Data/encuesta.rds")
head(encuesta)

library(srvyr)
diseno <- encuesta %>%
  as_survey_design(
    strata = Stratum,
    ids = PSU,
    weights = wk,
    nest = T
  )
```

Para efectos de los ejemplos y como se ha hecho en anteriores ocasiones, se divide la muestra en sub-grupos de la encuesta como sigue:

```{r}
sub_Urbano <- diseno %>%  filter(Zone == "Urban")
sub_Rural  <- diseno %>%  filter(Zone == "Rural")
sub_Mujer  <- diseno %>%  filter(Sex == "Female")
sub_Hombre <- diseno %>%  filter(Sex == "Male")
```

En este cap√≠tulo se ajustar√°n los modelos de regresi√≥n usando la base de datos de ejemplo que se ha venido trabajando en cap√≠tulos anteriores. Puesto que, en modelos de regresi√≥n, se utiliza muy frecuente el recurso gr√°fico. A continuaci√≥n, se define un tema est√°ndar que la CEPAL tiene para generar sus gr√°ficos el cual se utilizar√° en este cap√≠tulo.


```{r, echo=FALSE, eval=TRUE}
theme_cepal <- function(...) theme_light(10) + 
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        legend.position="bottom", 
        legend.justification = "left", 
        legend.direction="horizontal",
        plot.title = element_text(size = 20, hjust = 0.5),
        ...) 
```

Para observar que existe una correlaci√≥n entre el ingreso y el gasto, las cuales son las variables que se utilizar√°n para el ajuste de los modelos, se construye un scatterplot usando la librer√≠a `ggplot`. Cabe resaltar que, como la base de datos encuesta, la cual se usa para ejemplificar es una muestra de la base `BigCity`, analizaremos de manera gr√°fica si poblacionalmente las dos variables mencionadas anteriormente tienen correlaci√≥n como se muestra a continuaci√≥n:

```{r, plot1, echo = TRUE, eval = TRUE}
library(ggplot2); library(ggpmisc)
plot_BigCity <- ggplot(data = BigCity,
                       aes(x = Expenditure, y = Income)) +
                       geom_point() + geom_smooth(method = "lm",
                       se = FALSE,
                       formula = y ~ x) + theme_cepal()

plot_BigCity + stat_poly_eq(formula = y~x, aes(label = paste(..eq.label..,
   ..rr.label.., sep = "~~~"),size = 3), parse = TRUE)

```

Si bien, existen unas observaciones por fuera de la nube de punto, el comportamiento general de la relaci√≥n ingresos vs gastos mantiene una tendencia lineal.

Una vez hecho el an√°lisis gr√°fico de las variables a utilizar en los modelos a trabajar, se realizar√° primero un ajuste del modelo con los datos poblacionales y con esto poder analizar qu√© tan bueno ser√°n los ajustes que se realizar√°n posteriormente. A continuaci√≥n, se muestra el ajuste del modelo con los datos poblacionales:

```{r, tab1, results='asis', echo=TRUE, eval = TRUE}
fit <- lm(Income ~ Expenditure, data = BigCity)
```

Ahora bien, para observar los par√°metros poblacionales del modelo se utilizar√° la funci√≥n `modelsummary` de la librer√≠a `modelsummary` de la siguiente manera:

```{r, results='asis', echo=FALSE, eval = TRUE}
library(modelsummary)

modelsummary(
  list(Pob = fit),
  output = "latex_tabular",   # üîë fuerza tabular en lugar de talltblr
  title = "Modelo BigCity",
  statistic = NULL,
  gof_omit = "BIC|Log|AIC|F"
)
```

De la anterior salida se puede observar que, el intercepto es igual a 123.337 y el par√°metro $\beta_{1}$ asociado al gasto es 1.229. La dem√°s informaci√≥n relacionada a esta salida se analizar√° m√°s adelante.

Una vez revisada la informaci√≥n poblacional, se utilizar√° la informaci√≥n obtenida de la muestra para estimar los par√°metros y con ello analizar qu√© tan buenas son las estimaciones. A continuaci√≥n, se presenta una sintaxis similar a la anterior que permite construir el scatterplot pero para los datos de la muestra.

```{r, plot2, echo = TRUE, eval = TRUE}
plot_sin <- ggplot(data = encuesta,
            aes(x = Expenditure, y = Income)) +
            geom_point() +
            geom_smooth(method = "lm",
            se = FALSE, formula = y ~ x) + theme_cepal()

plot_sin + stat_poly_eq(formula = y~x, aes(label = paste(..eq.label..,
     ..rr.label.., sep = "~~~"), size = 5), parse = TRUE)
```

Como se puede observar, los datos de la muestra tienen una tendencia lineal aunque un poco dispersa a medida que crecen los gastos en las familias.
 
 Una vez hecho los an√°lisis gr√°ficos se procede a ajustar los modelos de regresi√≥n lineal. A modo de comparar el efecto que tiene hacer un correcto uso de los factores de expansi√≥n del dise√±o, primero, se ajustar√° un modelo sin tener encuesta dichos factores como se muestra a continuaci√≥n:

```{r, results='asis', tab3, echo = TRUE, eval = TRUE}
fit_sinP <- lm(Income ~ Expenditure, data = encuesta)
stargazer(fit_sinP, type = "latex",
          title = "Modelo sin factores de expansion",
          label = "tab:sin_factores",
          header = FALSE)
```

Para el modelo ajustado sin factores de expansi√≥n, el $\hat{\beta}_{0}$ es  121.52 y el $\hat{\beta}_{1}$ asociado a la variable gastos es 1.22.

Ahora, haciendo un Scatterplot con los datos encuesta pero utilizando los factores de expansi√≥n del dise√±o se debe agregar ` mapping = aes(weight = wk)` en la funci√≥n `geom_smooth`como sigue:

```{r, plot3, echo = TRUE, eval = TRUE}
plot_Ponde <- ggplot(data = encuesta,
                     aes(x = Expenditure, y = Income)) +
                     geom_point(aes(size = wk)) +
                     geom_smooth(method = "lm", se = FALSE, formula = y ~ x,                      mapping = aes(weight = wk)) + theme_cepal()

plot_Ponde + stat_poly_eq(formula = y~x, aes(weight = wk,
label = paste(..eq.label..,..rr.label.., sep = "~~~")), parse = TRUE,size = 5)
```


En este sentido, para ajustar modelos teniendo en cuenta los factores de expansi√≥n existen 2 formas, la primera es usando la funci√≥n `lm` y la segunda es usando la funci√≥n `svyglm` de la librer√≠a `survey`. A continuaci√≥n. se ajusta el modelo usando la funci√≥n `lm`:

```{r ,results='asis', tab4, echo = TRUE, eval = TRUE}
fit_Ponde <- lm(Income ~ Expenditure, data = encuesta, weights = wk)
stargazer(fit_Ponde, header = FALSE,
          title = "Modelo encuesta ponderada",
          type = "latex")
```

Para el modelo ajustado con factores de expansi√≥n usando la funci√≥n `lm`, el $\hat{\beta}_{0}$ es  103.14 y el $\hat{\beta}_{1}$ asociado a la variable gastos es 1.26. Ahora, haciendo el mismo ajuste pero usando la funci√≥n `svyglm`:

```{r, tab6, echo = TRUE, eval = TRUE}
fit_svy <- svyglm(Income ~ Expenditure,
                  design = diseno, family=stats::gaussian())
fit_svy
```

Obteniendo estimaciones para el $\hat{\beta}_{0}$ es  103.14 y el $\hat{\beta}_{1}$ asociado a la variable gastos es 1.26. Siendo exactamente las mismas que con la funci√≥n `lm` ya que, como se defini√≥ en los argumentos de la funci√≥n, la funci√≥n de enlace es Gausiana.

Por √∫ltimo y a modo de resumen se muestra un gr√°fico donde se encuentran depositados todos los modelos estimados anteriormente y as√≠ poder comparar de manera gr√°fica su ajuste:


```{r, plot4, echo=TRUE, eval=TRUE}
df_model <- data.frame(
  intercept = c(coefficients(fit)[1],
               coefficients(fit_sinP)[1],
               coefficients(fit_Ponde)[1],
               coefficients(fit_svy)[1]),
  slope = c(coefficients(fit)[2],
               coefficients(fit_sinP)[2],
               coefficients(fit_Ponde)[2],
               coefficients(fit_svy)[2]),
  Modelo = c("Poblaci√≥n", "Sin ponderar",
             "Ponderado(lm)", "Ponderado(svyglm)"))
plot_BigCity +  geom_abline( data = df_model,
    mapping = aes( slope = slope,
      intercept = intercept, linetype = Modelo,
      color = Modelo ), size = 2
  )

```


### Uso de ponderaciones

En el an√°lisis de datos provenientes de encuestas con dise√±os complejos surge un interrogante clave: **¬øc√≥mo deben incorporarse los pesos muestrales en los modelos de regresi√≥n?** La respuesta no es trivial, ya que los pesos reflejan tanto la probabilidad de selecci√≥n como los ajustes por no respuesta y calibraci√≥n, pero su uso directo en el modelado puede generar problemas de eficiencia y aumentar la varianza de los estimadores.

Para enfrentar estas limitaciones, se han propuesto diferentes estrategias de ajuste que buscan lograr un balance entre precisi√≥n y eficiencia en la estimaci√≥n. Entre los procedimientos m√°s utilizados destacan los siguientes:

**Pesos tipo Senado**
Este procedimiento ajusta los pesos de manera que su suma coincida con el tama√±o de la muestra, en lugar del tama√±o de la poblaci√≥n. El objetivo es mantener la representatividad relativa de las unidades, pero reduciendo la dispersi√≥n de los pesos originales, lo que resulta particularmente ventajoso en encuestas donde existe alta variabilidad entre los factores de expansi√≥n:

$$
w_k^{Senate} = w_k \times \frac{n}{\sum w_k}
$$

**Pesos normalizados**
En este enfoque los pesos originales se reescalan para que su suma sea igual a uno, lo que evita un incremento innecesario de la varianza en los modelos. Esta t√©cnica es especialmente √∫til cuando se trabaja con diferentes subconjuntos de datos (por ejemplo, modelos estimados en subpoblaciones) o cuando se busca minimizar la inflaci√≥n de la varianza:

$$
w_k^{Normalized} = \frac{w_k}{\sum w_k}
$$


Es importante resaltar que, en ambos m√©todos, los pesos ajustados se obtienen mediante transformaciones multiplicativas directas de los pesos muestrales originales. Por esta raz√≥n, no deben emplearse para calcular **totales poblacionales**, ni modifican los coeficientes de variaci√≥n asociados a ellos. Asimismo, estos procedimientos no afectan las estimaciones de **razones**, como medias o proporciones, ya que en dichos casos los pesos se cancelan en el cociente.

En la pr√°ctica, el uso de estos ajustes puede considerarse una soluci√≥n pragm√°tica en contextos donde no se dispone de software especializado para encuestas. Sin embargo, cuando se cuenta con programas estad√≠sticos que permiten la incorporaci√≥n directa de pesos y del dise√±o muestral ‚Äîcomo los descritos en la Subsecci√≥n 9.3.4‚Äî el reescalamiento de los pesos deja de ser necesario, ya que dichos programas realizan el tratamiento adecuado para preservar tanto la representatividad como las propiedades inferenciales del modelo.



## Diagn√≥stico del modelo

En el an√°lisis de encuestas de hogares, cuando se ajusta un modelo estad√≠stico, es crucial realizar **verificaciones de calidad** que garanticen la validez de las conclusiones. La literatura metodol√≥gica destaca que un modelo bien especificado no solo depende de la elecci√≥n de las covariables, sino tambi√©n de que se cumplan los supuestos b√°sicos que aseguran la coherencia de los resultados *(T√©llez, 2016)*.

Entre los elementos que deben revisarse al aplicar un modelo de regresi√≥n lineal en encuestas complejas se encuentran los siguientes:

* **Adecuaci√≥n del ajuste**: comprobar si el modelo logra explicar una proporci√≥n significativa de la variabilidad de la variable de inter√©s y si las predicciones se ajustan razonablemente a los datos observados.
* **Normalidad de los errores**: verificar si los errores se distribuyen aproximadamente de manera normal, lo que garantiza la validez de las pruebas de significancia.
* **Homogeneidad de la varianza (homocedasticidad)**: confirmar que la variabilidad de los errores se mantenga constante a lo largo de los valores de las covariables. La presencia de heterocedasticidad puede sesgar las inferencias.
* **Independencia de los errores**: examinar si los errores son independientes entre s√≠, evitando correlaciones que comprometan la validez de las pruebas estad√≠sticas.
* **Casos influyentes**: identificar observaciones que ejercen un efecto desproporcionado en la estimaci√≥n del modelo, lo que podr√≠a distorsionar los resultados.
* **Datos at√≠picos (outliers)**: detectar unidades que se apartan significativamente de la tendencia general de la muestra y que pueden afectar el ajuste del modelo.


En el contexto de encuestas complejas, estas verificaciones adquieren una relevancia particular. Problemas como la multicolinealidad, la falta de independencia entre observaciones o la presencia de valores extremos pueden acentuarse debido al dise√±o muestral (estratificaci√≥n, conglomeraci√≥n y ponderaci√≥n). Por ello, los procedimientos de diagn√≥stico no deben limitarse a la revisi√≥n de los supuestos cl√°sicos, sino tambi√©n considerar las especificidades del dise√±o.

La aplicaci√≥n sistem√°tica de estas pruebas diagn√≥sticas permite evaluar la solidez del modelo, incrementar la confianza en las inferencias y garantizar que los resultados derivados sean representativos y √∫tiles para el an√°lisis de pol√≠ticas p√∫blicas o para la investigaci√≥n social aplicada.



### Coeficiente de determinaci√≥n

Una medida cl√°sica para evaluar el ajuste de un modelo de regresi√≥n es el **coeficiente de determinaci√≥n** ($R^{2}$), tambi√©n conocido como coeficiente de correlaci√≥n m√∫ltiple. Este indicador estima la proporci√≥n de la varianza de la variable dependiente que es explicada por el modelo, y sus valores oscilan entre 0 y 1. Cuanto m√°s pr√≥ximo est√© de 1, mayor ser√° la proporci√≥n de variabilidad explicada; por el contrario, un valor cercano a 0 refleja que el modelo aporta poca capacidad explicativa.

No obstante, la interpretaci√≥n de $R^{2}$ var√≠a seg√∫n el campo disciplinar. En ciencias f√≠sicas, es com√∫n obtener valores superiores al 0.98 o 0.99, mientras que en ciencias qu√≠micas suelen alcanzarse niveles por encima de 0.90. En contraste, en ciencias sociales y, en general, en estudios con poblaciones humanas, incluso los mejores modelos explicativos rara vez superan un rango del 20 % al 40 % de la variabilidad de la variable de inter√©s (*Heringa*). Este contraste resalta que la magnitud de $R^{2}$ no debe interpretarse de manera absoluta, sino en funci√≥n del contexto y la naturaleza de los datos analizados.

El coeficiente de determinaci√≥n se calcula a partir de las sumas de cuadrados totales y de error, de la siguiente manera:

$$
R^{2} = 1 - \frac{SSE}{SST},
$$

donde $SST$ representa la suma de cuadrados totales y $SSE$ la suma de cuadrados del error.

En encuestas con **dise√±os de muestreo complejos**, es necesario ajustar esta medida para reflejar la estructura del dise√±o y los pesos muestrales. En este caso, el estimador ponderado se define como:

$$
\hat{R}_\omega^2 = 1 - \frac{(\widehat{SSE})_\omega}{(\widehat{SST})_\omega},
$$

donde $(\widehat{SSE})_\omega$ corresponde a la **suma ponderada de errores al cuadrado**, calculada como:

$$
(\widehat{SSE})_\omega = \sum_{h=1}^{H} \sum_{i \in s_{1h}} \sum_{k \in s_{hi}} w_{hik} \,(y_{hik} - x_{hik}\hat{\beta})^2,
$$

y $(\widehat{SST})_\omega$ representa la **suma total ponderada de cuadrados**, definida por:

$$
(\widehat{SST})_\omega = \sum_{h=1}^{H} \sum_{i \in s_{1h}} \sum_{k \in s_{hi}} w_{hik}\,(y_{hik} - \hat{\bar{Y}})^2.
$$

Finalmente, dado que $R^{2}$ tiende a incrementarse a medida que se incluyen m√°s variables en el modelo, se recomienda emplear tambi√©n el **coeficiente de determinaci√≥n ajustado** ($R_{adj}^{2}$), que incorpora una correcci√≥n en funci√≥n del n√∫mero de covariables y del tama√±o de la muestra:

$$
R_{adj}^{2} = 1 - \frac{(n-1)}{(n-p)} \,(1 - R_{\omega}^{2}),
$$

donde $n$ es el tama√±o muestral efectivo y $p$ el n√∫mero de par√°metros estimados.

Este ajuste permite una comparaci√≥n m√°s justa entre modelos con diferente n√∫mero de predictores y es particularmente √∫til en el an√°lisis de encuestas, donde la complejidad del dise√±o y el uso de ponderaciones pueden influir notablemente en la magnitud de $R^{2}$.


Para continuar con los modelos ajustados en la secci√≥n anterior, se procede a estimar los $R^{2}$ utilizando `R`. Inicialmente, se procede a estimar los par√°metros del modelo utilizando la funci√≥n `svyglm` de `survey` como se mostr√≥ anteriormente y tambi√©n, se ajusta un modelo solo con el intercepto para obtener la estimaci√≥n de la SST:

```{r, tab7, echo = TRUE, eval = TRUE}
fit_svy <- svyglm(Income ~ Expenditure,
                  design = diseno)

modNul <- svyglm(Income ~ 1, design = diseno)

s1 <- summary(fit_svy)
s0 <-summary(modNul)

WSST<- s0$dispersion
WSSE<- s1$dispersion
```

Por tanto, la estimaci√≥n del $R^{2}$ es:


```{r}
R2 = 1- WSSE/WSST
R2
```

y, para estimar el $R_{adj}^{2}$ se requiere definir el dise√±o muestral pero incluyendo los q-weigthed **(Pffeferman, 2011)**. A continuaci√≥n, se muestra los pasos para encontrar los q-weigthed:

-   Ajustar un modelo de regresi√≥n a los pesos finales de la encuesta utilizando las variables predictoras en el modelo de regresi√≥n de inter√©s.


```{r, eval=TRUE}
fit_Nul <- lm(wk ~ 1, data = encuesta)
```

-   Obtener las predicciones de los pesos de la encuesta para cada caso como una funci√≥n de las variables predictoras en el conjunto de datos

```{r, eval=TRUE}
qw <- predict(fit_Nul)
```

- Dividir los pesos finales de la encuesta por los valores predichos en el paso anterior:

```{r, eval=TRUE}
encuesta %<>% mutate(wk1 = wk/qw)
```

- Usar los nuevos pesos obtenidos para el ajuste de los modelos de regresi√≥n:

```{r, eval=TRUE}
diseno_qwgt <- encuesta %>%
  as_survey_design(
    strata = Stratum,
    ids = PSU,
    weights = wk1,
    nest = T)
```

Ahora bien, una vez definido el dise√±o muestral con los nuevos pesos q-weigthed, se procede a calcular el $R_{adj}^{2}$ como sigue:

```{r, echo = TRUE, eval = TRUE}
n = sum(diseno_qwgt$variables$wk)
p<- 2
R2Adj = 1-( ( (n-1)/(n-p) )*R2 )
R2Adj
```

Como se puede observar, el $R_{adj}^{2}$ es un poco m√°s bajo que el $R^{2}$ y cercanos al 50% que como se coment√≥ anteriormente, dependiendo del contexto del problema se podr√° concluir si es grande o peque√±o.


Despu√©s de realizar la comparaci√≥n entre las diferentes formas de estimar los coeficientes del modelo se opta  por la metodolog√≠a consolidadas en  `svyglm`:

```{r, echo=TRUE, eval=TRUE, results='asis'}

diseno_qwgt %<>% mutate(Age2 = Age^2)
mod_svy <- svyglm( Income ~ Expenditure + Zone + Sex + Age2 ,
                       design = diseno_qwgt)
s1 <- summary(mod_svy)
s0 <- summary(modNul)

mod_svy

stargazer(mod_svy, header = FALSE,single.row = T,
           title = "Modelo propuesto",
           type = "latex",  omit.stat=c("bic", "ll"))
```


### Diagn√≥stico de los residuales

En el diagn√≥stico de los modelos, el an√°lisis de los residuales constituye una herramienta fundamental. Bajo el supuesto de que el modelo ajustado es adecuado, los residuales proporcionan una estimaci√≥n de los errores y, en consecuencia, permiten evaluar la validez de los supuestos del modelo. Un examen cuidadoso de los mismos ayuda al investigador a determinar si el procedimiento de ajuste ha respetado dichos supuestos o, por el contrario, si alguno de ellos ha sido violado, en cuyo caso ser√≠a necesario revisar la especificaci√≥n del modelo o incluso replantear el m√©todo de ajuste.

En encuestas con dise√±os muestrales complejos, los **residuales de Pearson** son una forma habitual de evaluar discrepancias entre los valores observados y los esperados. Se definen como:

$$
r_{p_{i}} = \left(y_{i} - \mu_{i}(\hat{\beta}_{\omega})\right) \sqrt{\frac{\omega_{i}}{V(\hat{\mu}_{i})}},
$$

donde $\mu_{i}$ representa el valor esperado de $y_{i}$ bajo el modelo ajustado, $\omega_{i}$ es el peso muestral correspondiente al individuo $i$ y $V(\hat{\mu}_{i})$ es la funci√≥n de varianza del resultado.

#### Residuos estandarizados

En t√©rminos generales, los residuos corresponden a la diferencia entre los valores observados y los estimados por el modelo. El an√°lisis de estos residuos es esencial para verificar el cumplimiento de los supuestos de la regresi√≥n. Una pr√°ctica com√∫n consiste en graficar los residuos frente a los valores predichos o frente a las variables independientes. En un modelo correctamente especificado, la nube de puntos resultante deber√≠a mostrar un patr√≥n aleatorio; la presencia de formas sistem√°ticas puede indicar problemas como **heterocedasticidad** (varianza no constante) o **relaciones no lineales** no captadas por el modelo.


El an√°lisis gr√°fico es un procedimiento ampliamente utilizado para identificar posibles deficiencias en el modelo. En particular, los **gr√°ficos de residuos frente a valores predichos** son una de las herramientas m√°s informativas para evaluar la adecuaci√≥n del ajuste. La inspecci√≥n visual de estos gr√°ficos ayuda a determinar si el modelo cumple con los supuestos de normalidad e independencia de los errores.

En el contexto de encuestas complejas, los residuos pueden expresarse de la siguiente manera:

$$
r_{(p_k)} = \frac{y_k - \hat{\mu}_k}{\sqrt{V(\hat{\mu}_k)/w_k}},
$$

donde $\hat{\mu}_k$ es el valor predicho de $y_k$, $w_k$ es el peso muestral de la unidad $k$ y $V(\hat{\mu}_k)$ corresponde a la funci√≥n de varianza asociada. Estos residuos ponderados se emplean para evaluar tanto la **normalidad** como la **homogeneidad de la varianza** en los errores.

#### Evaluaci√≥n de la homocedasticidad

Uno de los supuestos m√°s relevantes en los modelos de regresi√≥n es la constancia de la varianza de los errores (homocedasticidad). Si este supuesto se viola, los estimadores de los par√°metros del modelo permanecen insesgados y consistentes, pero pierden eficiencia, es decir, ya no alcanzan la menor varianza posible entre todos los estimadores insesgados.

Para evaluar este aspecto, se recomienda representar los residuos frente a los valores predichos $\hat{y}$ o frente a alguna covariable $x_j$. La aparici√≥n de un patr√≥n sistem√°tico (por ejemplo, forma de embudo o curvaturas) es un indicio de **heterocedasticidad**. En tales casos, pueden considerarse estrategias de correcci√≥n, como transformaciones de la variable dependiente, inclusi√≥n de t√©rminos adicionales en el modelo o el uso de estimadores robustos de varianza.



Otra definici√≥n que se debe tener en consideraci√≥n para el an√°lisis de los residuales es el de la matriz hat, la cual se estima como:

$$
H  =  W^{1/2}X\left(X'WX\right)^{-1}X'W^{1/2}
$$
donde,

$$
W  =  diag\left\{ \frac{\omega_{1}}{V\left(\mu_{1}\right)\left[g'\left(\mu_{1}\right)\right]^{2}},...,\frac{\omega_{n}}{V\left(\mu_{n}\right)\left[g'\left(\mu_{n}\right)\right]^{2}}\right\}
$$
$W$ es una matriz diagonal de $n\times n$ y $g()$ es la funci√≥n de enlace del modelo lineal generalizado.


### Observaciones influyentes

En el an√°lisis diagn√≥stico de modelos, una t√©cnica fundamental consiste en la identificaci√≥n de observaciones influyentes. Estas son unidades muestrales cuyo impacto sobre el ajuste del modelo es desproporcionado en comparaci√≥n con el resto de la muestra. Es importante destacar que una observaci√≥n influyente no necesariamente corresponde a un valor at√≠pico: mientras que un at√≠pico puede estar alejado del patr√≥n general de los datos, su efecto sobre el ajuste puede ser m√≠nimo. Por el contrario, una observaci√≥n influyente puede alterar de manera significativa las estimaciones de los par√°metros, incluso si no luce at√≠pica.

Una observaci√≥n se considera influyente si su exclusi√≥n provoca cambios sustanciales en el ajuste global del modelo o en par√°metros espec√≠ficos. Para detectar este tipo de observaciones es esencial precisar el tipo de influencia que se desea evaluar, ya que una unidad puede ser influyente sobre la estimaci√≥n de los par√°metros pero no sobre la varianza del error, o viceversa.

En el caso de encuestas complejas, este an√°lisis requiere especial atenci√≥n, pues los pesos muestrales, las estratificaciones y las unidades primarias de muestreo (PSU) amplifican o reducen la influencia de cada observaci√≥n en comparaci√≥n con los modelos ajustados bajo supuestos de muestreo simple aleatorio. Para este prop√≥sito, la literatura recomienda el uso de herramientas adaptadas a dise√±os muestrales complejos, tales como el paquete `svydiags` en R (v√©ase Valliant, 2024), que implementa diagn√≥sticos extendidos compatibles con datos de encuestas.

A continuaci√≥n, se describen los principales estad√≠sticos utilizados para la detecci√≥n de observaciones influyentes en modelos de regresi√≥n, con sus respectivas adaptaciones al contexto de encuestas complejas:


#### Distancia de Cook

La **distancia de Cook** mide el efecto de eliminar la observaci√≥n *i* sobre el ajuste global del modelo. Eval√∫a simult√°neamente el tama√±o del residual, la varianza estimada y el apalancamiento de la observaci√≥n. En el contexto de encuestas complejas, su c√°lculo se adapta incorporando los pesos muestrales:

$$
c_{i}=\frac{w_{i}^{*}w_{i}e_{i}^{2}}{p\phi V\left(\hat{\mu}_{i}\right)\left(1-h_{ii}\right)^{2}}\boldsymbol{x}_{i}^{t}\left[\widehat{Var}\left(U_{w}\left(\hat{\boldsymbol{\beta}}_{w}\right)\right)\right]^{-1}\boldsymbol{x}_{i}
$$

donde:

* $w_i^*$ son los pesos de la encuesta,
* $e_i$ es el residual de la observaci√≥n *i*,
* $p$ es el n√∫mero de par√°metros del modelo,
* $\phi$ es el par√°metro de dispersi√≥n en el modelo lineal generalizado,
* $h_{ii}$ corresponde al apalancamiento de la observaci√≥n *i*,
* $\widehat{Var}\left(U_{w}\left(\hat{\boldsymbol{\beta}}_{w}\right)\right)$ es la varianza linealizada de la ecuaci√≥n de puntuaci√≥n.

Para evaluar su magnitud, se compara $c_i$ con puntos de referencia. Una aproximaci√≥n es el estad√≠stico:

$$
\frac{\left(df-p+1\right)\times c_{i}}{df} \doteq F_{\left(p,df-p\right)}
$$

donde $df$ son los grados de libertad basados en el dise√±o. En la pr√°ctica, la literatura (Heeringa; T√©llez, 2016) suele considerar como observaciones influyentes aquellas cuyo $c_i$ excede valores cr√≠ticos como 2 o 3.


#### $D_f\text{Beta}$

El estad√≠stico **$D_f \text{Beta}_{(i)}$** cuantifica el cambio en los coeficientes de regresi√≥n cuando la observaci√≥n *i* es eliminada:

$$
D_f \text{Beta}_{(i)} = \hat{\boldsymbol{\beta}}-\hat{\boldsymbol{\beta}}_{\left(i\right)}=\frac{\boldsymbol{A}^{-1}\boldsymbol{X}_{\left(i\right)}^{t}\hat{e}_{i}w_{i}}{1-h_{ii}}
$$

donde $\boldsymbol{A} =\boldsymbol{X}^{t}\boldsymbol{WX}$ y $\hat{\boldsymbol{\beta}}_{(i)}$ es el vector de par√°metros estimados sin la observaci√≥n *i*.

En su forma estandarizada:

$$
D_f Betas_{\left(i\right)}=\frac{{c_{ji}e_{i}}\big/{\left(1-h_{ii}\right)}}{\sqrt{v\left(\hat{\beta}_{j}\right)}}
$$

La interpretaci√≥n es directa: una observaci√≥n es influyente sobre el coeficiente $\hat{\beta}*j$ si $|D_f Betas*{(i)j}|\geq \frac{z}{\sqrt{n}}$, con $z=2$ o $3$, o alternativamente si supera el umbral $t_{0.025,n-p}/\sqrt{n}$.


#### $D_f \text{Fits}$

Finalmente, el estad√≠stico **$D_f \text{Fits}_{(i)}$** mide la influencia de una observaci√≥n sobre el ajuste total del modelo. Se calcula como:

$$
D_{f}Fits_{\left(i\right)}= \frac{h_{ii}e_{i}\big/\left(1-h_{ii}\right)}{\sqrt{v\left(\hat{\beta}_{j}\right)}}
$$

La observaci√≥n *i* se considera influyente si:

$$
|D_f Fits_{(i)}| \geq z\sqrt{\frac{p}{n}} \quad \text{con } z=2 \text{ o } 3
$$


Por otro lado, un an√°lisis que es de vital importancia en el ajuste de modelos de regresi√≥n m√°s espec√≠ficamente en el an√°lisis de residuales es el de varianza constante en los errores. La principal consecuencia de no tener en cuenta la violaci√≥n de este supuesto es que los estimadores pierden eficiencia. Si el supuesto de varianza constante no se cumple, los estimadores siguen siendo insesgados y consistentes, pero dejan de ser eficientes, es decir, dejan de ser los mejores en cuanto a que ya no tienen la menor varianza entre todos los estimadores insesgados. Como consecuencia de lo anterior, los intervalos de confianza ser√°n m√°s amplios y las pruebas t y F dar√°n resultados imprecisos *(Tellez, 2016)*.

Una de las formas de analizar el supuesto de varianzas constantes en los errores es hacerlo de manera gr√°fica. Para ello, se grafica los residuos del modelo contra $\hat{y}$ o los residuos del modelo contra $X_{i}$. Si al realizar estos gr√°ficos se logra evidenciar un patr√≥n (funciones cuadr√°ticas, c√∫bicas, logar√≠tmicas, etc), se puede decir que la varianza de los errores no es constante.

Otro supuesto que se debe revisar en los errores al momento de realizar ajustes es la normalidad en lo errores. Una forma muy com√∫n para hacer dicha evaluaci√≥n es realizar un gr√°fico cuantil-cuantil normal o QQplot. El QQplot es una gr√°fica de cuantiles para los residuos observados frente a los calculados a partir de una distribuci√≥n normal te√≥rica que tiene la misma media y varianza que la distribuci√≥n de los residuos observados. Por lo tanto, una l√≠nea recta de 45¬∞ en este gr√°fico sugerir√≠a que la normalidad es una suposici√≥n razonable para los errores aleatorios en el modelo.

A manera de ejemplificar los conceptos vistos, se van a utilizar los modelos previamente ajustados. En primero instancia, el an√°lisis del modelo se centrar√° en los supuestos de normalidad y varianza constante en los errores. Primero, se realizar√° el an√°lisis de la normalidad en los errores de manera gr√°fica como se muestra a continuaci√≥n:


```{r}
par(mfrow = c(2,2))
plot(mod_svy)
```

Como se puedo observar en el QQplot, hay evidencia gr√°fica de que los errores no se distribuyen seg√∫n una distribuci√≥n normal.

La librer√≠a `svydiags` est√° pensada en ayudar en el diagnostico de modelos de regresi√≥n lineal, siendo una extensi√≥n m√°s para complementar el paquete `survey`. Con las librer√≠as `svydiags` se extraen los residuales estandarizados como sigue:

```{r, echo = TRUE, eval=TRUE}
library(svydiags)
stdresids = as.numeric(svystdres(mod_svy)$stdresids)
diseno_qwgt$variables %<>% mutate(stdresids = stdresids)
```


Podemos hacer el an√°lisis de normalidad tambi√©n por medio del histograma de los residuales estandarizados como sigue:

```{r, echo = TRUE, eval = FALSE}
ggplot(data = diseno_qwgt$variables,
       aes(x = stdresids)) +
  geom_histogram(aes(y = ..density..),
                 colour = "black",
                 fill = "blue", alpha = 0.3) +
  geom_density(size = 2, colour = "blue") +
  geom_function(fun = dnorm, colour = "red",
                size = 2) +
  theme_cepal()+labs(y = "")
```

y como se puede observar gr√°ficamente los errores no siguen una distribuci√≥n normal.

Por otro lado, el otro an√°lisis que se realiza de manera gr√°fica es el de varianzas constantes el cual se realizar√° a continuaci√≥n:


Primero, agreguemos las predicciones a la base de datos para poder realizar las gr√°ficas.

```{r, echo=TRUE, eval=TRUE,size="tiny"}
library(patchwork)
diseno_qwgt$variables %<>%
  mutate(pred = predict(mod_svy))
g2 <- ggplot(data = diseno_qwgt$variables,
       aes(x = Expenditure, y = stdresids))+
  geom_point() +
  geom_hline(yintercept = 0) + theme_cepal()
g3 <- ggplot(data = diseno_qwgt$variables,
       aes(x = Age2, y = stdresids))+
  geom_point() +
  geom_hline(yintercept = 0) + theme_cepal()
```


```{r, plot6, echo=TRUE, eval=FALSE,size="tiny"}
g4 <- ggplot(data = diseno_qwgt$variables,
       aes(x = Zone, y = stdresids))+
  geom_point() +
  geom_hline(yintercept = 0) + theme_cepal()
g5 <- ggplot(data = diseno_qwgt$variables,
       aes(x = Sex, y = stdresids))+
  geom_point() +  geom_hline(yintercept = 0) +
  theme_cepal()

(g2|g3)/(g4|g5)
```

Como se puede observar en las gr√°ficas de gastos y edad, ambas muestran tendencias y no un comportamiento aleatorio. Por lo anterior, se puede decir que las varianzas no son constantes.

Otros de os an√°lisis a realizar es revisar si existen datos influyentes en la base de datos. Para ejemplificar los conceptos definidos, se seguir√°n con los modelos ajustados en la secci√≥n anterior. Una vez ajustados estos modelos y verificados los supuestos, se procede a hacer el c√°lculo de la distancia de Cook's usando la funci√≥n `svyCooksD`del paquete `svydiags` como sigue:

```{r, dcook, eval=FALSE}
library(svydiags)
d_cook = data.frame(
   cook = svyCooksD(mod_svy),
     id = 1:length(svyCooksD(mod_svy)))

table(d_cook$cook>3)


ggplot(d_cook, aes(y = cook, x = id)) +
  geom_point() +
  theme_bw(20)
```

Como se puede observar, ninguna de las distancias de Cook's es mayor a 3 por lo que, podemos decir que no existen observaciones influyentes.

Ahora bien, se desea observar si hay observaciones influyentes pero utilizando $D_{f}Betas_{\left(i\right)j}$ se realiza con la funci√≥n `svydfbetas` como se muestra a continuaci√≥n:

```{r}
d_dfbetas = data.frame(t(svydfbetas(mod_svy)$Dfbetas))
colnames(d_dfbetas) <- paste0("Beta_", 1:5)
d_dfbetas %>% slice(1:10L)
```
Una vez calculado los $D_{f}Betas_{\left(i\right)j}$ se procede a acomodar la salida con para verificar cu√°les observaciones son influyentes. Para esto, de calcula el umbral (cutoff) para definir si es o no influyente la observaci√≥n. Ese umbral es tomado de las salidas de la funci√≥n `svydfbetas`. Por √∫ltimo, se genera una variable dicot√≥mica que indique si la observaci√≥n es o no influyente como se muestra a continuaci√≥n:

```{r eval=TRUE, echo=TRUE}
d_dfbetas$id <- 1:nrow(d_dfbetas)
d_dfbetas <- reshape2::melt(d_dfbetas, id.vars = "id")
cutoff <- svydfbetas(mod_svy)$cutoff
d_dfbetas %<>% mutate( Criterio = ifelse(abs(value) > cutoff, "Si", "No"))

tex_label <- d_dfbetas %>%
  filter(Criterio == "Si") %>%
  arrange(desc(abs(value))) %>%
  slice(1:10L)
tex_label
```

Como se pudo observar en la salida anterior hay varias observaciones que resultan influyentes dado el criterio del $D_{f}Betas_{\left(i\right)j}$. A continuaci√≥n, y de manera ilustrativa, se grafican los $D_{f}Betas_{\left(i\right)j}$ y el umbral con el fin de ver de manera gr√°fica aquellas observaciones influyentes, teniendo en cuenta que, aquellos puntos rojos en la gr√°fica representan observaciones influyentes.

```{r eval=FALSE, plot_dfbetas, echo=TRUE}
ggplot(d_dfbetas, aes(y = abs(value), x = id)) +
  geom_point(aes(col = Criterio)) +
  geom_text(data = tex_label,
            angle = 45,
            vjust = -1,
            aes(label = id)) +
  geom_hline(aes(yintercept = cutoff)) +
  facet_wrap(. ~ variable, nrow = 2) +
  scale_color_manual(
    values = c("Si" = "red", "No" = "black")) +
  theme_cepal()
```
Si el objetivo ahora es detectar observaciones influyentes pero considerando ahora la estad√≠stica $D_{f}Fits_{\left(i\right)}$, se utiliza la funci√≥n `svydffits` y se siguen los mismos pasos mostrados para el estad√≠stico $D_{f}Betas_{\left(i\right)j}$:

```{r,plot_dffit, echo=TRUE, eval=FALSE}
d_dffits = data.frame( dffits = svydffits(mod_svy)$Dffits,
                       id = 1:length(svydffits(mod_svy)$Dffits))

cutoff <- svydffits(mod_svy)$cutoff

d_dffits %<>% mutate(C_cutoff = ifelse(abs(dffits) > cutoff, "Si", "No"))
ggplot(d_dffits, aes(y = abs(dffits), x = id)) +
  geom_point(aes(col = C_cutoff)) +
  geom_hline(yintercept = cutoff) +
   scale_color_manual(
    values = c("Si" = "red", "No" = "black"))+
  theme_cepal()
```

Como se puede observar en el gr√°fico anterior, tambi√©n hay observaciones influyentes utilizando $D_{f}Fits_{\left(i\right)}$, las cuales se muestran en rojo en el gr√°fico.

Un √∫ltimo acercamiento que se trabajar√° en este texto para la detecci√≥n de datos influyentes est√° encaminado al uso de la matriz *H*. En este sentido, la matriz asociada al Estimador de Pseudo M√°xima Verosimilitud (PMLE) de $\hat{\boldsymbol{B}}$ es $\boldsymbol{H}=\boldsymbol{XA}^{-1}\boldsymbol{X}^{-t}\boldsymbol{W}$ cuya diagonal esta dado por $h_{ii} = \boldsymbol{x_{i}^tA}^{-1}\boldsymbol{x_{i}}^{-t}w_{i}$. Utilizando la matriz *H*, una observaci√≥n puede ser grande y, como resultado, influir en las predicciones, cuando un $x_i$ es considerablemente diferente del promedio ponderado $\bar{x}_w=\sum_{i\in s}w_{i}\boldsymbol{x_{i}}\big/\sum_{i\in s}w_i$. Seg√∫n *(Tellez, 2016)* una observaci√≥n es considerada grande si es mayor a tres veces el promedio de los $h_{ii}$. A continuaci√≥n, se muestra el procedimiento en `R` cuya funci√≥n a utilizar es `svyhat`:

```{r, hat, eval=TRUE, echo=TRUE}
vec_hat <- svyhat(mod_svy, doplot = FALSE)
d_hat = data.frame(hat = vec_hat, id = 1:length(vec_hat))
d_hat %<>% mutate(C_cutoff = ifelse(hat > (3 * mean(hat)),"Si", "No"))

ggplot(d_hat, aes(y = hat, x = id)) +
  geom_point(aes(col = C_cutoff)) +
  geom_hline(yintercept = (3 * mean(d_hat$hat))) +
  scale_color_manual(
    values = c("Si" = "red", "No" = "black"))+
  theme_cepal()
```

Dado que esta √∫ltima t√©cnica es emp√≠rica, se puede observar en el gr√°fico anterior que hay varias observaciones posiblemente influyentes en el conjunto de datos de la muestra de hogares.


## Inferencia sobre los par√°metros del modelo

Una vez evaluado el correcto ajuste del modelo utilizando las metodolog√≠as vistas anteriormente y corroboradas las propiedades distribucionales de los errores ‚Äîy, en consecuencia, de la variable respuesta $y$‚Äî, el siguiente paso consiste en verificar si los par√°metros estimados son estad√≠sticamente significativos. Esto permite determinar si las covariables incluidas en el modelo aportan de manera sustantiva a la explicaci√≥n o predicci√≥n de la variable de estudio.

En los modelos de regresi√≥n, el enfoque cl√°sico para contrastar hip√≥tesis sobre los par√°metros $\beta_k$ se basa en las propiedades distribucionales de sus estimadores. Un estad√≠stico de prueba natural para evaluar la significancia de un coeficiente se construye a partir de la distribuci√≥n *t-Student* y se define como:

$$
t=\frac{\hat{\beta}_{k}-\beta_{k}}{se\left(\hat{\beta}_{k}\right)} \sim t_{n-p}
$$

donde $p$ es el n√∫mero de par√°metros del modelo y $n$ el tama√±o muestral. Este estad√≠stico permite contrastar la hip√≥tesis nula $H_{0}:\beta_{k}=0$ frente a la alternativa $H_{1}:\beta_{k}\neq 0$.

En consecuencia, cuando $|t|$ es lo suficientemente grande, se rechaza la hip√≥tesis nula, concluyendo que la covariable asociada al par√°metro $\beta_k$ tiene un efecto significativo en la variable respuesta.

De igual manera, las propiedades distribucionales de los $\beta$ permiten construir intervalos de confianza al nivel $(1-\alpha)\times100%$, definidos como:

$$
\hat{\beta}_{k}\pm t_{1-\frac{\alpha}{2},\,df}\,se\left(\hat{\beta}_{k}\right)
$$

donde $se(\hat{\beta}*k)$ es el error est√°ndar del estimador y $t*{1-\frac{\alpha}{2},,df}$ corresponde al percentil de la distribuci√≥n *t-Student* con $df$ grados de libertad.

En el caso particular de las encuestas de hogares con **dise√±os muestrales complejos**, los grados de libertad no se calculan simplemente como $n-p$ (como en el enfoque cl√°sico), sino que deben ajustarse para reflejar la estructura del muestreo. De acuerdo con la teor√≠a de dise√±o, se establece que:

$$
df = \sum_{h} a_{h} - H
$$

donde $\sum_{h}a_{h}$ es el n√∫mero total de conglomerados finales de la primera etapa y $H$ el n√∫mero de estratos de dicha etapa.

Este ajuste es fundamental porque asegura que la inferencia refleje de manera adecuada la variabilidad introducida por la estratificaci√≥n, la conglomeraci√≥n y las probabilidades de selecci√≥n desiguales, evitando conclusiones err√≥neas sobre la significancia de los par√°metros en el an√°lisis de encuestas complejas.



Para la aplicaci√≥n de las tem√°ticas vistas, es decir, realizar la prueba de hip√≥tesis y los intervalos de confianza para los par√°metros utilizaremos el modelo que se ha venido trabajando y aplicaremos las funciones `summary.svyglm` para las pruebas t y `confint.svyglm` para los intervalos de confianza como sigue:

```{r}
survey:::summary.svyglm(mod_svy)

survey:::confint.svyglm(mod_svy)
```

De lo anterior se puede observar que, con una confianza del 95% el √∫nico par√°metro significativo del modelo es Expenditure y ese mismo resultado lo reflejan los intervalos de confianza.

*Estimaci√≥n de una observaci√≥n*

Los modelos de regresi√≥n lineales, seg√∫n *(Neter et al., 1996).*, son utilizado esencialmente con 2 fines, el primero es tratar de explicar la variable respuesta en t√©rminos de covariables que pueden encontrarse en la encuesta o en registros administrativos, censos, etc. Adicionalmente, tambi√©n son usados para predecir valores de la variable en estudio ya sea dentro del intervalo de valores recogidos en la muestra o por fuera de dicho intervalo. Lo primero se ha abordado a lo largo de todo el cap√≠tulo y lo segundo se obtiene de la siguiente manera:


$$
\hat{E}(y_{i}\mid\boldsymbol{x}_{obs,i})=\boldsymbol{x}_{obs,i}\hat{\boldsymbol{\beta}}
$$

De manera expl√≠cita, si se ajusta un modelo con 4 covariables la expresi√≥n ser√≠a:

$$
\hat{E}(y_{i}\mid\boldsymbol{x}_{obs,i})=\hat{\beta}_{0}+\hat{\beta}_{1}x_{1i}+\hat{\beta}_{2}x_{2i}+\hat{\beta}_{3}x_{3i}+\hat{\beta}_{4}x_{4i}
$$

La varianza de la estimaci√≥n se calcula de la siguiente manera:

$$
var\left(\hat{E}\left(y_{i}\mid x_{obs,i}\right)\right)
=  x'_{obs,i}cov\left(\hat{\beta}\right)x{}_{obs,i}
$$

A continuaci√≥n, se presenta c√≥mo se realiza la estimaci√≥n del valor esperado, primero se estiman los par√°metros del modelo:

```{r, echo=FALSE}
mod_svy %>% broom::tidy()

```

Por lo anterior, la estimaci√≥n del valor esperado o predicci√≥n queda:

$$
\hat{E}(y_{i}\mid\boldsymbol{x}_{obs,i})=62.2+1.2x_{1i}+63.5x_{2i}+21.7x_{3i}+0.01x_{4i}
$$
Para calcular la varianza de la estimaci√≥n, primero se deben obtener las varianzas de la estimaci√≥n de los par√°metros:

```{r}
vcov(mod_svy)
```

Ahora bien, se procede a realizar los c√°lculos como lo indica la expresi√≥n mostrada anteriormente:

```{r, echo=TRUE}
xobs <- model.matrix(mod_svy) %>%
        data.frame() %>% slice(1) %>% as.matrix()

cov_beta <- vcov(mod_svy) %>% as.matrix()

as.numeric(xobs %*% cov_beta %*% t(xobs))
```

Si el objetivo ahora es calcular el intervalo de confianza para la predicci√≥n se utiliza la siguiente ecuaci√≥n:


$$
\boldsymbol{x}_{obs,i}\hat{\beta}\pm t_{\left(1-\frac{\alpha}{2},n-p\right)}\sqrt{var\left(\hat{E}\left(y_{i}\mid\boldsymbol{x}_{obs,i}\right)\right)}
$$

Para realizar los c√°lculos en R, se utiliza la funci√≥n `confint` y `predict` como sigue:

```{r,pred01, echo=TRUE,eval=FALSE}
pred <- data.frame(predict(mod_svy, type = "link"))
pred_IC <- data.frame(confint(predict(mod_svy, type = "link")))
colnames(pred_IC) <- c("Lim_Inf", "Lim_Sup")
pred_IC
```

Ahora, de manera gr√°fica las predicciones e intervalos se ver√≠a de la siguiente manera:

```{r, plot_pred, echo=TRUE,eval=FALSE}
pred <- bind_cols(pred, pred_IC)
pred$Expenditure <- encuesta$Expenditure
pred %>% slice(1:6L)
pd <- position_dodge(width = 0.2)
ggplot(pred %>% slice(1:100L),
       aes(x = Expenditure , y = link)) +
  geom_errorbar(aes(ymin = Lim_Inf,
                    ymax = Lim_Sup),
                width = .1,
                linetype = 1) +
  geom_point(size = 2, position = pd) +
  theme_bw()
```

Por √∫ltimo, si el inter√©s es hacer una predicci√≥n fuera del rango de valores que fue capturado en la muestra. Para esto, supongamos que se desea predecir:

```{r}
datos_nuevos <- data.frame(Expenditure = 1600,
                           Age2 = 40^2, Sex = "Male",
                           Zone = "Urban")
```

La varianza para la predicci√≥n se hace siguiendo la siguiente ecuaci√≥n:

$$
var\left(\hat{E}\left(y_{i}\mid\boldsymbol{x}_{obs,i}\right)\right)=\boldsymbol{x}_{obs,i}^{t}cov\left(\boldsymbol{\beta}\right)\boldsymbol{x}_{obs,i} + \hat{\sigma}^2_{yx}
$$

Por tanto, se construye la matriz de observaciones y se calcula la varianza como sigue:

```{r}
x_noObs = matrix(c(1,1600,1,1,40^2),nrow = 1)
as.numeric(sqrt(x_noObs%*%cov_beta%*%t(x_noObs)))
```

Por √∫ltimo, el intervalo de confianza sigue la siguiente ecuaci√≥n:

$$
\boldsymbol{x}_{obs,i}\hat{\beta}\pm t_{\left(1-\frac{\alpha}{2},n-p\right)}\sqrt{var\left(\hat{E}\left(y_{i}\mid\boldsymbol{x}_{obs,i}\right)\right)+\hat{\sigma}_{yx}^{2}}
$$
En `R` se hace la predicci√≥n de la siguiente manera:

```{r}
predict(mod_svy, newdata = datos_nuevos, type =  "link")
```

y el intervalo:
```{r}
confint(predict(mod_svy,newdata = datos_nuevos))
```
