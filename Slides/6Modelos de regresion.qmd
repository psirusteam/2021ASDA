---
title: "Análisis de encuestas de hogares con R"
subtitle: "Módulo 5: Modelos de regresión"
author: |
  | Andrés Gutiérrez.
  | Stalyn Guerrero 
institute: "CEPAL - Unidad de Estadísticas Sociales"
format: 
  beamer: 
    colortheme: dove
    fonttheme: default
    incremental: false
    aspectratio: 1610
    #theme: Berkeley
    toc: true
    slide_level: 2
    #highlight: pygments
Email: andres.gutierrez@cepal.org
lang: es
editor_options:
  markdown:
    wrap: 90
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE, warning = FALSE, message = FALSE,echo = TRUE,
                      error = FALSE, cache.path = "00_Caches/06_Regresion/")
options(digits = 4)
options(tinytex.verbose = TRUE)
library (survey)
library(srvyr)
library(convey)
library(TeachingSampling)
library(printr)
library(stargazer)
library(jtools)
library(broom)
library(ggpmisc)
library(modelsummary)
library(nortest)  #REALIZA 10 PRUEBAS 
library(moments)  #REALIZA 1 PRUEBA
library(svydiags)
library(magrittr)
library(purrr)
library(haven)

theme_cepal <- function(...) theme_light(10) + 
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        legend.position="bottom", 
        legend.justification = "left", 
        legend.direction="horizontal",
        plot.title = element_text(size = 20, hjust = 0.5),
        ...) 
```

# Modelos de regresión bajo diseños de muestreo complejos

## Introducción 

- Un modelo matemático es una relación funcional entre variables.
- El objetivo es encontrar modelos que relacionen variables de entrada con una variable de salida.
- A lo largo de la historia, varios autores han discutido el impacto de los diseños muestrales complejos en las inferencias relacionadas con modelos de regresión.


## Introducción 

- **Kish y Frankel (1974):** Fueron los primeros en abordar, de manera empírica, cómo los diseños muestrales complejos afectan las inferencias en modelos de regresión.

- **Fuller (1975):** Desarrolló un estimador de varianza que considera ponderaciones desiguales de observaciones, especialmente relevantes en contextos de muestreo complejo de dos etapas.

- **Sha et al. (1977):** Discutieron las violaciones de supuestos en modelos de regresión lineal y presentaron evaluaciones empíricas del desempeño de estimadores de varianza basados en la linealización para modelos de regresión lineal con datos de encuestas.

- **Binder (1983):** Se centró en las distribuciones muestrales de estimadores para parámetros de regresión en poblaciones finitas y estimadores de varianza relacionados.

## Introducción 

- **Skinner et al. (1989):** Trabajaron en estimadores de varianza para los coeficientes de regresión que permitieron diseños de muestras complejas, y recomendaron el uso de métodos de linealización u otros métodos para la estimación de la varianza.

- **Fuller (2002):** Ofreció un resumen de los métodos de estimación para modelos de regresión que involucran información relacionada con muestras complejas.

- **Pfeffermann (2011):** Discutió enfoques basados en el ajuste de modelos de regresión lineal a datos de encuestas de muestras complejas, respaldando el uso de un método "q-weighted."


## Modelos de Regresión Lineal Simple y Múltiple

- Un modelo de regresión lineal simple se define como 
$$y = \beta_{0} + \beta_{1}x + \varepsilon$$.

- Los modelos de regresión lineal múltiples extienden este concepto para múltiples variables predictoras: 
$$y = \boldsymbol{X}\boldsymbol{\beta} + \varepsilon$$.

- El valor esperado de la variable dependiente condicionado a las variables independientes se representa como $E(y|x)$.

## Consideraciones en Modelos de Regresión

- $E(\varepsilon_{i}|x_{i}) = 0$: El valor esperado de los residuos condicionado a las covariables es igual a 0.

- $Var(\varepsilon_{i}|x_{i}) = \sigma_{y,x}^{2}$: Homogeneidad de varianza, la varianza de los residuos condicionados es constante.

- $\varepsilon_{i}|x_{i} \sim N(0, \sigma_{y,x}^{2})$: Normalidad en los errores, los residuos condicionados se distribuyen normalmente.

- $cov(\varepsilon_{i}, \varepsilon_{j}|x_{i},x_{j})$: Independencia en los residuos, los residuos en diferentes sujetos no están correlacionados con los valores de sus variables predictoras.

## Resultados para el modelo de regresión 

Una vez definido el modelo de regresión lineal y sus supuestos, se puede deducir los siguiente:



\begin{eqnarray*}
\hat{y} & = & E\left(y\mid x\right)\\
 & = & E\left(\boldsymbol{x}\boldsymbol{\beta}\right)+E\left(\varepsilon\right)\\
 & = & \boldsymbol{x}\boldsymbol{\beta}+0\\
 & = & \beta_{0}+\beta_{1}x_{1}+\cdots+\beta_{p}x_{p}
\end{eqnarray*}


y Adicionalmente,

\begin{eqnarray*}
var\left(y_{i}\mid x_{i}\right) & = & \sigma_{y,x}^{2},\\
cov\left(y_{i},y_{j}\mid x_{i},x_{j}\right) & \text{=} & 0\\
 & \text{y}\\
y_{i} & \sim & N\left(x_{i}\boldsymbol{\beta},\sigma_{y,x}^{2}\right)
\end{eqnarray*}

## Estimación de los parámetros en un modelo de regresión simple.

La estimación del coeficiente de regresión $\beta_1$ en un modelo de regresión simple con muestras complejas involucra el uso de ponderaciones y totales. El estimador $\hat{\beta}_1$ se calcula como un cociente de totales ponderados.



\begin{eqnarray*}
\hat{\beta_{1}} & = & \frac{{\displaystyle \sum_{h}^{H}\sum_{\alpha}^{a_{h}}\sum_{i=1}^{n_{h\alpha}}\omega_{h\alpha i}\left(y_{h\alpha i}-\bar{y}_{\omega}\right)\left(x_{h\alpha i}-\bar{x}_{\omega}\right)}}{{\displaystyle \sum_{h}^{H}\sum_{\alpha}^{a_{h}}\sum_{i=1}^{n_{h\alpha}}\omega_{h\alpha i}\left(x_{h\alpha i}-\bar{x}_{\omega}\right)^{2}}}\\
 & = & \frac{t_{xy}}{t_{x^{2}}}
\end{eqnarray*}


## Varianza estimada

La varianza del estimador $\hat{\beta}_1$ se calcula considerando la varianza de los totales ponderados y sus covarianzas. Esta varianza estimada tiene en cuenta el diseño muestral y la estructura de ponderación.

\begin{eqnarray*}
var\left(\hat{\beta_{1}}\right) & = & \frac{var\left(t_{xy}\right)+\hat{\beta}_{1}^{2}var\left(t_{x^{2}}\right)-2\hat{\beta}_{1}cov\left(t_{xy},t_{x^{2}}\right)}{\left(t_{x^{2}}\right)^{2}}
\end{eqnarray*}


## Extensión a modelos de regresión múltiple:

Para modelos de regresión múltiple, la estimación de la varianza se generaliza a través de una matriz de varianza-covarianza que involucra los coeficientes de regresión.


\begin{eqnarray*}
var\left(\hat{\boldsymbol{\beta}}\right)=\hat{\Sigma}\left(\hat{\boldsymbol{\beta}}\right) & = & \left[\begin{array}{cccc}
var\left(\hat{\beta}_{0}\right) & cov\left(\hat{\beta}_{0},\hat{\beta}_{1}\right) & \cdots & cov\left(\hat{\beta}_{0},\hat{\beta}_{p}\right)\\
cov\left(\hat{\beta}_{0},\hat{\beta}_{1}\right) & var\left(\hat{\beta}_{1}\right) & \cdots & cov\left(\hat{\beta}_{1},\hat{\beta}_{p}\right)\\
\vdots & \vdots & \ddots & \vdots\\
cov\left(\hat{\beta}_{0},\hat{\beta}_{p}\right) & cov\left(\hat{\beta}_{1},\hat{\beta}_{p}\right) & \cdots & var\left(\hat{\beta}_{p}\right)
\end{array}\right]
\end{eqnarray*}

Este enfoque de estimación garantiza que se tengan en cuenta las particularidades del diseño muestral en la inferencia sobre los coeficientes de regresión. 


## Aplicación en encuestas de hogares 

El proceso inicia con la lectura de la muestra y definición del objeto `survey.design` 
```{r}
options(survey.lonely.psu="adjust")
encuesta <- readRDS("../Data/encuesta.rds")
data("BigCity", package = "TeachingSampling")

library(srvyr)
diseno <- encuesta %>%
  as_survey_design(
    strata = Stratum,
    ids = PSU,
    weights = wk,
    nest = T
  )
```

## Sub-grupos

Dividir la muestra en sub-grupos de la encuesta.

```{r}
sub_Urbano <- diseno %>%  filter(Zone == "Urban")
sub_Rural  <- diseno %>%  filter(Zone == "Rural")
sub_Mujer  <- diseno %>%  filter(Sex == "Female")
sub_Hombre <- diseno %>%  filter(Sex == "Male")
```

```{r, echo=FALSE, eval=TRUE}

```




## Scatterplot con los datos poblacionales
Para observar que existe una correlación entre el ingreso y el gasto es construido un scatterplot.
```{r, plot1, echo = TRUE, eval = TRUE}
library(ggplot2); library(ggpmisc)
plot_BigCity <- 
  ggplot(data = BigCity,
         aes(x = Expenditure, y = Income)) +
  geom_point() +
  geom_smooth(method = "lm",
              se = FALSE,
              formula = y ~ x) +
  theme_cepal()

plot_BigCity <- plot_BigCity + 
  stat_poly_eq(formula = y~x, 
  aes(label = paste(..eq.label..,
   ..rr.label.., sep = "~~~"),size = 3), parse = TRUE)

```

## Scatterplot con los datos poblacionales
El resultado obtenido es: 

![Relación del ingreso y el gasto en la población](Imagenes/06_Regresion/01_Fig_Regresion1.png){width="450"}


## Modelo poblacional
El modelo poblacional es estimado con `lm`
```{r, tab1, results='asis', echo=TRUE, eval = TRUE}
fit <- lm(Income ~ Expenditure, data = BigCity)
```

```{r, results='asis', echo=FALSE, eval = TRUE}
stargazer(fit, header = FALSE,
          title = "Modelo BigCity", 
          style = "ajps")
```

## Scatterplot con los datos encuesta sin ponderar

Una sintaxis similar permite construir el scatterplot en la muestra. 

```{r, plot2, echo = TRUE, eval = FALSE}
plot_sin <- 
  ggplot(data = encuesta,
         aes(x = Expenditure, y = Income)) +
  geom_point() +
  geom_smooth(method = "lm",
              se = FALSE,
              formula = y ~ x) +
  theme_cepal()
plot_sin <- plot_sin + stat_poly_eq(formula = y~x, 
  aes(label = paste(..eq.label..,
     ..rr.label.., sep = "~~~"), size = 5),
  parse = TRUE)
```

## Scatterplot con los datos encuesta sin ponderar

![Relación del ingreso y el gasto en la muestra sin ponderar ](Imagenes/06_Regresion/02_Fig_Regresion_sin_ponde.png){width="450"}

## Modelo sin ponderar
El modelo ignorando los factores de expansión quedas así: 
```{r, tab2, echo = TRUE, eval = FALSE}
fit_sinP <- lm(Income ~ Expenditure, data = encuesta)
stargazer(fit_sinP, header = FALSE,
          title = "Modelo encuesta Sin ponderar", 
          style = "ajps")
```

## Modelo sin ponderar

```{r, tab2, results='asis', echo = FALSE, eval = TRUE}
```

## Scatterplot con los datos encuesta ponderado
Para que el gráfico tenga en cuenta las ponderaciones debe agregar ` mapping = aes(weight = wk)` en la función `geom_smooth`.
```{r, plot3, echo = TRUE, eval = FALSE}
plot_Ponde <- 
  ggplot(data = encuesta,
         aes(x = Expenditure, y = Income)) +
  geom_point(aes(size = wk)) +
  geom_smooth(method = "lm",
              se = FALSE,
              formula = y ~ x, 
              mapping = aes(weight = wk)) +
  theme_cepal()
plot_Ponde <- plot_Ponde + stat_poly_eq(formula = y~x, 
  aes(weight = wk, 
    label = paste(..eq.label..,
      ..rr.label.., sep = "~~~")), 
  parse = TRUE,size = 5)
```

## Scatterplot con los datos encuesta sin ponderar

![Relación del ingreso y el gasto en la muestra sin ponderar ](Imagenes/06_Regresion/03_Fig_Regresion_con_ponde.png){width="450"}

## Modelo ponderado `lm`

La función `lm` permite incluir los `weights` en la estimación de los coeficientes.

```{r, tab3, echo = TRUE, eval = FALSE}
fit_Ponde <- lm(Income ~ Expenditure, 
                data = encuesta, weights = wk)
stargazer(fit_Ponde, header = FALSE,
          title = "Modelo encuesta ponderada", 
          style = "ajps")
```

## Modelo ponderado lm

```{r, tab3, results='asis', echo = FALSE, eval = TRUE}
```


## Modelo ponderado svyglm
Ahora, emplee la función `svyglm` de `survey`
```{r, tab4, echo = TRUE, eval = TRUE}
fit_svy <- svyglm(Income ~ Expenditure, 
                  design = diseno)
```

## Resumen del Modelo

```{r, tab4a, results='asis', echo = FALSE, eval = TRUE}
stargazer(fit_svy, header = FALSE,
          title = "Modelo encuesta ponderada, svyglm", 
          style = "ajps", omit.stat = "ll")
```

## Comparando los resultados

```{r, plot4, echo=TRUE, eval=FALSE}
df_model <- data.frame(
  intercept = c(coefficients(fit)[1],
               coefficients(fit_sinP)[1], 
               coefficients(fit_Ponde)[1],
               coefficients(fit_svy)[1]), 
  slope = c(coefficients(fit)[2],
               coefficients(fit_sinP)[2], 
               coefficients(fit_Ponde)[2],
               coefficients(fit_svy)[2]),
  Modelo = c("Población", "Sin ponderar", 
             "Ponderado(lm)", "Ponderado(svyglm)"))
plot_BigCity +  geom_abline( data = df_model,
    mapping = aes( slope = slope,
      intercept = intercept, linetype = Modelo,
      color = Modelo ), size = 2
  )

```

## Comparando los resultados

![Resultados de los modelos ](Imagenes/06_Regresion/04_Fig_Comparando_Regresion.png){width="450"}`

## Comparando los resultados
\scriptsize
```{r, echo = FALSE, eval = TRUE}
options("modelsummary_format_numeric_latex" = "plain")
modelsummary(list(Poblacion = fit,
                  "Sin Pond" = fit_sinP,
                  "Ponde(lm)" = fit_Ponde,
                  "Ponde(svyglm)" = fit_svy), 
             statistic = c("p = ({p.value})"),
             output = "markdown", gof_omit = 'BIC|Log' )

```

# Diagnostico del modelo 


## Diagnostico del modelo 


**Adecuado Ajuste del Modelo**:
  - Verificar que el modelo se ajuste adecuadamente a los datos recopilados en la encuesta.
  - Evaluar si la relación funcional especificada es apropiada para representar las variables de interés.

**Normalidad de Errores**:
  - Examinar si los errores del modelo siguen una distribución normal.
  - Esto es crucial para realizar pruebas de hipótesis precisas y estimar intervalos de confianza confiables.

**Varianza Constante de Errores**:
  - Asegurarse de que la varianza de los errores sea constante en todos los niveles de las variables independientes.
  - La heterocedasticidad puede impactar en las pruebas y la interpretación de coeficientes.

## Diagnostico del modelo 

**Errores No Correlacionados**:
  - Evaluar si los errores pueden considerarse no correlacionados entre sí.
  - La autocorrelación de errores puede afectar la eficiencia de las estimaciones.

**Datos Influyentes**:
  - Identificar valores atípicos o datos influyentes que tienen un efecto desproporcionadamente grande en el modelo de regresión.
  - Estos datos deben tratarse con precaución y su impacto debe ser evaluado.

**Valores Atípicos (Outliers)**:

## Estimación del $R^{2}$ y $R_{adj}^{2}$

- En análisis de regresión, el coeficiente de determinación ($R^{2}$) mide la variabilidad explicada por el modelo.

- El $R_{\omega}^{2}$ ajusta $R^{2}$ para muestras complejas, considerando ponderaciones de la muestra.

- $R_{\omega}^{2}$ se basa en la suma de cuadrados totales ponderada (WSST) y la suma de cuadrados del error ponderada (WSSE).

- La fórmula de $R^{2}$ es $1 - \frac{SSE}{SST}$, donde SSE es la suma de cuadrados del error y SST es la suma de cuadrados totales.


## Estimación del $R^{2}$ y $R_{adj}^{2}$

- Para $R_{\omega}^{2}$, la fórmula es $1 - \frac{WSSE}{WSST}$, considerando las ponderaciones de la muestra.


\begin{eqnarray*}
\widehat{WSSE_{\omega}} & = & \sum_{h}^{H}\sum_{\alpha}^{a_{h}}\sum_{i=1}^{n_{h\alpha}}\omega_{h\alpha i}\left(y_{h\alpha i}-x_{h\alpha i}\hat{\beta}\right)^{2}
\end{eqnarray*}


- Se utiliza el coeficiente de determinación ajustado ($R_{adj}^{2}$) para tener en cuenta el tamaño de la muestra y el número de predictores en el modelo.

- $R_{adj}^{2}$ se calcula como $1 - \frac{(n-1)}{(n-p)}R_{\omega}^{2}$, donde $n$ es el tamaño de la muestra y $p$ es el número de predictores.

## Estimación del $R^2$ para el modelo del ingreso.

```{r, tab7.a, echo = TRUE, eval = FALSE}
fit_svy <- svyglm(Income ~ Expenditure, 
                  design = diseno,family=stats::gaussian())

medY <- diseno %>% summarise(medY = survey_mean(Income))

diseno %<>% mutate(
  ypred = fitted(fit_svy, type = "response"),
  medY = medY,
  sst = (Income - medY$medY)^2,
  sse = (ypred - medY$medY)^2
  )

diseno %>% summarise(WSST = survey_total(sst),
                     WSSE = survey_total(sse)) %>% 
  transmute(WSST, WSSE, R2 = WSSE/WSST)


```

## Estimación del $R^2$ para el modelo del ingreso
El resultado para el $R^2$ es 
```{r, tab7.a, echo = FALSE, eval = TRUE}
```
De forma alternativa es:  

```{r, tab7, echo = TRUE, eval = TRUE}
modNul <- svyglm(Income ~ 1, design = diseno)
s1 <- summary(fit_svy)
s0 <-summary(modNul)

WSST<- s0$dispersion
WSSE<- s1$dispersion
R2 = 1- WSSE/WSST
R2
```

## Estimación del $R_{adj}^{2}$ para el modelo del ingreso

Calculamos el $R_{adj}^{2}$ utilizando la fórmula adecuada. Asegúrate de definir los valores de `n` y `p` de acuerdo a tu modelo.

```{r}
n = nrow(encuesta)
p = 2
(R2Adj = 1 - ((n-1)/(n-p)) * R2)
```

## Metodología de los Q_Weighting de pfefferman

Cuando trabajamos con datos de encuestas que siguen un diseño muestral complejo y es posible aplicar la metodología de los q-weights  **(Pffeferman, 2011)**., 

1. **Ajuste del Modelo de Regresión a los Q-Weights:**
   Inicialmente, ajustamos un modelo de regresión lineal a los q-weights en R. Esto se hace utilizando la función `lm()`.

```{r}
fit_wgt <- lm(wk ~ Expenditure, data = encuesta)
```

2. **Obtención de Predicciones de Q-Weights:**
   A continuación, calculamos las predicciones de los q-weights para cada caso, utilizando las variables predictoras del modelo de regresión.

```{r}
qw <- predict(fit_wgt)
```

## Metodología de los Q_Weighting de pfefferman

3. **Creación de Nuevos Q-Weights:**
    Para obtener los q-weights ajustados, dividimos los weights originales por las predicciones calculadas en el paso anterior.

```{r}
   encuesta <- encuesta %>% mutate(wk1 = wk/qw)
```

4. **Definición de un Diseño Muestral con Q-Weights:**
   Usamos los nuevos q-weights obtenidos para definir un diseño muestral que refleje estos pesos.
   
```{r}
diseno_qwgt <- encuesta %>%
     as_survey_design(
       strata = Stratum,
       ids = PSU,
       weights = wk1,
       nest = TRUE)
```


## Modelos empleando los Q_Weighting

Estimando los coeficientes del modelo con los Q_Weighting de pfefferman

```{r}
library(tidyr)
fit_svy_qwgt <- svyglm(Income ~ Expenditure,
                       design = diseno_qwgt)
s1_qwgt <- summary(fit_svy_qwgt)
tidy(fit_svy_qwgt)
```

## Calculo del $R^2$ y $R_{adj}^{2}$
Obtenido el $R^2$

```{r}
WSST<- s0$dispersion
WSSE<- s1_qwgt$dispersion
(R2 = 1- WSSE/WSST)
```

Obtenido el  $R_{adj}^{2}$

```{r}
n = nrow(encuesta)
p = 2
(R2Adj = 1-((1-R2)*(n-1)/(n-1-1)))
```

## Modelos empleando los Q_Weighting

```{r,echo=FALSE}
modelsummary(list("svyglm(wgt)" = fit_svy, 
                  "svyglm(qwgt)" = fit_svy_qwgt), 
             output = "markdown", 
              statistic = c("p = ({p.value})"),
             title = "Comprando Modelos con Q Weighting",
             gof_omit = 'R2 Adj.|BIC|Log')
```



## Modelo propuesto
Después de realizar la comparación entre las diferentes formas de estimar los coeficientes del modelo se opta  por la metodología consolidadas en  `svyglm`
```{r, mod1, echo=TRUE, eval=FALSE, results='asis'}
diseno_qwgt %<>% mutate(Age2 = Age^2) 
mod_svy <- svyglm(
  Income ~ Expenditure + Zone + Sex + Age2 ,
                       design = diseno_qwgt)
s1_final <- summary(mod_svy)

stargazer(mod_svy, header = FALSE,single.row = T,
           title = "Modelo propuesto", 
           style = "ajps",  omit.stat=c("bic", "ll"))
```

## Resumen del modelo propuesto

```{r,mod1, echo=FALSE,eval=TRUE,  results='asis'}
```

## Diagnósticos de los residuales

En el diagnóstico de los modelos es crucial el análisis de los residuales. Estos análisis proporcionan, bajo el supuesto que el modelo ajustado es
adecuado, una estimación de los errores.

**Residuales Pearson**

Los residuales de Pearson como sigue *(Heeringa)*

$$
r_{pi}=\left(y_{i}-\mu_{i}\left(\hat{\boldsymbol{\beta}}_{\omega}\right)\right)\sqrt{\frac{\omega_{i}}{V\left(\hat{\mu}_{i}\right)}}
$$

Donde, $\mu_{i}$ es el valor esperado de $y_{i}$,  $\omega_{i}$ es la ponderación de la encuesta para el i-ésimo individuo del diseño muestral complejo, Por último, $V(μ_{i})$ es la función de varianza del resultado.

## Matriz **Hat** 

Otra definición que se debe tener en consideración para el análisis de los residuales es el de la matriz hat, la cual se estima como:

\begin{eqnarray*}
H & = & W^{1/2}X\left(X'WX\right)^{-1}X'W^{1/2}
\end{eqnarray*}

donde,


\begin{eqnarray*}
W & = & diag\left\{ \frac{\omega_{1}}{V\left(\mu_{1}\right)\left[g'\left(\mu_{1}\right)\right]^{2}},...,\frac{\omega_{n}}{V\left(\mu_{n}\right)\left[g'\left(\mu_{n}\right)\right]^{2}}\right\} 
\end{eqnarray*}

$W$ es una matriz diagonal de $n\times n$ y $g()$ es la función de enlace del modelo lineal generalizado.


## Distancia de cook

Diagnostica si la i-ésima observación es influyente en la estimación del modelo, por estar lejos del centro de masa de los datos. Se calcula de la siguiente manera:

$$
c_{i}=\frac{w_{i}^{*}w_{i}e_{i}^{2}}{p\phi V\left(\hat{\mu}_{i}\right)\left(1-h_{ii}\right)^{2}}\boldsymbol{x}_{i}^{t}\left[\widehat{Var}\left(U_{w}\left(\hat{\boldsymbol{\beta}}_{w}\right)\right)\right]^{-1}\boldsymbol{x}_{i}
$$

Los elementos de la ecuación son: 

-   $w_i^* =$ Pesos de la encuesta.
-   $w_i$ Elementos por fuera de la diagonal de la matriz hat
-   $e_i=$ residuales
-   $p=$ número de parámetros del Modelo de regresión.
-   $\phi =$ parámetro de dispersión en el glm
-   $\widehat{Var}\left(U_{w}\left(\hat{\boldsymbol{\beta}}_{w}\right)\right) =$ estimación de
    varianza linealizada de la ecuación de puntuación, que se utiliza para pseudo MLE en
    Modelos lineales generalizados ajustados a datos de encuestas de muestras complejas

## Distancia de cook

Una vez que se ha determinado el valor de la $D$ de Cook para un elemento de muestra
individual, se puede calcular la siguiente estadística de prueba para evaluar la
importancia de la estadística $D$:

$$
\frac{\left(df-p+1\right)\times c_{i}}{df} \doteq F_{\left(p,df-p\right)}
$$

donde $df=$ grados de liberta basados en el diseño. Por otro lado, la literatura como *Tellez (2016)*, *Heeringa* considera a las observaciones influyentes cuando $c_{i}$ sean mayores a 2 o 3.


## $D_fBeta_{(i)}$ 

Este estadístico mide el cambio en la estimación
del vector de coeficientes de regresión cuando la i-ésima observación
es eliminada. Se evalúa con la siguiente expresión:

$$
D_fBeta_{(i)} = \hat{\boldsymbol{\beta}}-\hat{\boldsymbol{\beta}}_{\left(i\right)}=\frac{\boldsymbol{A}^{-1}\boldsymbol{X}_{\left(i\right)}^{t}\hat{e}_{i}w_{i}}{1-h_{ii}}
$$

Donde $\boldsymbol{A} =\boldsymbol{X}^{t}\boldsymbol{WX}$ $\hat{\boldsymbol{\beta}}_{(i)}$ es el vector de parámetros estimados una vez se ha eliminado la
i-ésima observación, $h_{ii}$ es el correspondiente elemento de la diagonal de *H* y $\hat{e}_i$ es el residual de la i-ésima observación.

## $D_fBeta_{(i)}$ 

Otra forma de reescribir este estadístico en términos de la matriz $H$ es:

$$
D_fBetas_{\left(i\right)}=\frac{{c_{ji}e_{i}}\big/{\left(1-h_{ii}\right)}}{\sqrt{v\left(\hat{\boldsymbol{\beta}}_{j}\right)}}
$$

donde: 

  - $c_{ji}=$ es el ji-estimo elemento de $\boldsymbol{A}^{-1}w_{i}^{2}\boldsymbol{X}_{\left(i\right)}\boldsymbol{X}_{\left(i\right)}^{t}\boldsymbol{A}^{-1}$

 - El estimador de $v\left(\hat{B}_{j}\right)$ basado en el Modelo se obtiene como: $v_{m}\left(\hat{B}_{j}\right)=\hat{\sigma}\sum_{i=1}^{n}c_{ji}^{2}$ con $\hat{\sigma}=\sum_{i\in s}w_{i}e^2/ \left( \hat{N} - p \right)$ y $\hat{N} = \sum_{i \in s}w_{i}$

  - La i-ésima observación es influyente para $B_j$ si $\mid D_{f}Betas_{\left(i\right)j}\mid\geq\frac{z}{\sqrt{n}}$ con $z=$ 2 o 3

  - Como alternativa puede usar $t_{0.025,n-p}/\sqrt(n)$ donde $t_{0.025,n-p}$ es el percentil $97.5$


## Estadístico $D_{f}Fits_{\left(i\right)}$ 

Este estadístico mide el cambio en el ajuste del modelo cuando se elimina el registro i-ésimo. Se calcula de la siguiente manera:

$$
D_{f}Fits_{\left(i\right)}= \frac{h_{ii}e_{i}\big/\left(1-h_{ii}\right)}{\sqrt{v\left(\hat{\beta}_{j}\right)}}
$$

Donde, $\sqrt{v\left(\hat{\beta}_{j}\right)}$ puede ser aproximada por el diseño o el Modelo. La i-ésima observación se considera influyente en el ajuste del Modelo si
$\mid DfFits\left(i\right)\mid\geq z\sqrt{\frac{p}{n}}$ con $z =$ 2 o 3


## Practica en `R`

```{r, eval=FALSE}
par(mfrow = c(2,2))
plot(mod_svy)
```

![Analisis de residuales ](Imagenes/06_Regresion/05_Fig_residuales_Regresion.png){width="350"}

Como se puedo observar en el QQplot, hay evidencia gráfica de que los errores no se distribuyen según una distribución normal.


## Pruebas de normalidad

- $H_0$: Los errores proviene de una distribución normal.

- $H_1$: Los errores no proviene de una distribución normal.

Ahora, la librería `svydiags` esta pensada ayudar en el diagnostico de modelos de regresión lineal, siendo una extensión más para complementar el paquete `survey`. 

Con las librería svydiags se extraen los residuales estandarizados así: 

```{r, echo = TRUE, eval=TRUE}
library(svydiags)
stdresids = as.numeric(svystdres(mod_svy)$stdresids)
diseno_qwgt$variables %<>% 
  mutate(stdresids = stdresids)
```


## Histograma de los residuales

El primer análisis de normalidad se hace por medio del histograma. 
```{r, hist1, echo = TRUE, eval = FALSE}
p1_hist <- ggplot(data = diseno_qwgt$variables,
                  aes(x = stdresids)) +
  geom_histogram(
    aes(y = ..density..),
    colour = "black",
    bins = 30,
    fill = "blue",
    alpha = 0.3
  ) + geom_density(linewidth = 2, colour = "blue") +
  geom_function(fun = dnorm, colour = "red",
                linewidth = 2) +
  theme_cepal() + labs(y = "")
```
## Histograma de los residuales

![Histogrma de los residuales stdresids  ](Imagenes/06_Regresion/06_Fig_hist_residuales_Regresion.png){width="350"}


## Varianza constante
Agregando las predicciones a la base de datos. 
```{r, echo=TRUE, eval=TRUE,size="tiny"}
library(patchwork)
diseno_qwgt$variables %<>% 
  mutate(pred = predict(mod_svy))
g2 <- ggplot(data = diseno_qwgt$variables,
       aes(x = Expenditure, y = stdresids))+
  geom_point() +
  geom_hline(yintercept = 0) + theme_cepal()
g3 <- ggplot(data = diseno_qwgt$variables,
       aes(x = Age2, y = stdresids))+
  geom_point() +
  geom_hline(yintercept = 0) + theme_cepal()
```

## Varianza constante

```{r, plot6, echo=TRUE, eval=FALSE,size="tiny"}
g4 <- ggplot(data = diseno_qwgt$variables,
       aes(x = Zone, y = stdresids))+
  geom_point() +
  geom_hline(yintercept = 0) + theme_cepal()
g5 <- ggplot(data = diseno_qwgt$variables,
       aes(x = Sex, y = stdresids))+
  geom_point() +  geom_hline(yintercept = 0) +
  theme_cepal()

(g2|g3)/(g4|g5)
```

## Varianza constante

![Varianza constante](Imagenes/06_Regresion/07_Fig_Var_cosntante_Regresion.png){width="350"}


## Detección de observaciones influyentes (Distancia de cook)

La función `svyCooksD` pertenece a la librería `svydiags` permite tener el calculo de la Distancia de cook para el modelo ajustado. 

```{r, dcook, eval=FALSE}
 d_cook = data.frame(
   cook = svyCooksD(mod_svy), 
     id = 1:length(svyCooksD(mod_svy)))

ggplot(d_cook, aes(y = cook, x = id)) +
  geom_point() + 
  theme_bw(20)
```

## Detección de observaciones influyentes (Distancia de cook)

Como se puede observar, ninguna de las distancias de Cook’s es mayor a 3 por lo que, podemos decir que no existen observaciones influyentes.

![Distancia de cook](Imagenes/06_Regresion/08_Fig_Distancia_cook_Regresion.png){width="350"}

## Detección de observaciones influyentes ($D_{f}Betas_{\left(i\right)j}$)

 se desea observar si hay observaciones influyentes pero utilizando  $D_{f}Betas_{\left(i\right)j}$ se realiza con la función `svydfbetas` como se muestra a continuación:
  
```{r}
d_dfbetas = data.frame(t(svydfbetas(mod_svy)$Dfbetas))
colnames(d_dfbetas) <- paste0("Beta_", 1:5)
d_dfbetas %>% slice(1:5L)
```

## Detección de observaciones influyentes ($D_{f}Betas_{\left(i\right)j}$)

```{r eval=TRUE, echo=TRUE}
d_dfbetas$id <- 1:nrow(d_dfbetas)
d_dfbetas <- reshape2::melt(d_dfbetas, 
                            id.vars = "id")
cutoff <- svydfbetas(mod_svy)$cutoff
d_dfbetas %<>%
  mutate(
    Criterio = ifelse(
      abs(value) > cutoff, "Si", "No"))

tex_label <- d_dfbetas %>% 
  filter(Criterio == "Si") %>%
  arrange(desc(abs(value))) %>%
  slice(1:10L)
```

## Detección de observaciones influyentes ($D_{f}Betas_{\left(i\right)j}$)

```{r eval=FALSE, plot_dfbetas, echo=TRUE}
ggplot(d_dfbetas, aes(y = abs(value), x = id)) +
  geom_point(aes(col = Criterio)) +
  geom_text(data = tex_label,
            angle = 45,
            vjust = -1,
            aes(label = id)) +
  geom_hline(aes(yintercept = cutoff)) +
  facet_wrap(. ~ variable, nrow = 2) +
  scale_color_manual(
    values = c("Si" = "red", "No" = "black")) +
  theme_cepal()
```

## Detección de observaciones influyentes ($D_{f}Betas_{\left(i\right)j}$)

![Detección de observaciones influyentes $D_{f}Betas_{\left(i\right)j}$](Imagenes/06_Regresion/09_Fig_DFbetas_Regresion.png){width="400"}

## Detección de observaciones influyentes ($D_{f}Fits_{\left(i\right)}$)

```{r,plot_dffit, echo=TRUE, eval=FALSE}
d_dffits = data.frame(
  dffits = svydffits(mod_svy)$Dffits, 
  id = 1:length(svydffits(mod_svy)$Dffits))

cutoff <- svydffits(mod_svy)$cutoff

d_dffits %<>% mutate(
    C_cutoff = ifelse(abs(dffits) > cutoff, "Si", "No"))
ggplot(d_dffits, aes(y = abs(dffits), x = id)) +
  geom_point(aes(col = C_cutoff)) + 
  geom_hline(yintercept = cutoff) + 
   scale_color_manual(
    values = c("Si" = "red", "No" = "black"))+
  theme_cepal()
```

## Detección de observaciones influyentes ($D_{f}Fits_{\left(i\right)}$)

![Detección de observaciones influyentes $D_{f}Fits_{\left(i\right)}$](Imagenes/06_Regresion/10_Fig_DFfit_Regresion.png){width="400"}

## Matriz *H* 
  - La matriz asociada al Estimador de Pseudo Máxima Verosimilitud (PMLE) de $\hat{\boldsymbol{B}}$ es $\boldsymbol{H}=\boldsymbol{XA}^{-1}\boldsymbol{X}^{-t}\boldsymbol{W}$ cuya diagonal esta dado por $h_{ii} = \boldsymbol{x_{i}^tA}^{-1}\boldsymbol{x_{i}}^{-t}w_{i}$.

  - Una observación puede ser grande y, como resultado, influir en las predicciones, cuando un $x_i$ es considerablemente diferente del promedio ponderado $\bar{x}_w=\sum_{i\in s}w_{i}\boldsymbol{x_{i}}\big/\sum_{i\in s}w_i$.

## Detección de observaciones influyentes ($h_{ii}$)

```{r, hat, eval=FALSE, echo=TRUE}
vec_hat <- svyhat(mod_svy, doplot = FALSE)
d_hat = data.frame(hat = vec_hat, 
                    id = 1:length(vec_hat))
d_hat %<>% mutate(
  C_cutoff = ifelse(hat > (3 * mean(hat)),
                    "Si", "No"))

ggplot(d_hat, aes(y = hat, x = id)) +
  geom_point(aes(col = C_cutoff)) + 
  geom_hline(yintercept = (3 * mean(d_hat$hat))) +
  scale_color_manual(
    values = c("Si" = "red", "No" = "black"))+
  theme_cepal()
```

## Detección de observaciones influyentes ($h_{ii}$)
Se puede observar en el gráfico anterior que hay varias observaciones posiblemente influyentes en el conjunto de datos de la muestra de hogares.

![Detección de observaciones influyentes $h_{ii}$](Imagenes/06_Regresion/11_Fig_hat_Regresion.png){width="400"}

# Inferencia sobre los parámetros del Modelo

## Inferencia sobre $\beta_k$

- Inferencia sobre los parámetros del modelo es fundamental para evaluar la significancia de los parámetros estimados.

- Utilizamos un estadístico de prueba basado en la distribución "t-student" para evaluar la significancia de los parámetros $\beta_k$.


$$
t=\frac{\hat{\beta}_{k}-\beta_{k}}{se\left(\hat{\beta}_{k}\right)}\sim t_{n-p}
$$
Donde $p$ es el número de parámetros del modelo y $n$ el tamaño de la muestra de la encuesta.

- El estadístico de prueba compara la hipótesis nula $H_0: \beta_k = 0$ con la alternativa $H_1: \beta_k \neq 0$.

## Intervalo de confianza para $\beta_k$

- Podemos construir un intervalo de confianza al $(1-\alpha)\times100\%$ para $\beta_k$ usando el estadístico de prueba.


$$
\hat{\beta}_{k}\pm t_{1-\frac{\alpha}{2},\,df}\,se\left(\hat{\beta}_{k}\right)
$$

- Los grados de libertad ($df$) en una encuesta de hogares (muestras complejas) se calculan como el número de conglomerados finales de la primera etapa menos el número de estratos de la etapa primaria ($df = \sum_{h}a_h - H$).

- Las funciones `summary.svyglm` para las pruebas t y `confint.svyglm` para los intervalos de confianza

## Inferencia sobre $\beta_k$
El uso de `broom::tidy()` permite organizar la salida en la siguiente tabla 
```{r}
mod_svy %>% broom::tidy()
```

## Intervalo de confianza para $\beta_k$

Se puede observar que, con una confianza del 95\% el único parámetro significativo del modelo es Expenditure y ese mismo resultado lo reflejan los intervalos de confianza.

```{r}
survey:::confint.svyglm(mod_svy)
```

## Estimación de una observación

- Los modelos de regresión lineal se utilizan para dos propósitos principales: explicar la variable respuesta en función de las covariables y predecir valores de la variable de interés.

- Para realizar predicciones, utilizamos la fórmula
$$\hat{E}(y_i | \boldsymbol{x}_{obs,i}) = \boldsymbol{x}_{obs,i} \hat{\boldsymbol{\beta}}$$, 

donde $\boldsymbol{x}_{obs,i}$ representa las covariables de una observación no incluida en la muestra.

- La varianza de la estimación se calcula como $$var(\hat{E}(y_i | x_{obs,i})) = x'_{obs,i}cov(\hat{\boldsymbol{\beta}})x{}_{obs,i}$$.

## Estimación de una observación

```{r, echo=FALSE}
 model.matrix(mod_svy) %>%
  as.data.frame()%>% slice(1:7)
```

\begin{eqnarray*}
\hat{E}(y_{i}\mid\boldsymbol{x}_{obs,i}) & = & 67.0 + 1.21x_{1i} +67.1x_{2i}+21.3x_{3i}+0.00846x_{4i}\\
       &=& 67.0 +1.21(346.3) + 67.1(0) + 21.3(1) + 0.00846(68^2)\\
       &=&  546.4
\end{eqnarray*}

## Estimando el IC de predicción

Para calcular la varianza de la estimación, primero se deben obtener las varianzas de la estimación de los parámetros: 

```{r}
vcov(mod_svy)
```

## Estimando el IC de predicción

Ahora bien, se procede a realizar los cálculos como lo indica la expresión mostrada anteriormente:

```{r, echo=TRUE}
xobs <- model.matrix(mod_svy) %>%
        data.frame() %>% slice(1) %>% as.matrix()

cov_beta <- vcov(mod_svy) %>% as.matrix()

as.numeric(xobs %*% cov_beta %*% t(xobs))
```

## Intervalo de confianza para la predicción

Si el objetivo ahora es calcular el intervalo de confianza para la predicción se utiliza la siguiente ecuación:

$$
\boldsymbol{x}_{obs,i}\hat{\beta}\pm t_{\left(1-\frac{\alpha}{2},n-p\right)}\sqrt{var\left(\hat{E}\left(y_{i}\mid\boldsymbol{x}_{obs,i}\right)\right)}
$$


Para realizar los cálculos en R, se utiliza la función `confint` y `predict` como sigue:

```{r,pred01, echo=TRUE,eval=TRUE}
pred <- data.frame(predict(mod_svy, type = "response"))
pred_IC <- data.frame(confint(predict(mod_svy, type = "response")))
colnames(pred_IC) <- c("Lim_Inf", "Lim_Sup")
pred <- bind_cols(pred, pred_IC)
```

## Intervalo de confianza para la predicción
```{r}
pred %>% slice(1:10)
```

## Intervalo de confianza para la predicción

Ahora, de manera gráfica las predicciones e intervalos se vería de la siguiente manera:

```{r, plot_pred, echo=TRUE,eval=FALSE}
pred$Expenditure <- encuesta$Expenditure
pd <- position_dodge(width = 0.2)
ggplot(pred %>% slice(1:100L),
       aes(x = Expenditure , y = response)) +
  geom_errorbar(aes(ymin = Lim_Inf,
                    ymax = Lim_Sup),
                width = .1,
                linetype = 1) +
  geom_point(size = 2, position = pd) +
  theme_bw()
```

## Intervalo de confianza para la predicción

![Intervalo de confianza para la predicción](Imagenes/06_Regresion/12_Fig_IC_pred_Regresion.png){width="400"}

## Predicción fuera  fuera del rango de valores.

Por último, si el interés es hacer una predicción fuera del rango de valores que fue capturado en la muestra. Para esto, supongamos que se desea predecir:

```{r}
datos_nuevos <- data.frame(Expenditure = 1600, 
                           Age2 = 40^2, Sex = "Male", 
                           Zone = "Urban")
```

La varianza para la predicción se hace siguiendo la siguiente ecuación:

$$
var\left(\hat{E}\left(y_{i}\mid\boldsymbol{x}_{obs,i}\right)\right)=\boldsymbol{x}_{obs,i}^{t}cov\left(\boldsymbol{\beta}\right)\boldsymbol{x}_{obs,i} + \hat{\sigma}^2_{yx}
$$

## Predicción fuera  fuera del rango de valores.

Se construye la matriz de observaciones y se calcula la varianza como sigue:

```{r}
x_noObs = matrix(c(1,1600,1,1,40^2),nrow = 1)
as.numeric(sqrt(x_noObs%*%cov_beta%*%t(x_noObs)))
```

Por último, el intervalo de confianza sigue la siguiente ecuación:

$$
\boldsymbol{x}_{obs,i}\hat{\beta}\pm t_{\left(1-\frac{\alpha}{2},n-p\right)}\sqrt{var\left(\hat{E}\left(y_{i}\mid\boldsymbol{x}_{obs,i}\right)\right)+\hat{\sigma}_{yx}^{2}}
$$

## Predicción fuera  fuera del rango de valores.

En `R` se hace la predicción de la siguiente manera:

```{r}
predict(mod_svy, newdata = datos_nuevos, type =  "link") %>% 
  data.frame()
```

y el intervalo:
```{r}
confint(predict(mod_svy, newdata = datos_nuevos))
```


# Procesando múltiples bases. 

## Lectura de múltiples bases

Para realizar la lectura de múltiples bases debemos conocer las rutas donde estas estas guardadas para ello empleamos la función `file.list` del paquete base, que nos permite tener un listado completo de los archivos.


```{r, tab_mult0, eval=FALSE}
library(stringr)
(data_path <- list.files("V:/DAT/BADEHOG/BADEHOG_N/Estandarizadas/",
                         full.names = TRUE, pattern = "2020") %>% 
  tibble(path = .) %>%  
   mutate(
     Pais = basename(path) %>% str_extract("^[A-Z]+")))

```
*Note* que utiliza la función `gsub` para separar el nombre del país de la ruta.


## Lectura de múltiples bases

```{r, tab_mult0, eval=TRUE, echo=FALSE}
```


## Lectura de encuestas

Para la lectura de los archivos, se procede de la siguiente forma.

```{r, eval=FALSE}
require(purrr)
require(haven)
data_path %<>% 
  mutate(encuesta = path %>% map(~read_dta(.x) %>% 
           transmute(upm = `_upm`,
           estrato =`_estrato`,
           sexo, area_ee,lp,li,ingcorte,
           fep =`_fep`)))
```

La función `map` es utilizada para trabajar con los elementos de una lista. 
Las variables seleccionadas son sexo, área geográfica (area_ee), Linea de pobreza (lp), Linea de indigencia (li), Íngreso persona (ingcorte) y factor de expansión por persona (fep).

## Lectura de encuestas (resultado)

![Lectura de encuestas](Imagenes/06_Regresion/13_Lectura_multiple_base.PNG){width="450"}

El resultado es objeto tipo `tibble` el cual permite observar de forma compacta el contenido de una lista e indica el tipo y tamaño de cada objeto en la contenido en la lista.

## Definir el diseño

Ahora se debe definir un diseño para cada encuesta, para nuestro ejemplo se define el diseño muestral.

```{r}
options(survey.lonely.psu="adjust")
data_path <- readRDS("Imagenes/06_regresion/15_data_path.rds")
data_path %<>% mutate(
  diseno = encuesta %>%
           map(~as_survey_design(.data = .x,
               ids = upm,
               strata = estrato, 
               weights = fep,
               nest = T
               )))
```

## Definir el diseño (resultado)

![Diseño muestral para multiples bases](Imagenes/06_Regresion/14_Diseno_multiple base.PNG){width="500"}

## Estimación de los coeficiente del modelo en multiples encuestas

```{r, tab_mult1, eval=FALSE}
library(tidyr)
data_path %>% mutate(
  model = map(diseno,
              ~svyglm(ingcorte~sexo+area_ee,.x) %>% 
               coef() %>%
               data.frame(estimado = .) %>% 
               tibble::rownames_to_column(var = "Coef"))) %>% 
  dplyr::select(pais,model) %>% unnest(model) 
```

## Estimación de los coeficiente del modelo en multiples encuestas (Resultado)

```{r, tab_mult1, eval=TRUE, echo=FALSE}
```



## Alternativa para el procesamiento de múltiples archivos.

En ocasiones solo se desea obtener un resultado rápido para realizar un reporte o una comparación rápida de información, en estas ocasiones no es necesario guardar en la memoria de `R` toda la encuesta, por esta razón se ilustra una alternativa de procesamiento de múltiples archivos.  

- **Paso 1** Leer archivo y organizar encuestas. 
- **Paso 2** Definir diseño muestral. 
- **Paso 3** Procesar información.
- **Paso 4** Organizar y presentar resultados. 

## Creando función para el procesamiento de múltiples archivos.


```{r}
options(survey.lonely.psu="adjust")
library(tidyr)
model_aux <- function(input_file){
  ## Paso 1 
  encuesta <- read_dta(input_file) %>% 
    transmute(upm = `_upm`,   estrato =`_estrato`,
              sexo, area_ee,lp,li,ingcorte, fep =`_fep`)
  ## Paso 2 
  diseno <- as_survey_design(.data = encuesta,
                             ids = upm,
                             strata = estrato, 
                             weights = fep,
                             nest = T)
  ## Paso 3 
  s <- svyglm(ingcorte~sexo+area_ee,diseno) 
  tidy(s)
}

```

## Procesando encuestas múltiples
Para el *Paso 4* realizamos la siguiente sintaxis.

```{r,tab_mult7, echo=TRUE, eval=FALSE}
setNames(data_path$path, data_path$pais) %>% 
  map_df(~model_aux(.x), .id = "País" )  %>% 
  saveRDS("Imagenes/06_Regresion/16_modelo_multiples.rds")
```

## Procesando encuestas múltiples
Los resultados se muestran en el orden de lectura de los archivos

```{r,echo=FALSE}
readRDS("Imagenes/06_Regresion/16_modelo_multiples.rds")
```



## ¡Gracias!

::: yellow
*Email*: [andres.gutierrez\@cepal.org](mailto:andres.gutierrez@cepal.org){.email}
:::




