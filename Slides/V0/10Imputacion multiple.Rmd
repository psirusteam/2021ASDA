---
title: "Análisis de encuestas de hogares con R"
subtitle: "Modulo 9: Métodos de imputación"
date: "CEPAL - Unidad de Estadísticas Sociales"
output:
  beamer_presentation:
    colortheme: dove
    fonttheme: default
    incremental: yes
    theme: Berkeley
    toc: yes
    slide_level: 2
    #highlight: pygments
  ioslides_presentation:
    incremental: yes
    widescreen: yes
    toc: yes
  slidy_presentation:
    incremental: yes
Email: andres.gutierrez@cepal.org
editor_options:
  markdown:
    wrap: 90
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = FALSE, warning = FALSE, message = FALSE, error = FALSE)
options(digits = 4)
options(tinytex.verbose = TRUE)
library (survey)
library(srvyr)
library(convey)
library(TeachingSampling)
library(printr)
library(stargazer)
library(broom)
library(jtools)
library(modelsummary)
library(patchwork)
library(ggplot2)
#rm(list = ls())
```

## Introducción valores perdidos

-   Sea $\boldsymbol{X}_{n \times p} = x_{ij}$ una matriz completa (sin valores
    perdidos), de tal forma que $X_{ij}$ es el valor de la variable $j$,
    $j=1, \dots, p$ en el caso $i$, $i=1, \dots, n$.

-   Sea $\boldsymbol{M}_{n \times p} = m_{ij}$, donde $m_{ij} = 1$ si $x_{ij}$
    es un dato perdido y $m_{ij}=0$ si $x_{ij}$ está presente.

-   Note que la matriz $M$ describe el patrón de missing, y su media marginal de
    columna, puede ser interpretada como la probabilidad de que $x_{ij}$ sea
    missing.

## Introducción valores perdidos

-   La matriz $\boldsymbol{M}_{n \times p}$ presenta un comportamiento
    completamente al azar (MCAR): si la probabilidad de respuesta es
    independiente de las variables observadas y de las no observadas
    completamente. El mecanismo de pérdida es ignorable tanto para inferencias
    basadas en muestreo como en máxima verosimilitud.

-   Los valores de la matriz $\boldsymbol{M}_{n \times p}$ son al azar (MAR): si
    la probabilidad de respuesta es independiente de las variables no observadas
    completamente y no de las observadas. El mecanismo de pérdida es ignorable
    para inferencias basadas en máxima verosimilitud.

-   Los datos no están perdidos al azar (MNAR): si la probabilidad de respuesta
    no es independiente de las variables no observadas completamente y
    posiblemente, también, de las observadas El mecanismo de pérdida es no
    ignorable.

## Introducción valores perdidos

![](Imagenes/Cap%208/fig1.png){width="250"}
![](Imagenes/Cap%208/fig2.png){width="250"}

## Lectura de la base

```{r}
encuesta <- readRDS("../Data/encuesta.rds") %>% 
  filter(Age >= 15)
(tab_antes <- prop.table(table(encuesta$Employment)))
(med_antes <- mean(encuesta$Income, na.rm = TRUE))
```

## Creando valores perdidos

```{r}
set.seed(1234)
encuesta_MCAR <-  sample_frac(encuesta, 0.8 )
dat_plot <- bind_rows(
  list(encuesta_MCAR = encuesta_MCAR, 
       encuesta = encuesta), .id = "Caso"  )
```

## Creando valores perdidos

```{r, MCAR1, echo=TRUE, eval=FALSE}
p1 <- ggplot(dat_plot, aes(x=Zone, y = Income)) + 
  geom_boxplot() + facet_grid(.~Caso) + theme_bw()+
  geom_hline(yintercept = mean(encuesta$Income), 
             col = "red")

p2 <- ggplot(dat_plot, aes(x=Sex, y = Income)) + 
  geom_boxplot() + facet_grid(.~Caso) +theme_bw()+
  geom_hline(yintercept = mean(encuesta$Income), 
             col = "red")
library(patchwork)
p1|p2
```

## Creando valores perdidos

```{r, MCAR1, echo=FALSE, eval=TRUE}
```

## Creando valores perdidos

```{r, MCAR2, echo=TRUE, eval=FALSE}
p1 <- ggplot(dat_plot, aes(x = Income, fill = Caso)) + 
  geom_density(alpha = 0.3) + theme_bw() +
  theme(legend.position = "bottom") +
  geom_vline(xintercept = mean(encuesta$Income), 
             col = "red")

p2 <- ggplot(dat_plot, aes(x = Income, fill = Caso)) + 
  geom_density(alpha = 0.3) + facet_grid(.~Sex) + 
  theme_bw()+ 
  geom_vline(xintercept = mean(encuesta$Income), 
             col = "red") +
  theme(legend.position = "none")
(p1/p2)
```

## Creando valores perdidos

```{r, MCAR2, echo=FALSE, eval=TRUE}
```

## Creando valores perdidos

```{r, MCAR3, echo=TRUE, eval=FALSE}
p1 <- ggplot(dat_plot, aes(x = Expenditure, fill = Caso)) + 
  geom_density(alpha = 0.3) + theme_bw() +
  theme(legend.position = "bottom") +
  geom_vline(xintercept = mean(encuesta$Expenditure), 
             col = "red")

p2 <- ggplot(dat_plot, aes(x = Expenditure, fill = Caso)) + 
  geom_density(alpha = 0.3) + facet_grid(.~Sex) + 
  theme_bw()+ 
  geom_vline(xintercept = mean(encuesta$Expenditure), 
             col = "red") +
  theme(legend.position = "none")
(p1/p2)
```

## Creando valores perdidos

```{r, MCAR3, echo=FALSE, eval=TRUE}
```

## Creando valores perdidos

```{r}
library(TeachingSampling)
set.seed(1234)
temp_estrato <- paste0(encuesta$Zone, encuesta$Sex) 
table(temp_estrato)
sel <- S.STSI(S = temp_estrato, 
              Nh = c(469,411,510,390),
              nh = c(20, 380, 20,280))
encuesta_MAR <- encuesta[-sel,]
dat_plot2 <- bind_rows(
  list(encuesta_MAR = encuesta_MAR,
       encuesta = encuesta), .id = "Caso"  )

```

## Creando valores perdidos

```{r, MAR1, echo=TRUE, eval=FALSE}
p1 <- ggplot(dat_plot2, aes(x= Caso, y = Expenditure)) + 
   geom_hline(yintercept = mean(encuesta$Expenditure), 
              col = "red") + 
  geom_boxplot() +
  facet_grid(Zone~Sex) + theme_bw()

p1
```

## Creando valores perdidos

```{r, MAR1, echo=FALSE, eval=TRUE}
```

## Creando valores perdidos

```{r, MAR2, echo=TRUE, eval=FALSE}
p1 <- ggplot(dat_plot2, aes(x = Income, fill = Caso)) + 
 geom_density(alpha = 0.3) + theme_bw() +
  theme(legend.position = "bottom") +
  geom_vline(xintercept = mean(encuesta$Income), 
             col = "red")

p2 <- ggplot(dat_plot2, aes(x = Income, fill = Caso)) + 
  facet_grid(.~Sex) +
  geom_density(alpha = 0.3) + theme_bw() +
  theme(legend.position = "none") +
  geom_vline(xintercept = mean(encuesta$Income), 
             col = "red")
p1/p2
```

## Creando valores perdidos

```{r, MAR2, echo=FALSE, eval=TRUE}
```

## Creando valores perdidos

```{r, MAR3, echo=TRUE, eval=FALSE}
p1 <- ggplot(dat_plot2, 
             aes(x = Expenditure, fill = Caso)) + 
 geom_density(alpha = 0.3) + theme_bw() +
  theme(legend.position = "bottom") +
  geom_vline(
    xintercept = mean(encuesta$Expenditure), 
             col = "red")

p2 <- ggplot(dat_plot2, 
             aes(x = Expenditure, fill = Caso)) + 
  facet_grid(.~Sex) +
  geom_density(alpha = 0.3) + theme_bw() +
  theme(legend.position = "none") +
  geom_vline(
    xintercept = mean(encuesta$Expenditure), 
             col = "red")
p1/p2
```

## Creando valores perdidos

```{r, MAR3, echo=FALSE, eval=TRUE}
```

## Creando valores perdidos

```{r}
encuesta_MNAR <- encuesta %>% 
  arrange((Income)) %>% 
  slice(1:1300L)

dat_plot3 <- bind_rows(
  list(encuesta_MNAR = encuesta_MNAR,
       encuesta = encuesta), .id = "Caso"  )

```

## Creando valores perdidos

```{r, MNAR1, echo=TRUE, eval=FALSE}
p1 <- ggplot(dat_plot3, aes(x = Income, fill = Caso)) + 
  geom_density(alpha = 0.2) + theme_bw() +
   theme(legend.position = "bottom") +
  geom_vline(
    xintercept = mean(encuesta$Income), 
             col = "red") +
  geom_vline(
    xintercept = mean(encuesta_MNAR$Income), 
             col = "blue")
p1
```

## Creando valores perdidos

```{r, MNAR1, echo=FALSE, eval=TRUE}
```

## Creando valores perdidos

```{r, MNAR2, echo=TRUE, eval=FALSE}
p1 <- ggplot(dat_plot3, 
             aes(x = Expenditure, fill = Caso)) + 
  geom_density(alpha = 0.2) + theme_bw() +
   theme(legend.position = "bottom") +
  geom_vline(
    xintercept = mean(encuesta$Expenditure), 
             col = "red") +
  geom_vline(
    xintercept = mean(encuesta_MNAR$Expenditure), 
             col = "blue")
p1
```

## Creando valores perdidos

```{r, MNAR2, echo=FALSE, eval=TRUE}
```

## Creando valores perdidos

```{r, MNAR3, echo=TRUE, eval=FALSE}
p1 <- ggplot(dat_plot3, aes(x= Caso, y = Income)) + 
   geom_hline(yintercept = mean(encuesta$Income),
              col = "red") +  geom_boxplot() +
  facet_grid(Zone~Sex) + theme_bw()

p1
```

```{r, echo=FALSE, eval=FALSE}
saveRDS(list(encuesta_MAR = encuesta_MAR, 
             encuesta_MCAR = encuesta_MCAR, 
             encuesta_MNAR = encuesta_MNAR),
        file = "../Data/encuesta_imp.rds")
```

## Creando valores perdidos

```{r, MNAR3,  echo=FALSE, eval=TRUE}
```

## Creando valores perdidos

```{r}
encuesta <- full_join(
  encuesta,
  encuesta_MCAR %>% 
    select(HHID, PersonID, Income, Employment) %>%
    mutate(
      Income_missin = Income,
      Employment_missin = Employment,
      Employment = NULL,
      Income = NULL
    )
)
```

## Imputación de valores perdidos.

```{r}
encuesta %>% group_by(Zone) %>% 
  summarise(Income = sum(is.na(Income_missin) / n()))

encuesta %>% group_by(Sex) %>% 
  summarise(Income = sum(is.na(Income_missin) / n()))


```

## Imputación por la media no condicional.

Consiste en asignar el promedio de la totalidad de los datos a los valores
faltantes, este método no afecta el promedio, pero si afecta la variabilidad, el
sesgo y los percentiles.

## Imputación por la media no condicional.

```{r}
promedio <- mean(encuesta$Income_missin, na.rm = TRUE)
encuesta %<>%
  mutate(
    Income_imp = ifelse(is.na(Income_missin), 
                           promedio, Income_missin))
sum(is.na(encuesta$Income_imp))
```

## Imputación por la media no condicional.

```{r, Media_1, echo=TRUE, eval=FALSE}
## Ordenando la base para gráfica 
dat_plot4 <- tidyr::gather(
  encuesta %>% select(Zone,Sex,Income, Income_imp),
  key = "Caso", value = "Income2", -Zone,-Sex)

p1 <- ggplot(dat_plot4, aes(x = Income2, fill = Caso)) + 
  geom_density(alpha = 0.2) + theme_bw() +
   theme(legend.position = "bottom") +
  geom_vline(
    xintercept = mean(encuesta$Income), 
             col = "red") +
  geom_vline(
    xintercept = mean(encuesta$Income_imp), 
             col = "blue")
p1
```

## Imputación por la media no condicional.

```{r, Media_1, echo=FALSE, eval=TRUE}
```

## Imputación por la media no condicional.

```{r, Media_2, echo=TRUE, eval=FALSE}
p1 <- ggplot(dat_plot4, aes(x= Caso, y = Income2)) + 
   geom_hline(yintercept = mean(encuesta$Income),
              col = "red") +  geom_boxplot() +
  facet_grid(Zone~Sex) + theme_bw()

p1
```

## Imputación por la media condicional.

Una variante del procedimiento anterior consiste en formar categorías a partir
de covariables correlacionadas con la variable de interés, e imputar los datos
omitidos con observaciones provenientes de la submuestra que comparte
características comunes

## Imputación por la media condicional.

```{r, Media_2, echo=FALSE, eval=TRUE}
```

## Imputación por la media condicional.

```{r}
encuesta %<>% group_by(Stratum) %>%
  mutate(
    Income_imp = ifelse(is.na(Income_missin),
     mean(Income_missin, na.rm = TRUE),
     Income_missin)) %>% data.frame()
sum(is.na(encuesta$Income_imp))
encuesta %<>%
  mutate(
    Income_imp = ifelse(is.na(Income_imp), 
                           promedio, Income_imp))
sum(is.na(encuesta$Income_imp))
```

## Imputación por la media condicional.

```{r}
encuesta %>% summarise(
  Income_ = mean(Income),
  Income_sd = sd(Income),
  Income_imp_ = mean(Income_imp),
  Income_imp_sd = sd(Income_imp))
```

## Imputación por la media condicional.

```{r}
encuesta %>%group_by(Zone) %>%  summarise(
  Income_ = mean(Income),
  Income_sd = sd(Income),
  Income_imp_ = mean(Income_imp),
  Income_imp_sd = sd(Income_imp))
```

## Imputación por la media condicional.

```{r}
encuesta %>%group_by(Sex) %>%  summarise(
  Income_ = mean(Income),
  Income_sd = sd(Income),
  Income_imp_ = mean(Income_imp),
  Income_imp_sd = sd(Income_imp))
```

## Imputación por la media condicional.

```{r, Media_3, echo=TRUE, eval=FALSE}
## Ordenando la base para gráfica 
dat_plot5 <- tidyr::gather(
  encuesta %>% select(Zone,Sex,Income, Income_imp),
  key = "Caso", value = "Income2", -Zone,-Sex)

p1 <- ggplot(dat_plot5, aes(x = Income2, fill = Caso)) + 
  geom_density(alpha = 0.2) + theme_bw() +
   theme(legend.position = "bottom") +
  geom_vline(
    xintercept = mean(encuesta$Income), 
             col = "red") +
  geom_vline(
    xintercept = mean(encuesta$Income_imp), 
             col = "blue")
p1
```

## Imputación por la media condicional.

```{r, Media_3, echo=FALSE, eval=TRUE}
```

## Imputación por la media condicional.

```{r, Media_4, echo=TRUE, eval=FALSE}
p1 <- ggplot(dat_plot5, aes(x= Caso, y = Income2)) + 
   geom_hline(yintercept = mean(encuesta$Income),
              col = "red") +  geom_boxplot() +
  facet_grid(Zone~Sex) + theme_bw()
p1
```

## Imputación por la media condicional.

```{r, Media_4, echo=FALSE, eval=TRUE}
```

## Imputación por Hot-deck y Cold-deck

**Hot-deck** La imputación *hot deck* consiste en reemplazar los valores
faltantes de una o más variables para un no encuestado (llamado receptor) con
valores observados de un encuestado (el donante) que es similar al no encuestado
con respecto a las características observadas en ambos casos.

**Cold-deck** A este método lo llamamos *Cold-deck* por analogía con *Hot-deck*.
El método consiste en reemplazar el valor faltante por valores de una fuente no
relacionada con el conjunto de datos en consideración. Por ejemplo, se pide a un
grupo de personas diligenciar una cuestionario sobre hábitos de lectura y que
cinco personas no respondieron a un ítem. Entonces, la imputación de la
respuesta por *Cold-deck* es sustituir las respuestas con información de un
donante similar en una encuesta realizada anteriormente.

## Imputación por hot-deck

```{r}
donante <- which(!is.na(encuesta$Income_missin))
receptor <- which(is.na(encuesta$Income_missin))
encuesta$Income_imp <- encuesta$Income_missin
set.seed(1234)
for(ii in receptor){
don_ii <- sample(x = donante, size = 1)
encuesta$Income_imp[ii] <- 
  encuesta$Income_missin[don_ii]  
}
sum(is.na(encuesta$Income_imp))
```

## Imputación por hot-deck

```{r}
encuesta %>% summarise(
  Income_ = mean(Income),
  Income_sd = sd(Income),
  Income_imp_ = mean(Income_imp),
  Income_imp_sd = sd(Income_imp))
```

## Imputación por hot-deck

```{r}
encuesta %>%group_by(Zone) %>%  summarise(
  Income_ = mean(Income),
  Income_sd = sd(Income),
  Income_imp_ = mean(Income_imp),
  Income_imp_sd = sd(Income_imp))
```

## Imputación por hot-deck

```{r}
encuesta %>%group_by(Sex) %>%  summarise(
  Income_ = mean(Income),
  Income_sd = sd(Income),
  Income_imp_ = mean(Income_imp),
  Income_imp_sd = sd(Income_imp))
```

## Imputación por hot-deck

```{r, hot_deck_1, echo=TRUE, eval=FALSE}
## Ordenando la base para gráfica 
dat_plot6 <- tidyr::gather(
  encuesta %>% select(Zone,Sex,Income, Income_imp),
  key = "Caso", value = "Income2", -Zone,-Sex)

p1 <- ggplot(dat_plot6, aes(x = Income2, fill = Caso)) + 
  geom_density(alpha = 0.2) + theme_bw() +
   theme(legend.position = "bottom") +
  geom_vline(
    xintercept = mean(encuesta$Income), 
             col = "red") +
  geom_vline(
    xintercept = mean(encuesta$Income_imp), 
             col = "blue")
p1
```

## Imputación por hot-deck

```{r, hot_deck_1, echo=FALSE, eval=TRUE}
```

## Imputación por hot-deck

```{r, hot_deck_2, echo=TRUE, eval=FALSE}
p1 <- ggplot(dat_plot6, aes(x= Caso, y = Income2)) + 
   geom_hline(yintercept = mean(encuesta$Income),
              col = "red") +  geom_boxplot() +
  facet_grid(Zone~Sex) + theme_bw()
p1
```

## Imputación por la media condicional.

```{r, hot_deck_2, echo=FALSE, eval=TRUE}
```

## Imputación por hot-deck

```{r}
donante <- which(!is.na(encuesta$Income_missin))
receptor <- which(is.na(encuesta$Income_missin))
encuesta$Employment_imp <- encuesta$Employment_missin
(prop <- prop.table(
  table(na.omit(encuesta$Employment_missin))))

set.seed(1234)
imp <- sample(size = length(receptor),
  c("Unemployed", "Inactive","Employed"),
       prob = prop, replace = TRUE     )
encuesta$Employment_imp[receptor] <- imp 
sum(is.na(encuesta$Employment_imp))
```

## Imputación por hot-deck

```{r}
prop.table(
  table(encuesta$Employment_missin, useNA = "a"))

prop.table(
  table(encuesta$Employment_imp, useNA = "a"))

```

## Imputación por hot-deck

```{r}
prop.table( table(encuesta$Zone, encuesta$Employment_missin, 
        useNA = "a")) %>% addmargins()

prop.table( table(encuesta$Zone, encuesta$Employment_imp,
        useNA = "a")) %>% addmargins()
```

## Imputación por hot-deck

```{r}
prop.table( table(encuesta$Sex, encuesta$Employment_missin, 
        useNA = "a")) %>% addmargins()

prop.table( table(encuesta$Sex, encuesta$Employment_imp,
        useNA = "a")) %>% addmargins()
```

## Imputación por regresión

Se ajusta un modelo lineal que describa a $y$, variable a imputar, para un
conjunto $X$ de variables auxiliares que se deben disponer. Resuelve el problema
de la distorsión de la distribución de la variable a imputar, pero puede crear
inconsistencias dentro de la base de datos, pues podría obtenerse valores
"imposibles", ya que el valor $y$ es obtenido de variables auxiliares.

## Imputación por regresión

```{r, warning=FALSE, message=FALSE}
require(nnet)
encuesta$Income_imp <- encuesta$Income_missin
encuesta$Employment_imp <- encuesta$Employment_missin
encuesta_obs <- filter(encuesta, 
                       !is.na(Income_missin))
encuesta_no_obs <- filter(encuesta, 
                          is.na(Income_missin))
mod <- lm(Income~Zone + Sex +Expenditure,
          data = encuesta_obs)

mod.mult <- multinom(
             Employment~Zone + Sex +Expenditure,
             data = encuesta_obs)
```

## Imputación por regresión

```{r}
imp <- predict(mod, encuesta_no_obs)
imp.mult <- predict(mod.mult, encuesta_no_obs, 
                    type =  "class")
encuesta_no_obs$Income_imp <- imp
encuesta_no_obs$Employment_imp <- imp.mult
encuesta <- bind_rows(encuesta_obs,encuesta_no_obs)
```

## Imputación por regresión

```{r}
prop.table(
  table(encuesta$Employment_missin, useNA = "a"))

prop.table(
  table(encuesta$Employment_imp, useNA = "a"))

```

## Imputación por regresión

```{r}
prop.table( table(encuesta$Zone, encuesta$Employment_missin, 
        useNA = "a")) %>% addmargins()

prop.table( table(encuesta$Zone, encuesta$Employment_imp,
        useNA = "a")) %>% addmargins()
```

## Imputación por regresión

```{r}
prop.table( table(encuesta$Sex, encuesta$Employment_missin, 
        useNA = "a")) %>% addmargins()

prop.table( table(encuesta$Sex, encuesta$Employment_imp,
        useNA = "a")) %>% addmargins()
```

## Imputación por regresión

```{r}
encuesta %>% summarise(
  Income_ = mean(Income),
  Income_sd = sd(Income),
  Income_imp_ = mean(Income_imp),
  Income_imp_sd = sd(Income_imp))
```

## Imputación por regresión

```{r}
encuesta %>%group_by(Zone) %>%  summarise(
  Income_ = mean(Income),
  Income_sd = sd(Income),
  Income_imp_ = mean(Income_imp),
  Income_imp_sd = sd(Income_imp))
```

## Imputación por regresión

```{r}
encuesta %>%group_by(Sex) %>%  summarise(
  Income_ = mean(Income),
  Income_sd = sd(Income),
  Income_imp_ = mean(Income_imp),
  Income_imp_sd = sd(Income_imp))
```

## Imputación por regresión

```{r, regresion_1, echo=TRUE, eval=FALSE}
## Ordenando la base para gráfica 
dat_plot7 <- tidyr::gather(
  encuesta %>% select(Zone,Sex,Income, Income_imp),
  key = "Caso", value = "Income2", -Zone,-Sex)

p1 <- ggplot(dat_plot7, aes(x = Income2, fill = Caso)) + 
  geom_density(alpha = 0.2) + theme_bw() +
   theme(legend.position = "bottom") +
  geom_vline(
    xintercept = mean(encuesta$Income), 
             col = "red") +
  geom_vline(
    xintercept = mean(encuesta$Income_imp), 
             col = "blue")
p1
```

## Imputación por regresión

```{r, regresion_1, echo=FALSE, eval=TRUE}
```

## Imputación por regresión

```{r, regresion_2, echo=TRUE, eval=FALSE}
p1 <- ggplot(dat_plot7, aes(x= Caso, y = Income2)) + 
   geom_hline(yintercept = mean(encuesta$Income),
              col = "red") +  geom_boxplot() +
  facet_grid(Zone~Sex) + theme_bw()
p1
```

## Imputación por regresión

```{r, regresion_2, echo=FALSE, eval=TRUE}
```

## Imputación por el vecino más cercano

-   **Paso 1**: Definir una magnitud de distancia (Distancia euclidiana,
    k-media, K-Medioides).
-   **Paso 2**: Para la $i$-ésimo elemento identificar el donante, cual será el
    más cercano al receptor según la magnitud de distancia previamente definida.
-   **Paso 3**: Se imputa el valor faltante con la información del donante
    identificado previamente.

## Imputación por el vecino más cercano

```{r}
encuesta$Income_imp <- encuesta$Income_missin
encuesta$Employment_imp <- encuesta$Employment_missin
encuesta_obs <- filter(encuesta, 
                       !is.na(Income_missin))
encuesta_no_obs <- filter(encuesta, 
                          is.na(Income_missin))
for(ii in 1:nrow(encuesta_no_obs)){
Expen_ii <- encuesta_no_obs$Expenditure[[ii]]
don_ii <- which.min(abs(Expen_ii - 
                          encuesta_obs$Expenditure))
encuesta_no_obs$Income_imp[[ii]] <- 
  encuesta_obs$Income_missin[[don_ii]]
encuesta_no_obs$Employment_imp[[ii]] <-
  encuesta_obs$Employment_missin[[don_ii]]
}

encuesta <- bind_rows(encuesta_obs,encuesta_no_obs)
```

## Imputación por el vecino más cercano

```{r}
prop.table(
  table(encuesta$Employment_missin, useNA = "a"))

prop.table(
  table(encuesta$Employment_imp, useNA = "a"))

```

## Imputación por el vecino más cercano

```{r}
prop.table( table(encuesta$Zone, encuesta$Employment_missin, 
        useNA = "a")) %>% addmargins()

prop.table( table(encuesta$Zone, encuesta$Employment_imp,
        useNA = "a")) %>% addmargins()
```

## Imputación por el vecino más cercano

```{r}
prop.table( table(encuesta$Sex, encuesta$Employment_missin, 
        useNA = "a")) %>% addmargins()

prop.table( table(encuesta$Sex, encuesta$Employment_imp,
        useNA = "a")) %>% addmargins()
```

## Imputación por el vecino más cercano

```{r}
encuesta %>% summarise(
  Income_ = mean(Income),
  Income_sd = sd(Income),
  Income_imp_ = mean(Income_imp),
  Income_imp_sd = sd(Income_imp))
```

## Imputación por el vecino más cercano

```{r}
encuesta %>%group_by(Zone) %>%  summarise(
  Income_ = mean(Income),
  Income_sd = sd(Income),
  Income_imp_ = mean(Income_imp),
  Income_imp_sd = sd(Income_imp))
```

## Imputación por el vecino más cercano

```{r}
encuesta %>%group_by(Sex) %>%  summarise(
  Income_ = mean(Income),
  Income_sd = sd(Income),
  Income_imp_ = mean(Income_imp),
  Income_imp_sd = sd(Income_imp))
```

## Imputación por el vecino más cercano

```{r, Vecino_1, echo=TRUE, eval=FALSE}
## Ordenando la base para gráfica 
dat_plot8 <- tidyr::gather(
  encuesta %>% select(Zone,Sex,Income, Income_imp),
  key = "Caso", value = "Income2", -Zone,-Sex)

p1 <- ggplot(dat_plot8, aes(x = Income2, fill = Caso)) + 
  geom_density(alpha = 0.2) + theme_bw() +
   theme(legend.position = "bottom") +
  geom_vline(
    xintercept = mean(encuesta$Income), 
             col = "red") +
  geom_vline(
    xintercept = mean(encuesta$Income_imp), 
             col = "blue")
p1
```

## Imputación por el vecino más cercano

```{r, Vecino_1, echo=FALSE, eval=TRUE}
```

## Imputación por el vecino más cercano

```{r, Vecino_2, echo=TRUE, eval=FALSE}
p1 <- ggplot(dat_plot8, aes(x= Caso, y = Income2)) + 
   geom_hline(yintercept = mean(encuesta$Income),
              col = "red") +  geom_boxplot() +
  facet_grid(Zone~Sex) + theme_bw()
p1
```

## Imputación por el vecino más cercano

```{r, Vecino_2, echo=FALSE, eval=TRUE}
```

## Imputación por el vecino más cercano con regresión

-   **Paso 1**: Ajustar un modelo de regresión.
-   **Paso 2**: Realizar la predicción de los valores observados y no
    observados.
-   **Paso 3**: Comparar las predicciones obtenidas para los valores observados
    y no observados.
-   **Paso 4**: Para la $i$-ésima observación identificar el donante con la
    menor distancia al receptor.
-   **Paso 5**: Reemplazar el valor faltante con la información proveniente del
    donante.

*NOTA* Se toma es la información observada en el donante.

## Imputación por el vecino más cercano con regresión

```{r, warning=FALSE, message=FALSE}
encuesta$Income_imp <- encuesta$Income_missin
encuesta$Employment_imp <- encuesta$Employment_missin
encuesta_obs <- filter(encuesta, 
                       !is.na(Income_missin))
encuesta_no_obs <- filter(encuesta, 
                          is.na(Income_missin))
mod <- lm(Income~Zone + Sex +Expenditure,
          data = encuesta_obs)

```

## Imputación por el vecino más cercano con regresión

```{r}
pred_Obs <- predict(mod, encuesta_obs)
pred_no_Obs <- predict(mod, encuesta_no_obs)

for(ii in 1:nrow(encuesta_no_obs)){
don_ii <- which.min(abs(pred_no_Obs[ii] - pred_Obs))
encuesta_no_obs$Income_imp[[ii]] <- 
  encuesta_obs$Income_missin[[don_ii]]
encuesta_no_obs$Employment_imp[[ii]] <-
  encuesta_obs$Employment_missin[[don_ii]]
}

encuesta <- bind_rows(encuesta_obs,encuesta_no_obs)
```

## Imputación por el vecino más cercano con regresión

```{r}
prop.table(
  table(encuesta$Employment_missin, useNA = "a"))

prop.table(
  table(encuesta$Employment_imp, useNA = "a"))

```

## Imputación por el vecino más cercano con regresión

```{r}
prop.table( table(encuesta$Zone, encuesta$Employment_missin, 
        useNA = "a")) %>% addmargins()

prop.table( table(encuesta$Zone, encuesta$Employment_imp,
        useNA = "a")) %>% addmargins()
```

## Imputación por el vecino más cercano con regresión

```{r}
prop.table( table(encuesta$Sex, encuesta$Employment_missin, 
        useNA = "a")) %>% addmargins()

prop.table( table(encuesta$Sex, encuesta$Employment_imp,
        useNA = "a")) %>% addmargins()
```

## Imputación por el vecino más cercano con regresión

```{r}
encuesta %>% summarise(
  Income_ = mean(Income),
  Income_sd = sd(Income),
  Income_imp_ = mean(Income_imp),
  Income_imp_sd = sd(Income_imp))
```

## Imputación por el vecino más cercano con regresión

```{r}
encuesta %>%group_by(Zone) %>%  summarise(
  Income_ = mean(Income),
  Income_sd = sd(Income),
  Income_imp_ = mean(Income_imp),
  Income_imp_sd = sd(Income_imp))
```

## Imputación por el vecino más cercano con regresión

```{r}
encuesta %>%group_by(Sex) %>%  summarise(
  Income_ = mean(Income),
  Income_sd = sd(Income),
  Income_imp_ = mean(Income_imp),
  Income_imp_sd = sd(Income_imp))
```

## Imputación por el vecino más cercano con regresión

```{r, Vecino_R1, echo=TRUE, eval=FALSE}
## Ordenando la base para gráfica 
dat_plot9 <- tidyr::gather(
  encuesta %>% select(Zone,Sex,Income, Income_imp),
  key = "Caso", value = "Income2", -Zone,-Sex)

p1 <- ggplot(dat_plot9, aes(x = Income2, fill = Caso)) + 
  geom_density(alpha = 0.2) + theme_bw() +
   theme(legend.position = "bottom") +
  geom_vline(
    xintercept = mean(encuesta$Income), 
             col = "red") +
  geom_vline(
    xintercept = mean(encuesta$Income_imp), 
             col = "blue")
p1
```

## Imputación por el vecino más cercano

```{r, Vecino_R1, echo=FALSE, eval=TRUE}
```

## Imputación por el vecino más cercano

```{r, Vecino_R2, echo=TRUE, eval=FALSE}
p1 <- ggplot(dat_plot9, aes(x= Caso, y = Income2)) + 
   geom_hline(yintercept = mean(encuesta$Income),
              col = "red") +  geom_boxplot() +
  facet_grid(Zone~Sex) + theme_bw()
p1
```

## Imputación por el vecino más cercano

```{r, Vecino_R2, echo=FALSE, eval=TRUE}
```

## Introducción a la imputación múltiple.

Suponga que existe un conjunto de $n$ datos que relaciona dos variables $X$,
$Y$, a través del siguiente modelo de regresión simple:

$$y_i = \beta x_i + \varepsilon_i$$ Para todo individuo $i = 1, \ldots, n.$, de
tal manera que los errores tienen distribución normal con $E(\varepsilon) = 0$ y
$Var(\varepsilon) = \sigma ^2$.

## Introducción a la imputación múltiple.

-   Sea $Y_{Obs}$ los valores observados para un conjunto de individuos de
    tamaño $n_1$.
-   Sea $Y_{NoObs}$ los valores **NO** observados de la variable $Y$ de tamaño
    $n_0$, es decir, $n_1 + n_0 = n$.\
-   Suponga que sí fue posible observar los valores de la covariable $X$ para
    todos los individuos en la muestra.

**Simulación**

Simular un conjunto de $n = 500$ datos con una pendiente $\beta = 10$ y con una
dispersión de $\sigma = 2$. A su vez, el conjunto de datos tendrá $n_0 = 200$
valores faltantes en la variable respuesta.

## Introducción a la imputación múltiple.

El algoritmo de simulación.

```{r}
generar <- function(n = 500, n_0 = 200, 
                    beta = 10, sigma = 2){
  x <- runif(n)
  mu <- beta * x
  y <- mu + rnorm(n, mean = 0, sd = sigma)
  datos <- data.frame(x = x, y = y)
  faltantes <- sample(n, n_0)
  datos$faltantes <- "No"
  datos$faltantes[faltantes] <- "Si"
  datos$y.per <- y
  datos$y.per[faltantes] <- NA
  return(datos)
}
```

## Introducción a la imputación múltiple.

```{r}
set.seed(1234)
datos <- generar()
head(datos,12)
```

## Introducción a la imputación múltiple.

```{r, multi0, echo=TRUE,eval=FALSE}
library(patchwork)
p1 <- ggplot(data = datos, aes(x = x, y = y)) +
  geom_point() +
  geom_smooth(formula = y~x , method = "lm")
p2 <- ggplot(data = datos, aes(x = x, y = y.per)) +
  geom_point() + 
  geom_smooth(formula = y~x , method = "lm")
  
p1 | p1
```

## Introducción a la imputación múltiple.

```{r, multi0, echo=FALSE,eval=TRUE}
```

## Introducción a la imputación múltiple.

Ahora, dado el 40% de valores faltantes, es necesario imputar los datos
faltantes. Para esto, utilizaremos la técnica de imputación múltiple propuesta
por Rubin (1987)[^1]. La idea consiste en generar $M > 1$ conjuntos de valores
para los datos faltantes. Al final, el valor *imputado* corresponderá al
promedio de esos $M$ valores.

[^1]: Rubin, D. B. (1987). Multiple imputation for survey nonresponse.

## Introducción a la imputación múltiple

Hay varias maneras de realizar la imputación:

-   **Ingenua**: Esta clase de imputación carece de aleatoriedad y por tanto, la
    varianza de $\beta$ va a ser subestimada.
-   **Bootstrap**: Se seleccionan $m$ muestras bootstrap, y para cada una se
    estiman los parámetros $\beta$ y $\sigma$ para generar $\dot{y}_i$. Al final
    se promedian los $m$ valores y se imputa el valor faltante.
-   **Bayesiana**: Se definen las distribuciones posteriores de $\beta$ y
    $\sigma$ para generar $M$ valores de estos parámetros y por tanto $M$
    valores de $\dot{y}_i$. Al final se promedian los $M$ valores y se imputa el
    valor faltante.

## Introducción a la imputación múltiple

Dado que el interés es la estimación de la pendiente de la regresión simple
$\beta$, entonces la esperanza estimada al utilizar la metodología de imputación
múltiple está dada por:
$$E(\hat{\beta} | Y_{obs}) = E(E(\hat{\beta} | Y_{obs}, Y_{mis}) | Y_{obs})$$

Esta expresión es estimada por el promedio de las $M$ estimaciones puntuales de
$\hat{\beta}$ sobre las $M$ imputaciones, dado por:
$$\bar{\hat{\beta}} = \frac{1}{M} \sum_{m = 1} ^ M \hat{\beta}_m$$

## Introducción a la imputación múltiple

La varianza estimada al utilizar la metodología de imputación múltiple está dada
por la siguiente expresión: $$
V(\hat{\beta} | Y_{obs}) = E(V(\hat{\beta} | Y_{obs}, Y_{mis}) | Y_{obs}) +
V(E(\hat{\beta} | Y_{obs}, Y_{mis}) | Y_{obs}) 
$$

La primera parte de la anterior expresión se estima como el promedio de las
varianzas muestrales de $\hat{\beta}$ sobre las $M$ imputaciones, dado por:
$$\bar{U} = \frac{1}{M} = \sum_{m = 1} ^ M Var(\beta)$$

El segundo término se estima como la varianza muestral de las $M$ estimaciones
puntuales de $\hat{\beta}$ sobre las $M$ imputaciones, dada por:
$$B = \frac{1}{M-1} = \sum_{m = 1} ^ M (\hat{\beta}_m - \bar{\hat{\beta}})$$

## Introducción a la imputación múltiple

Es necesario tener en cuenta un factor de corrección (puesto que $M$ es finito).
Por tanto, la estimación del segundo término viene dada por la siguiente
expresión: $$(1 + \frac{1}{M}) B$$

Por tanto, la varianza estimada es igual a:
$$\hat{V}(\hat{\beta} | Y_{obs}) = \bar{U} + (1 + \frac{1}{M}) B$$

```{r boot0, eval=TRUE, echo=FALSE}
im.bootstrap <- function(datos, M = 15){
  library(dplyr)
  n <- nrow(datos)
  datos1 <- na.omit(datos)
  n1 <- nrow(datos1)
  n0 <- n - n1
  Ind <- is.na(datos$y.per)
  faltantes.boot <- NULL
  beta1 <- NULL
  sigma1 <- NULL
  
  for (m in 1:M){
    datos.m <- dplyr::sample_n(datos1, n1, replace = TRUE)
    model1 <- lm(y ~ 0 + x, data = datos.m)
    beta <- model1$coeff
    sigma <- sqrt(anova(model1)[["Mean Sq"]][2])
    faltantes.boot <- rnorm(n0, datos$x[Ind] * beta, sd = sigma)
    datos$y.per[Ind] <-  faltantes.boot
    model.input <- lm(y.per ~ 0 + x, data = datos)
    beta1[m] <- model.input$coeff
    sigma1[m] <- summary(model.input)$coeff[2]
  }
  beta.input <- mean(beta1)
  u.bar <- mean(sigma1 ^ 2)
  B <- var(beta1)
  beta.sd <- sqrt(u.bar + B + B/M)
  result <- list(new = datos, beta = beta.input, sd = beta.sd)
}
```

## Imputación Bootstrap

Una función que realiza esta imputación es la siguiente:

```{r boot1, eval=FALSE}
im.bootstrap <- function(datos, M = 15){
  library(dplyr)
  n <- nrow(datos)
  datos1 <- na.omit(datos)
  n1 <- nrow(datos1)
  n0 <- n - n1
  Ind <- is.na(datos$y.per)
  faltantes.boot <- NULL
  beta1 <- NULL
  sigma1 <- NULL
## Continua...  
```

## Imputación Bootstrap

Continuando... \footnotesize

```{r boot2, eval=FALSE}
for (m in 1:M){
    datos.m <- dplyr::sample_n(datos1, n1, replace = TRUE)
    model1 <- lm(y ~ 0 + x, data = datos.m)
    beta <- model1$coeff
    sigma <- sqrt(anova(model1)[["Mean Sq"]][2])
    faltantes.boot <- rnorm(n0, datos$x[Ind] * beta,
                            sd = sigma)
    datos$y.per[Ind] <-  faltantes.boot
    model.input <- lm(y.per ~ 0 + x, data = datos)
    beta1[m] <- model.input$coeff
    sigma1[m] <- summary(model.input)$coeff[2]
  }
  beta.input <- mean(beta1)
  u.bar <- mean(sigma1 ^ 2)
  B <- var(beta1)
  beta.sd <- sqrt(u.bar + B + B/M)
  result <- list(new = datos, beta = beta.input,
                 sd = beta.sd)
}
```

## Imputación Bootstrap

Al aplicar la función sobre el conjunto de datos creado, se obtienen las
siguientes salidas:

```{r, message=FALSE}
datos <- generar()
im.bootstrap(datos)$beta
im.bootstrap(datos)$sd
head(im.bootstrap(datos)$new)
```

## Imputación Bootstrap

Nótese que existe una buena dispersión en los valores imputados.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
nuevos <- im.bootstrap(datos)$new
ggplot(data = nuevos, aes(x = x, y = y.per, color = faltantes)) + geom_point() 
```

## Imputación Bootstrap en la encuesta.

```{r}
encuesta$Income_imp <- encuesta$Income_missin
encuesta$Employment_imp <- encuesta$Employment_missin
encuesta_obs <- filter(encuesta, 
                       !is.na(Income_missin))
encuesta_no_obs <- filter(encuesta, 
                          is.na(Income_missin))
n0 <- nrow(encuesta_no_obs)
n1 <- nrow(encuesta_obs)
```

## Imputación Bootstrap en la encuesta.

\footnotesize

```{r}
M = 10 
set.seed(1234)
for (ii in 1:M) {
vp <- paste0("Income_vp_",ii)
vp2 <- paste0("Employment_vp_",ii)

encuesta_temp <- encuesta_obs %>%
  sample_n(size = n1, replace = TRUE)

mod <- lm(Income~Zone + Sex +Expenditure,
          data = encuesta_temp)
mod.mult <- multinom(Employment~Zone + Sex +Expenditure,
          data = encuesta_temp)

encuesta_no_obs[[vp]] <- predict(mod, encuesta_no_obs)
encuesta_obs[[vp]] <- encuesta_obs$Income

encuesta_no_obs[[vp2]] <- predict(mod.mult, 
                                  encuesta_no_obs,type = "class")
encuesta_obs[[vp2]] <- encuesta_obs$Employment
}
```

## Imputación Bootstrap en la encuesta.

```{r}
select(encuesta_no_obs, 
       Income, matches("Income_vp_"))[1:10,1:4]
```

## Imputación Bootstrap en la encuesta.

```{r, Bootstrap1, echo=TRUE, eval=FALSE}
encuesta <- bind_rows(encuesta_obs, encuesta_no_obs)
## Ordenando la base para gráfica 
dat_plot10 <- tidyr::gather(
  encuesta %>% select(Zone,Sex,matches("Income_vp_")),
  key = "Caso", value = "Income2", -Zone,-Sex)

p1 <- ggplot(dat_plot10, aes(x = Income2, col = Caso)) + 
  geom_density(alpha = 0.2) + theme_bw() +
   theme(legend.position = "bottom") +
  geom_density(data = encuesta ,aes(x = Income), 
              col =  "black", size = 1.2) 

p1
```

## Imputación por el vecino más cercano

```{r, Bootstrap1, echo=FALSE, eval=TRUE}
```

## Imputación Bootstrap en la encuesta.

```{r, Bootstrap2, echo=TRUE, eval=FALSE}
## Ordenando la base para gráfica 
dat_plot11 <- tidyr::gather(
  encuesta %>% 
  select(Zone,Sex, Employment,matches("Employment_vp_")),
  key = "Caso", value = "Employment2", -Zone,-Sex) %>%
  group_by(Caso,Employment2) %>% tally() %>% 
  group_by(Caso) %>% mutate(prop = n/sum(n))

p1 <- ggplot(dat_plot11, 
        aes(x = Employment2, y = prop,
            fill = Caso, color="red")) + 
       geom_bar(stat="identity",
          position = position_dodge(width = 0.5))  +
   theme_bw() +
   theme(legend.position = "bottom") +
  scale_fill_manual(values = c("Employment" = "black"))
p1
```

## Imputación por el vecino más cercano

```{r, Bootstrap2, echo=FALSE, eval=TRUE}
```

## Definir diseño de la muestra con `srvyr`

```{r}
library(srvyr)

diseno <- encuesta %>%
  as_survey_design(
    strata = Stratum,
    ids = PSU,
    weights = wk,
    nest = T
  )

```

## Estimación del promedio con valores plausibles (vp)

```{r}
estimacion_vp <-  diseno %>% 
 summarise(
   vp1 = survey_mean(Income_vp_1, vartype = c("var")),
   vp2 = survey_mean(Income_vp_2, vartype = c("var")),
   vp3 = survey_mean(Income_vp_3, vartype = c("var")),
   vp4 = survey_mean(Income_vp_4, vartype = c("var")),
   vp5 = survey_mean(Income_vp_5, vartype = c("var")),
   vp6 = survey_mean(Income_vp_6, vartype = c("var")),
   vp7 = survey_mean(Income_vp_7, vartype = c("var")),
   vp8 = survey_mean(Income_vp_8, vartype = c("var")),
   vp9 = survey_mean(Income_vp_9, vartype = c("var")),
   vp10 =survey_mean(Income_vp_10, vartype = c("var")))
```

## Estimación del promedio con valores plausibles (vp)

```{r, echo=FALSE}
require(tidyr)
(estimacion_vp %<>% tidyr::gather() %>% 
    separate(key, c("vp", "estimacion")) %>% 
mutate(estimacion = ifelse(is.na(estimacion), "promedio","var" )) %>% 
  spread(estimacion,value) %>% 
  mutate(vp = 1:10))
```

## Estimación del promedio con valores plausibles (vp)

```{r, echo=TRUE}
Media_vp = mean(estimacion_vp$promedio)
(Ubar = mean(estimacion_vp$var))
(B = var(estimacion_vp$promedio))
var_vp = Ubar + (1 + 1/M) 
(resultado <- data.frame(Media_vp, 
                        Media_vp_se = sqrt(var_vp)))
```

## Estimación de la varianza con valores plausibles (vp)

```{r}
estimacion_var_vp <-  diseno %>% 
  summarise_at(vars(matches("Income_vp")), 
               survey_var,  vartype = "var" )
             
```

## Estimación de la varianza con valores plausibles (vp)

```{r, echo = FALSE}
(estimacion_var_vp %<>% tidyr::gather() %>%
   separate(key, c("A", "B","vp", "estimacion")) %>% 
mutate(estimacion = ifelse(is.na(estimacion), "promedio","var" ),
       A = NULL, B = NULL, vp = as.numeric(vp)) %>% 
  spread(estimacion,value))
```

## Estimación de la varianza con valores plausibles (vp)

```{r, echo=TRUE}
Media_var_vp = mean(estimacion_var_vp$promedio)
(Ubar = mean(estimacion_var_vp$var))
(B = var(estimacion_var_vp$promedio))
var_var_vp = Ubar + (1 + 1/M)*B 
resultado$var_vp <- Media_var_vp
resultado$var_vp_se <- sqrt(var_var_vp)
```

## Comparando resultados con valores plausibles (vp)

```{r}
diseno %>% summarise(Media = survey_mean(Income), 
                     Var = survey_var(Income))
resultado
```

## Estimación de la proporción con valores plausibles (vp)

```{r}
estimacion_prop_vp <- 
  lapply(paste0("Employment_vp_",1:10),
       function(vp){
        diseno %>% 
         group_by_at(vars(Employment = vp)) %>% 
  summarise(prop = survey_mean(vartype = "var"),
            .groups = "drop") %>%
         mutate(vp = vp)
       }) %>% bind_rows()
  
             
```

## Estimación de la varianza con valores plausibles (vp)

```{r, echo = FALSE}
(estimacion_prop_vp %<>% separate(vp, c("A", "B","vp")) %>% 
mutate(A = NULL, B = NULL, vp = as.numeric(vp)) %>%
  select(vp,Employment:prop_var)) %>% slice(1:12L)
```

## Estimación de la varianza con valores plausibles (vp)

```{r, echo=TRUE}
resultado = estimacion_prop_vp %>% 
  group_by(Employment) %>% 
  summarise(prop_pv = mean(prop),
            Ubar = mean(prop_var),
            B = var(prop)) %>% 
  mutate(prop_pv_var = Ubar + (1 + 1/M)*B)

```

## Comparando resultados con valores plausibles (vp)

```{r}
 diseno %>%  group_by(Employment ) %>% 
  summarise(prop = survey_mean(vartype = "var"))
resultado
```

## Lectura de múltiples bases

Para realizar la lectura de múltiples bases debemos conocer las rutas donde
estas estas guardadas para ello empleamos la función `file.list` del paquete
base, que nos permite tener un listado completo de los archivos.

```{r, tab_mult0, eval=FALSE}

(data_path <- list.files("Z:/BC/",full.names = TRUE, 
                        pattern = "2020") )

```

## Lectura de múltiples bases
\scriptsize
```{r, tab_mult0, eval=TRUE, echo=FALSE}
```

## Lectura de encuestas e imputación de datos

Dado que el proceso de imputación es un proceso más complejo que estimar
promedios o proporciones se hace necesario construir una función adaptada a
nuestras necesidades que nos ayude con el proceso

## Función para el proceso de imputación (Promedio sin condicionar)

Para el siguiente ejercicio se considero la variable ingresos (ingcorte) y se
considera un valor perdido cuando `ingcorte = 0` que toma valores perdidos
\scriptsize
```{r, eval=TRUE}
imp_media <- function(input_file){
  ## Identificando el nombre del país
  pais = gsub("Z:\\/BC\\/(.*)_.*","\\1",x = input_file)
  ## Paso 1: lectura y selección de variables
  encuesta <- read_dta(input_file) %>% 
    transmute(ingcorte,
              ingcorte_imp = ifelse(ingcorte==0,NA,ingcorte))
  ## Paso 2: Definir el método de imputación 
  media = mean(encuesta$ingcorte_imp, na.rm = TRUE)
  ## Paso 3: Aplicar el método de imputación
  encuesta %<>%
    mutate(pais = pais,
      ingcorte_media = ifelse(is.na(ingcorte_imp),
                                   media, ingcorte_imp))
  ## Paso 4: Retornar el resultado
  return(encuesta)
}

```


## Procesando encuestas múltiples
Para aplicar la función `imp_media` en las diferentes encuestas ejecutamos la siguiente sintaxis.

```{r,tab_mult1, echo=TRUE, eval=FALSE}
library(furrr)
library(haven)
future::plan(multiprocess)
temp <- data_path %>% 
    future_map_dfr(~imp_media(.x),.progress = FALSE) 

temp %>% filter(is.na(ingcorte_imp)) %>% head( 10)
```

La función `future_map_dfr` es utilizada para trabajar con los elementos de una lista, ademas realizar procesamiento en paralelo, es decir, cada núcleo del ordenador opera una encuesta diferente, lo que permite reducir los tiempos de computacionales


## Procesando encuestas múltiples (Resultado)

Los resultados se muestran en el orden de lectura de los archivos

```{r,tab_mult1, echo=FALSE, eval=TRUE}
```

## Comparando resultados en los paises. 


```{r}
temp %>% group_by(pais) %>% 
  summarise_all(mean,  na.rm = TRUE)
```


## Comparando resultados en los paises. 

```{r}
temp %>% group_by(pais) %>% 
  summarise_all(median,  na.rm = TRUE)
```


## Función para el proceso de imputación (Promedio condicionado)

\scriptsize
```{r, eval=TRUE}
imp_media_grupo <- function(input_file){
  ## Identificando el nombre del país
  pais = gsub("Z:\\/BC\\/(.*)_.*","\\1",x = input_file)
  ## Paso 1: lectura y selección de variables
  encuesta <- read_dta(input_file) %>% 
    transmute(areageo2,ingcorte,
              ingcorte_imp = ifelse(ingcorte==0,NA,ingcorte))
  ## Paso 2 y 3: Definir el método de imputación 
  ## aplicar el método de imputación
  encuesta %<>% group_by(areageo2) %>% 
    mutate(pais = pais,
      ingcorte_media = ifelse(is.na(ingcorte_imp),
                                   mean(ingcorte_imp,na.rm = TRUE ),
                                   ingcorte_imp))
  ## Paso 4: Retornar el resultado
  return(encuesta)
}

```


## Procesando encuestas múltiples
Para aplicar la función `imp_media_grupo` en las diferentes encuestas ejecutamos la siguiente sintaxis.

```{r,tab_mult2, echo=TRUE, eval=FALSE}
future::plan(multiprocess)
temp <- data_path %>% 
    future_map_dfr(~imp_media_grupo(.x),.progress = FALSE) 
temp %>% filter(is.na(ingcorte_imp)) %>% head( 10)
```

## Procesando encuestas múltiples (Resultado)

Los resultados se muestran en el orden de lectura de los archivos
\scriptsize
```{r,tab_mult2, echo=FALSE, eval=TRUE}
```

## Comparando resultados en los paises. 


```{r}
temp %>% group_by(pais, areageo2) %>% 
  summarise_all(mean,  na.rm = TRUE) %>% 
  head(10) %>% data.frame()
```


## Comparando resultados en los paises. 

```{r}
temp %>% group_by(pais,areageo2) %>% 
  summarise_all(median,  na.rm = TRUE) %>% 
  head(10) %>% data.frame()
```


## Función para el proceso de imputación (Promedio condicionado)

\scriptsize
```{r, eval=TRUE}
imp_media_lm <- function(input_file){
  ## Identificando el nombre del país
  pais = gsub("Z:\\/BC\\/(.*)_.*","\\1",x = input_file)
  ## Paso 1: lectura y selección de variables
  encuesta <- read_dta(input_file) %>% 
    transmute(areageo2,ingcorte, sexo = as.factor(sexo),edad,
              ingcorte_imp = ifelse(ingcorte==0,NA,ingcorte))
  ## Paso 2: Definir el método de imputación 
  encuesta2 <- filter_all(encuesta,  all_vars(!is.na(.))) %>% 
    select(-ingcorte)
  mod <- lm(ingcorte_imp~.,encuesta2) 
  ## Paso 3: Aplicar el método de imputación
  encuesta$pred <- as.numeric(predict(mod,encuesta))
  encuesta %<>% 
  mutate(pais = pais,ingcorte_lm = ifelse(is.na(ingcorte_imp),
                              pred, ingcorte_imp),
         pred = NULL) %>% 
    select(pais,matches("ingcorte"))
  ## Paso 4: Retornar el resultado
  return(encuesta)
}

```


## Procesando encuestas múltiples
Para aplicar la función `imp_media_lm` en las diferentes encuestas ejecutamos la siguiente sintaxis.

```{r,tab_mult3, echo=TRUE, eval=FALSE}
future::plan(multiprocess)
temp <- data_path %>% 
    future_map_dfr(~imp_media_lm(.x),.progress = FALSE) 
temp %>% filter(is.na(ingcorte_imp)) %>% head( 10)
```

## Procesando encuestas múltiples (Resultado)

Los resultados se muestran en el orden de lectura de los archivos

```{r,tab_mult3, echo=FALSE, eval=TRUE}
```

## Comparando resultados en los paises. 


```{r}
temp %>% group_by(pais) %>% 
  summarise_all(mean,  na.rm = TRUE) 
```


## Comparando resultados en los paises. 

```{r}
temp %>% group_by(pais) %>% 
  summarise_all(median,  na.rm = TRUE)
```

## ¡Gracias!

::: yellow
*Email*: [andres.gutierrez\@cepal.org](mailto:andres.gutierrez@cepal.org){.email}
:::

