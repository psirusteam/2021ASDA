---
title: "Análisis de encuestas de hogares con R"
subtitle: "Modulo 7: Modelos lineales generalizados (Variable categóricas)"
date: "CEPAL - Unidad de Estadísticas Sociales"
output:
  beamer_presentation:
    colortheme: dove
    fonttheme: default
    incremental: yes
    theme: Berkeley
    toc: yes
    slide_level: 2
    #highlight: pygments
  ioslides_presentation:
    incremental: yes
    widescreen: yes
    toc: yes
  slidy_presentation:
    incremental: yes
Email: andres.gutierrez@cepal.org
editor_options:
  markdown:
    wrap: 90
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE, warning = FALSE, message = FALSE, error = FALSE)
options(digits = 4)
options(tinytex.verbose = TRUE)
library (survey)
library(srvyr)
library(convey)
library(TeachingSampling)
library(printr)
library(stargazer)
library(broom)
library(jtools)
library(modelsummary)
library(patchwork)
#rm(list = ls())
```

## Método de Pseudo máxima verosimilitud

Sea $\boldsymbol{y}_i$ el vector de observaciones los cuales provienen de los vectores
aleatorios $\boldsymbol{Y}_i$ para $i \in U$. Suponga también que
$\boldsymbol{Y_1, \dots, Y_N}$ son IID con función de densidad $f(\boldsymbol{y},\theta)$.
Si todos los elementos de la población finita $U$ fueran conocidos la función de
log-verosimilitud estaría dada por: $$
L_{U}\left(\theta\right)=\sum_{i\in U}\log\left[f\left(\boldsymbol{y}_{i};\theta\right)\right]
$$ y las ecuaciones de verosimilitud están dadas por: $$
\sum_{i\in U}\boldsymbol{u}_{i}\left(\theta\right)=\boldsymbol{0}
$$ donde 
$$
\boldsymbol{u}_{i}\left(\theta\right)=\frac{\partial\log\left[f\left(\boldsymbol{y}_{i};\theta\right)\right]}{\partial\theta}
$$

## Método de Pseudo máxima verosimilitud

Si se cumplen las condiciones de regularidad (Ver Pag 281 de Cox and Hinkley 1974[^1]), es
posible considerar a $$\boldsymbol{T}=\sum_{i\in U}\boldsymbol{u}_{i}\left(\theta\right)$$
como un vector de totales. La estimación $\boldsymbol{T}$ se puede hacer mediante
$$\boldsymbol{\hat{T}}=\sum_{i\in U}w_i\boldsymbol{u}_{i}\left(\theta\right),$$ donde
$w_i$ son los pesos previamente definidos.

[^1]: Cox, D. R., & Hinkley, D. V. (1974). Theoretical Statistics Chapman and Hall,
    London. See Also.

## Método de Pseudo máxima verosimilitud (Definición)

Un estimador de Máxima Pseudo Verosimilitud (MVP) $\hat{\theta}_{MPV}$ de $\theta_U$ será
la solución de las ecuaciones de Pseudo-Verosimilitud dadas por
$$\boldsymbol{\hat{T}}=\sum_{i\in U}w_i\boldsymbol{u}_{i}\left(\theta\right) = 0,$$

Através de la Linealización de Taylor podemos obtener la varianza asintotica de
$\hat{\theta}_{MPV}$ dada por:

$$
V_{p}\left(\hat{\theta}_{MPV}\right)\approx\left[J\left(\theta_{U}\right)\right]^{-1}V_{p}\left[\sum_{i\in s}w_{i}\boldsymbol{u}_{i}\left(\theta_{U}\right)\right]\left[J\left(\theta_{U}\right)\right]^{-1}
$$

$$
\hat{V}_{p}\left(\hat{\theta}_{MPV}\right)=\left[\hat{J}\left(\hat{\theta}_{MPV}\right)\right]^{-1}\hat{V}_{p}\left[\sum_{i\in s}w_{i}\boldsymbol{u}_{i}\left(\hat{\theta}_{MPV}\right)\right]\left[\hat{J}\left(\hat{\theta}_{MPV}\right)\right]^{-1}
$$

## Método de Pseudo máxima verosimilitud (Definición)

Con 
$$
J\left(\theta_{U}\right)=  \frac{\partial T\left(\theta\right)}{\partial\theta}\bigg|_{\theta=\theta_{U}}=  \sum_{i\in U}\frac{\partial\boldsymbol{u}_{i}\left(\theta\right)}{\partial\theta}\bigg|_{\theta=\theta_{U}}
$$

$$
\hat{J}\left(\hat{\theta}_{MPV}\right)=  \frac{\partial\hat{T}\left(\theta\right)}{\partial\theta}\bigg|_{\theta=\hat{\theta}_{MPV}}=  \sum_{i\in s}w_{i}\frac{\partial\boldsymbol{u}_{i}\left(\theta\right)}{\partial\theta}\bigg|_{\theta=\hat{\theta}_{MPV}}
$$

$\hat{V}_{p}\left[\sum_{i\in s}w_{i}\boldsymbol{u}_{i}\left(\theta_{U}\right)\right]$ es
la matriz de varianza estimada y
$\hat{V}_{p}\left[\sum_{i\in s}w_{i}\boldsymbol{u}_{i}\left(\theta_{MPV}\right)\right]$ es
un estimador consistente para la varianza.

## Introducción al GLM

Un modelo lineal generalizado tiene tres componentes básicos:

-   **Componente aleatoria**: Identifica la variable respuesta ($y_1, \dots, y_N$) y su
    distribución de probabilidad.

-   **Componente sistemática**: Especifica las variables explicativas (independientes o
    predictoras) utilizadas en la función predictora lineal.

    Las covariables $x_1, \dots, x_k$ producen un predictor lineal $\eta_i$ que resulta de
    la combinación lineal $\eta_{i}=\sum_{j=1}^{k}x_{ij}\beta_{j}$ donde $x_{ij}$ es el
    valor del j-ésimo predictor en el i-ésimo individuo, e $i = 1,\dots,N$.

## Introducción al GLM

-   **Función link**: Es una función del valor esperado de $Y$ , $E(Y )$, como una
    combinación lineal de las variables predictoras.

    Se denota el valor esperado $Y$ como $\mu = E(Y)$, entonces la función *link*
    especifica una función $$g(\mu)=\sum_{j=1}^{k}x_{ij}\beta_{j}.$$ 
    Así, la función $g(\cdot)$ realciona las componentes aleatoria y sistemática.
    De este modo, para $i=1,\dots, N$ 
    $$\mu_i = E(Y_i) $$
    $$\eta_i = g(\mu_i) = \sum_{j}\beta_jx_{ij}$$
    

## Introducción al GLM

  - Todos los modelos se pueden incluir dentro de la llamada familia exponencial de
distribuciones $$f\left(y_{i}\mid\theta_{i}\right)=a\left(\theta_{i}\right)b\left(\theta_{i}\right)\exp\left[y_{i}Q\left(\theta_{i}\right)\right]$$ de modo que $Q\left(\theta\right)$ recibe el nombre de *parámetro natural*. Además, $a(\cdot)$ y $b(\cdot)$ son funciones conocidas. 

  - Los modelos de regresión lineal típicos para respuestas continuas son un caso particular de los $GLM$.

  
## Lectura de la base y definición del diseño muestral

```{r}
library(survey)
library(srvyr)
encuesta <- readRDS("../Data/encuesta.rds")
diseno <- encuesta %>%
  as_survey_design(
    strata = Stratum,
    ids = PSU,
    weights = wk,
    nest = T
  )

```

## Definir nueva variable 
Creando nuevas variables en la base de datos.  
```{r, tabs1, echo=TRUE, eval=TRUE}
diseno <- diseno %>% 
  mutate(
  pobreza = ifelse(Poverty != "NotPoor", 1, 0),
  desempleo = ifelse(Employment == "Unemployed", 1, 0))
```

## Modelo para el ingreso

```{r, echo=FALSE, eval=TRUE}
theme_cepal <- function(...) theme_light(10) + 
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        legend.position="bottom", 
        legend.justification = "left", 
        legend.direction="horizontal",
        plot.title = element_text(size = 20, hjust = 0.5),
        ...) 
```

Estimador de momentos de la distribución gamma

```{r, echo=TRUE, eval=TRUE}
library(ggplot2)

x <- encuesta$Income
n = length(x)
shape1 = (n*mean(x)^2)/sum((x-mean(x))^2)
rate1 = (n*mean(x))/sum((x-mean(x))^2)
c(shape1 = shape1, rate1 = rate1)
```

## Modelo para el ingreso
La densidad empirica para el ingreso. 
```{r, plot_gamma1, echo=TRUE, eval=FALSE}
ggplot(data = encuesta, aes(x = Income) ) + 
  geom_histogram(aes(y =..density..), bins = 30) +
  geom_density(aes(y =..density..), size = 2)+ 
  geom_function(fun = dgamma, 
  args = list(shape = shape1, rate = rate1),
  col = "red", size = 2)  +
  theme_cepal()

```

## Modelo para el ingreso
La linea roja se obtiene con la estimación de los parámetros, la linea negra es la densidad empírica. 
```{r, plot_gamma1, echo=FALSE, eval=TRUE}
```

## Modelo gamma para variable continua.  

La función de enlace $g(\cdot)$ para el GLM con una variable dependiente distribuida por Gamma es el recíproco, $\frac{1}{\mu_{i}}$. Eso significa que el valor esperado de  $y_i$ observado, ($E(y_i) = \mu_i$), está relacionado con sus variables de entrada como, por ejemplo, 
$$
\frac{1}{\mu_{i}} = B_0 + B_1x_1
$$
o 
$$
\mu_{i} = \frac{1}{B_0 + B_1x_1}
$$


## Modelo gamma ingreso 

```{r,mod_gamma1, echo=TRUE,eval=FALSE}
mod_qw <- lm(wk ~ Age + Sex + Region + Zone,
             data = encuesta)

encuesta$wk2 <-   encuesta$wk/predict(mod_qw)
diseno <- encuesta %>%
  as_survey_design( strata = Stratum,
    ids = PSU, weights = wk2,
    nest = T)

modelo <- svyglm(formula = Income ~ Age + Sex +
                   Region + Zone,
                   design = diseno, 
                  family = Gamma(link = "inverse")) 
broom::tidy(modelo)
```

## Modelo gamma 
Estimación de los parámetro del modelo. 
```{r,mod_gamma1, echo=FALSE,eval=TRUE}
```


## Modelo gamma
Es útil la estimación de la dispersión que ofrece _svyglm_ de forma predeterminada dado que no tiene en cuenta la información especial sobre la dispersión que se puede calcular utilizando la distribución Gamma. **No todos los GLM tienen una forma mejorada y específica del modelo para estimar**.
```{r}
(alpha = MASS::gamma.dispersion(modelo))
mod_s <- summary(modelo, dispersion = alpha)
mod_s$dispersion

```
## Modelo Gamma
```{r}
mod_s$coefficients
```



## Utilizando la función predict
Estimando los intervalos de confianza para la predicción. 
```{r, IC_1, eval=FALSE}
pred <- data.frame(
  predict(modelo, type = "response", se = T))
pred_IC <- data.frame(
  confint(predict(modelo, type = "response", se = T)))
colnames(pred_IC) <- c("Lim_Inf", "Lim_Sup")
pred <- bind_cols(pred, pred_IC)
pred$Income <- encuesta$Income
pred$Age <- encuesta$Age
pred %>% slice(1:6L)
```

## Utilizando la función predict
```{r, IC_1, eval=TRUE,echo=FALSE}
```

## Scaterplot de la predicción
Intervalos de confizan para la predicción en cada punto.
```{r, plot_pred, echo=TRUE,eval=FALSE}
pd <- position_dodge(width = 0.2)
ggplot(pred %>% slice(1:100L),
       aes(x = Age , y = response)) +
  geom_errorbar(aes(ymin = Lim_Inf,
                    ymax = Lim_Sup),
                width = .1,
                linetype = 1) +
  geom_point(size = 2, position = pd) +
  theme_bw()
```

## Utilizando la función predict
```{r, plot_pred, echo=FALSE,eval=TRUE}
```

## Efecto del modelo. 
Efecto de los variables en el modelo.
```{r, plot_effecto2,  echo=TRUE, eval=FALSE}
effe_sex <- effect_plot(modelo, pred = Sex,
                        interval = TRUE)
effe_Zona <-effect_plot(modelo, pred = Zone, 
                        interval = TRUE)
effe_Region <- effect_plot(modelo, pred = Region,
                           interval = TRUE)
(effe_sex |effe_Zona)/effe_Region
```

## Efecto del modelo.
```{r, plot_effecto2,  echo=FALSE, eval=TRUE}
```

<!-- ## Modelo Gamma -->
<!-- ```{r} -->
<!-- par(mfcol=c(2,2)) -->
<!-- plot(modelo) -->
<!-- ``` -->

## Modelos multinomial
El modelo de regresión logit multinomial es la extensión natural del modelo de regresión logística binomial simple para encuestar respuestas que tienen tres o más categorías distintas. Esta técnica es más apropiada para variables de encuesta con categorías de respuesta nominales.

## Modelo multinomial 
Para ajustar el modelo debemos tener presente que: 

  - Su variable dependiente debe medirse en el nivel nominal.
  - Tiene una o más variables independientes que son continuas , ordinales o nominales (incluidas las variables dicotómicas).
  - Tener independencia de las observaciones y la variable dependiente debe tener categorías mutuamente excluyentes y exhaustivas 
  
## Modelo multinomial 
  - No debe haber **multicolinealidad.** La multicolinealidad ocurre cuando tiene dos o más variables independientes que están altamente correlacionadas entre sí.
  - Debe haber una relación lineal entre cualquier variable independiente continua y la transformación logit de la variable dependiente 
  - No debe haber valores atípicos, valores de apalancamiento elevados o puntos muy influyentes .
  
## Modelo multinomial
El modelo múltinomial esta dado como:
$$
Pr\left(Y_{ik}\right)=Pr\left(y_{i}=k\mid\boldsymbol{x}_{i}:\boldsymbol{\beta}_{1},\dots\boldsymbol{\beta}_{m}\right)=\frac{\exp\left(\beta_{0k}+\boldsymbol{\beta}_{k}\boldsymbol{x}_{i}\right)}{\sum_{j=1}^{m}\exp\left(\beta_{0j}+\boldsymbol{\beta}_{j}\boldsymbol{x}_{i}\right)}
$$

donde $\boldsymbol{\beta}_k$ es el vector de coeficiente de $\boldsymbol{X}$ para la k-ésima categoría de $Y$. 

## Modelo multinomial

```{r}
diseno %>% group_by(Employment) %>% 
  summarise(Prop = survey_mean(vartype = c("se", "ci")))
```

## Modelo multinomial
```{r}
diseno %>% filter(Age >= 15)%>% group_by(Employment) %>% 
  summarise(Prop = survey_mean(vartype = c("se", "ci")))
```

## Modelo multinomial
```{r}
library(svyVGAM)
diseno_15 <- diseno %>% filter(Age >= 15)
model_mul <- svy_vglm(
    formula = Employment ~ Age + Sex + Region + Zone,
                   design = diseno_15, 
     crit = "coef",
    family = multinomial(refLevel = "Unemployed")) 
```
La función `broom::tidy()`, que normalmente usamos para limpiar y estandarizar la salida del modelo, no puede ser empleada en este caso, sin embargo, en el link[^2] encuentra la función que utilizamos a continuación. 

[^2]: https://tech.popdata.org/pma-data-hub/posts/2021-08-15-covid-analysis/ 

```{r, echo=FALSE, eval=TRUE}
tidy.svyVGAM <- function(
  x, 
  conf.int = FALSE, 
  conf.level = 0.95,
  exponentiate = FALSE, 
  ...
){
  # Replace `summary(x)$coefficients` with `summary(x)$coeftable`
  ret <- as_tibble(summary(x)$coeftable, rownames = "term")
  
  # All of this stays the same:
  colnames(ret) <- c("term", "estimate", "std.error", "statistic", "p.value")
  coefs <- tibble::enframe(stats::coef(x), name = "term", value = "estimate")
  ret <- left_join(coefs, ret, by = c("term", "estimate"))
  if (conf.int){
    ci <- broom:::broom_confint_terms(x, level = conf.level, ...)
    ret <- dplyr::left_join(ret, ci, by = "term")
  }
  if (exponentiate){ret <- broom:::exponentiate(ret)}
  
  # This part only works for the multinomial case, and only if your covariates
  # have no ":" in their names - NOT FOR GENERAL USE
  ret %>% 
  tidyr::separate(term, into = c("term", "y.level"), sep = ":") %>% 
    arrange(y.level) %>% 
    relocate(y.level, .before = term)
}
```


## Modelo multinomial
```{r,modMult, echo=TRUE, eval=FALSE}
tab_model <- tidy.svyVGAM(model_mul, 
                               exponentiate = FALSE, 
                               conf.int = FALSE) 
tab_model
```

## Modelo multinomial
```{r,modMult, echo=FALSE, eval=TRUE}
```

## Plot del IC para los coeficientes. 
```{r, plot_Coef_mult, echo=TRUE,eval=FALSE}
tab_model %>% 
  mutate(
    model = if_else(
      y.level == 1, 
      "Inactive",
      "Employed", 
    ),
    sig = gtools::stars.pval(p.value)
  )  %>% 
  dotwhisker::dwplot(
    dodge_size = 0.3,
    vline = geom_vline(xintercept = 1, colour = "grey60",
                       linetype = 2)
  ) + 
  guides(color = guide_legend(reverse = TRUE)) + 
  theme_bw() + theme(legend.position = "top")
```

## Plot del IC para los coeficientes. 
```{r, plot_Coef_mult, echo=FALSE,eval=TRUE}
```

## modelo multinomial función alternativa. 
La función `svy_vglm` realiza la estimación de los parámatros, sin embargo, presenta limitaciones 
para hacer las predicciones con el modelo, por lo tanto, podemos usar como alternativa. 
```{r, Coef_mult2, echo=TRUE,eval=FALSE}
library(CMAverse)
model_mul2 <- svymultinom(
  formula = Employment ~ Age + Sex + Region + Zone,
  weights = diseno_15$variables$wk2, 
  data = diseno_15$variables
) 
summary(model_mul2)$summarydf
```

## Modelo multinomial función alternativa. 
Parámetros estimados
\tiny
```{r, Coef_mult2, echo=FALSE,eval=TRUE}
```

## Predicción del modelo
El hacer uso de esta función podemos obtener de forma simple la predicción de las probabilidades
```{r, pred_mult2, echo=TRUE, eval=FALSE}
tab_pred <- predict(model_mul2, type = "probs") %>% 
  data.frame()
tab_pred %>% slice(1:15)
```

## Predicción del modelo 
\small
```{r, pred_mult2, echo=FALSE, eval=TRUE}
```

## Predicción del modelo 
```{r}
diseno_15$variables  %<>% 
  mutate(predicion = predict(model_mul2))

diseno_15 %>% group_by(Employment) %>% 
  summarise(Prop = survey_mean(vartype = c("se", "ci")))
```

## Predicción del modelo 
```{r}
diseno_15 %>% group_by(predicion) %>% 
  summarise(Prop = survey_mean(vartype = c("se", "ci")))
```
## ¡Gracias!

::: yellow
*Email*: [andres.gutierrez\@cepal.org](mailto:andres.gutierrez@cepal.org){.email}
:::

