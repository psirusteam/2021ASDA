```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, 
                      message = FALSE,
                      cache = TRUE)
```

# Imputación múltiple en encuestas de hogares

La no respuesta en encuestas de hogares es un fenómenos que desde siempre ha sucedido, más ahora después de la pandemia del Covid -19. Esto sucede por muchas razones, por ejemplo, la longitud de los cuestionarios en las encuestas, el no conocer algunas características particulares del hogar, la renuencia por entregar información sensible, entre otras. Si la no respuesta en algún indicador del estudio es muy alto, puede poner en riesgo la calidad de las estimaciones que se obtienen utilizando los estimadores clásicos.

Debido a este problema, se ha avanzado en la literatura especializada metodologías que permiten atacar este problema, el cual es una realidad en todas las encuestas de hogares en los distintos países. 427

En este sentido, alguno de los avances en la teoría de los métodos en el contexto de muestras comlejas son: imputación múltiple (MI; Van Buuren, 2012; Carpenter y Kenward, 2013; Berglund y Heeringa, 2014; Stata Corp, 2015; Raghunathan, 2016). También se encuentra en la literatura métodos como el de imputación fraccional (FI; Kim y Fuller, 2004; Kim y Shao, 2014), el Bootstrap Bayesiano de Población Finita (Zhou et al., 2016a,b), y métodos de máxima verosimilitud como los de Chambers et al., (2012). 

El objetivo principal de este capítulo es abordar el problema de la falta de datos en encuestas de hogares, revisar las posibles causas, el impacto que tiene en la estimación de los indicadores, y mostrar algunas soluciones a la falta de datos en las encuesta.

Siguiendo las ideas anteriores, sea $\boldsymbol{X}_{n \times p} = x_{ij}$ una matriz completa (sin valores perdidos) de tal forma que $X_{ij}$ es el valor de la variable $j$ con $j=1, \dots, p$ e $i$ con $i=1, \dots, n$. Adicionalmente, se define $\boldsymbol{M}_{n \times p} = m_{ij}$ una matriz indicadoradonde $m_{ij} = 1$ si el valor de $x_{ij}$ es un dato perdido y $m_{ij}=0$ si $x_{ij}$ está presente.

Ahora bie, note que la matriz $M$ describe el patrón de missing (datos faltantes), y su media marginal de columna puede ser interpretada como la probabilidad de que $x_{ij}$ sea missing. A continuación, se describen alguna de las particularidades de la matriz $\boldsymbol{M}_{n \times p}$:


- La matriz $\boldsymbol{M}_{n \times p}$ presenta un comportamiento completamente al azar (MCAR): si la probabilidad de respuesta es independiente de las variables observadas y de las no observadas completamente. El mecanismo de pérdida es ignorable tanto para inferencias basadas en muestreo como en máxima verosimilitud.

- Los valores de la matriz $\boldsymbol{M}_{n \times p}$ son al azar (MAR): si la probabilidad de respuesta es independiente de las variables no observadas completamente y no de las observadas. El mecanismo de pérdida es ignorable para inferencias basadas en máxima verosimilitud.

- Los datos no están perdidos al azar (MNAR): si la probabilidad de respuesta no es independiente de las variables no observadas completamente y posiblemente, también, de las observadas. El mecanismo de pérdida es no ignorable.

En las dos figuras siguientes, se ilustran los casos de observaciones perdidas de manera aleatoria y con un patrón identificado:

![](Imagenes/Cap%208/fig1.png){width="250"}
![](Imagenes/Cap%208/fig2.png){width="250"}

Como se ha venido trabajando en los capítulos anteriores, primero carguemos la base de datos con la muestra seleccionada y con el fin de poder ejemplificar el tratamiento de datos faltantes, se incluiran manualmente "valores perdidos". En este sentido, la lectura de la base se hará a continuación:


```{r, eval=TRUE}
encuesta <- readRDS("Data/encuesta.rds") 
```

Se filtran encuestados mayores a 15 años y se calcula  la proporción de la población desempleada, inactiva y empleada antes de generar los valores faltantes. Pero antes de eso, se cargan todas las librerías que se utilizarán en este capítulo:

```{r}
knitr::opts_chunk$set(cache = FALSE, warning = FALSE, message = FALSE, error = FALSE)
#options(digits = 4)
options(tinytex.verbose = TRUE)
library (survey)
library(srvyr)
library(convey)
library(TeachingSampling)
library(printr)
library(stargazer)
library(broom)
library(jtools)
library(modelsummary)
library(patchwork)
library(ggplot2)
```


Cálculo de las proprociones de personas desempleadas, inactivas y empleados:
```{r}
encuesta<- encuesta |> filter(Age >= 15)
(tab_antes <- prop.table(table(encuesta$Employment)))
```

También se calcula el promedio de ingresos en al muestra:

```{r}
(med_antes <- mean(encuesta$Income, na.rm = TRUE))
```

Luego de los conteos anteriores, se genera un 20% de valores faltantes siguiendo un esquema MCAR como sigue:

```{r}
set.seed(1234)
encuesta_MCAR <-  sample_frac(encuesta, 0.8 )
dat_plot <-       bind_rows(
  list(encuesta_MCAR = encuesta_MCAR, 
       encuesta = encuesta), .id = "Caso"  )
```


Ahora bien, para poder ver el efecto de la inclusión de datos faltantes de manera gráfica por zona y sexo para la variable ingreso, se realizan las siguientes gráficas:

```{r, echo=TRUE, eval=TRUE}
p1 <- ggplot(dat_plot, aes(x=Zone, y = Income)) + 
  geom_boxplot() + facet_grid(.~Caso) + theme_bw()+
  geom_hline(yintercept = mean(encuesta$Income), 
             col = "red")

p2 <- ggplot(dat_plot, aes(x=Sex, y = Income)) + 
  geom_boxplot() + facet_grid(.~Caso) +theme_bw()+
  geom_hline(yintercept = mean(encuesta$Income), 
             col = "red")
library(patchwork)
p1|p2
```

Como se puede observar en las gráficas anteriores, la distribución de los ingresos por Zona y Sexo se mantiene similar con o sin presencia de la no respuesta. Esto se debe a que la no respuesta que se incluyó no depende de la variable de estudio.

Ahora bien, analizando la variable de interés se tiene que tampoco hay cambios distribucionales notables entre las distribuciones con y sin datos faltantes por sexo, como se puede observar a continuación:

```{r, echo=TRUE, eval=TRUE}
p1 <- ggplot(dat_plot, aes(x = Income, fill = Caso)) + 
  geom_density(alpha = 0.3) + theme_bw() +
  theme(legend.position = "bottom") +
  geom_vline(xintercept = mean(encuesta$Income), 
             col = "red")

p2 <- ggplot(dat_plot, aes(x = Income, fill = Caso)) + 
  geom_density(alpha = 0.3) + facet_grid(.~Sex) + 
  theme_bw()+ 
  geom_vline(xintercept = mean(encuesta$Income), 
             col = "red") +
  theme(legend.position = "none")
(p1/p2)
```

Si graficamos ahora la varibale gastos, se tienen los mismos resultados que para ingresos.


```{r, echo=TRUE, eval=TRUE}
p1 <- ggplot(dat_plot, aes(x = Expenditure, fill = Caso)) + 
  geom_density(alpha = 0.3) + theme_bw() +
  theme(legend.position = "bottom") +
  geom_vline(xintercept = mean(encuesta$Expenditure), 
             col = "red")

p2 <- ggplot(dat_plot, aes(x = Expenditure, fill = Caso)) + 
  geom_density(alpha = 0.3) + facet_grid(.~Sex) + 
  theme_bw()+ 
  geom_vline(xintercept = mean(encuesta$Expenditure), 
             col = "red") +
  theme(legend.position = "none")
(p1/p2)
```

Por otro lado, simulemos ahora una pérdida de información MAR como sigue:


```{r}
library(TeachingSampling)
set.seed(1234)
temp_estrato <- paste0(encuesta$Zone, encuesta$Sex) 
table(temp_estrato)
sel <- S.STSI(S = temp_estrato, 
              Nh = c(481,428,531,439),
              nh = c(20, 380, 20,280))
encuesta_MAR <- encuesta[-sel,]
dat_plot2 <- bind_rows(
  list(encuesta_MAR = encuesta_MAR,
       encuesta = encuesta), .id = "Caso"  )

```

El código anterior utiliza la librería *TeachingSampling* para realizar un muestreo aleatorio estratificado. Primero, se establece la semilla aleatoria en 1234 para asegurarse de que los resultados sean reproducibles. A continuación, se crea una variable llamada *temp_estrato* que combina dos variables de la encuesta "Zone" y "Sex" utilizando la función "paste0" para crear grupos de estratos. La función *table* se usa para mostrar la frecuencia de cada estrato.

Luego, se realiza el muestreo estratificado utilizando la función *S.STSI* que toma los siguientes argumentos:

-   "S": el vector de estratos creado anteriormente
-   "Nh": el número de unidades en cada estrato (en este caso, 469, 411, 510 y 390)
-   "nh": el tamaño de muestra deseado para cada estrato (en este caso, 20, 380, 20 y 280)

El resultado del muestreo estratificado es un vector de índices de fila que corresponden a las observaciones seleccionadas para la muestra. Luego, se crea un nuevo conjunto de datos llamado "encuesta_MAR" que excluye las observaciones seleccionadas en la muestra.

Finalmente, se usa la función *bind_rows* del paquete *dplyr* para unir los dos conjuntos de datos, "encuesta" y "encuesta_MAR", en un solo conjunto de datos llamado "dat_plot2", con una nueva variable "Caso" que indica el caso de cada observación en el conjunto de datos.

Observemos gráficamente el efecto de la perdida de dinformación en una encuesta en un esquema MAR:


```{r, echo=TRUE, eval=TRUE}
p1 <- ggplot(dat_plot2, aes(x= Caso, y = Expenditure)) + 
   geom_hline(yintercept = mean(encuesta$Expenditure), 
              col = "red") + 
  geom_boxplot() +
  facet_grid(Zone~Sex) + theme_bw()

p1
```

En el gráfico anterior se logra observar un cambio en la distribución de los datos en las distintas desagregaciones cuando en la encuesta no se tiene pérdida de información y cuando sí se tiene con un esquema MAR. Naturalmente, esto afectaría en las estimaciones finales que se hagan de los parámetros estudiados.


Con mayor claridad, se puede ver el cambio distribucional en la siguiente gráfica:

```{r, MAR2, echo=TRUE, eval=TRUE}
p1 <- ggplot(dat_plot2, aes(x = Income, fill = Caso)) + 
 geom_density(alpha = 0.3) + theme_bw() +
  theme(legend.position = "bottom") +
  geom_vline(xintercept = mean(encuesta$Income), 
             col = "red")

p2 <- ggplot(dat_plot2, aes(x = Income, fill = Caso)) + 
  facet_grid(.~Sex) +
  geom_density(alpha = 0.3) + theme_bw() +
  theme(legend.position = "none") +
  geom_vline(xintercept = mean(encuesta$Income), 
             col = "red")
p1/p2
```

Este comportamiento es natural que suceda en un esquema MAR de datos faltantes puesto que, como se mencionó anteriormente, cuando se dice que los datos faltantes están "missing at random" (MAR), significa que la probabilidad de que los datos estén ausentes está relacionada con los valores observados en otras variables del conjunto de datos. En otras palabras, la probabilidad de que un valor esté ausente no está relacionada con el valor real del dato en sí mismo, sino que depende de la distribución de los datos en otras variables.

La ventaja que tienen los mecanismo de missing MAR es que se puede estimar el valor real de los datos faltantes utilizando la información de otras variables disponibles en el conjunto de datos. Esto puede mejorar la calidad de los resultados de los análisis y evitar la necesidad de descartar observaciones con datos faltantes.

Otra gráfica en donde se evidencia el cambio de distribución de los gastos entre hombres y mujeres. 

```{r, MAR3, echo=TRUE, eval=TRUE}
p1 <- ggplot(dat_plot2, 
             aes(x = Expenditure, fill = Caso)) + 
 geom_density(alpha = 0.3) + theme_bw() +
  theme(legend.position = "bottom") +
  geom_vline(
    xintercept = mean(encuesta$Expenditure), 
             col = "red")

p2 <- ggplot(dat_plot2, 
             aes(x = Expenditure, fill = Caso)) + 
  facet_grid(.~Sex) +
  geom_density(alpha = 0.3) + theme_bw() +
  theme(legend.position = "none") +
  geom_vline(
    xintercept = mean(encuesta$Expenditure), 
             col = "red")
p1/p2
```

Ahora bien, para seguir con la ejemplificación de los esquemas de datos faltantes, generemos ahora un esquema de pérdida de información en una encuesta NMAR (siglas en inglés de "Not Missing at Random"). Como se mencionó al inicio de este capítulo, en este tipo de esquema, la probabilidad de que un dato falte está relacionada con el propio valor de ese dato, es decir, la probabilidad de que falte un dato no es aleatoria y depende de alguna característica o variable del propio dato.

En otras palabras, en un esquema aleatorio NMAR, la probabilidad de que falte un dato no es independiente del valor de ese dato, sino que está influenciada por algún factor que puede estar relacionado con el fenómeno que se está estudiando. Esto puede llevar a que los datos faltantes introduzcan un sesgo en los resultados del análisis estadístico, lo que hace que el manejo adecuado de los datos faltantes en este tipo de esquemas sea particularmente importante en la investigación.


```{r, eval=TRUE}
encuesta_MNAR <- encuesta %>% 
  arrange((Income)) %>% 
  slice(1:1300L)

dat_plot3 <- bind_rows(
  list(encuesta_MNAR = encuesta_MNAR,
       encuesta = encuesta), .id = "Caso"  )
```

El código anterior tiene como objetivo crear un nuevo conjunto de datos llamado *encuesta_MNAR* que contiene las primeras 1300 observaciones del conjunto de datos original *encuesta*, ordenadas por la variable *Income*. Luego, el código une el conjunto de datos original *encuesta* con el conjunto de datos *encuesta_MNAR* usando la función *bind_rows()*, y crea una nueva variable llamada "Caso" que indica la fuente de los datos.

Ahora bien, para ver el efecto que tiene en una encuesta el tener datos faltante con esquema NMAR, se ilustran los siguientes gráficos:

```{r, MNAR1, echo=TRUE, eval=TRUE}
p1 <- ggplot(dat_plot3, aes(x = Income, fill = Caso)) + 
  geom_density(alpha = 0.2) + theme_bw() +
   theme(legend.position = "bottom") +
  geom_vline(
    xintercept = mean(encuesta$Income), 
             col = "red") +
  geom_vline(
    xintercept = mean(encuesta_MNAR$Income), 
             col = "blue")
p1
```

Como se puede observar en la gráfica anterior, la distribución de los ingresos cambia notablemente cuando se tienen datos faltantes con esquema NMAR, lo mismo sucede con la variable gastos, como se puede observar en la siguiente gráfica:

```{r, MNAR2, echo=TRUE, eval=TRUE}
p1 <- ggplot(dat_plot3, 
             aes(x = Expenditure, fill = Caso)) + 
  geom_density(alpha = 0.2) + theme_bw() +
   theme(legend.position = "bottom") +
  geom_vline(
    xintercept = mean(encuesta$Expenditure), 
             col = "red") +
  geom_vline(
    xintercept = mean(encuesta_MNAR$Expenditure), 
             col = "blue")
p1
```

Para ver más al detalle el impacto que tiene la no respuesta con un esquema NMAR, a continuación se muestra una gráfica del ingreso discriminada por sexo y por zona. También se nota un cambio en la distribución de los ingresos significativos.

```{r, MNAR3, echo=TRUE, eval=TRUE}
p1 <- ggplot(dat_plot3, aes(x= Caso, y = Income)) + 
   geom_hline(yintercept = mean(encuesta$Income),
              col = "red") +  geom_boxplot() +
  facet_grid(Zone~Sex) + theme_bw()

p1
```

Para efectos de ejemplificar la solución del problema a los datos faltantes en una encuesta de hogares, generemos la siguiente base de datos:

```{r}
encuesta <- full_join(
  encuesta,
  encuesta_MCAR %>% 
    dplyr::select(HHID, PersonID, Income, Employment) %>%
    mutate(
      Income_missin = Income,
      Employment_missin = Employment,
      Employment = NULL,
      Income = NULL
    )
)
```

El código anterior utiliza la función *full_join()* de la librería *dplyr* de ´R´ para combinar dos conjuntos de datos: encuesta y encuesta_MCAR. La combinación se realiza mediante la unión completa (o full join), que devuelve todas las filas de ambas tablas, uniendo las filas con valores coincidentes y rellenando con valores faltantes para las columnas que no tienen una coincidencia en ambas tablas.

La segunda Base de datos, encuesta_MCAR, se transforma previamente con las siguientes operaciones:

-   Se seleccionan las columnas HHID, PersonID, Income y Employment mediante la función *dplyr::select()*.

-   Se agregan dos nuevas columnas, Income_missin y Employment_missin, utilizando la función mutate(). 

Los valores de estas columnas son idénticos a los de las columnas Income y Employment, respectivamente. Las columnas Income y Employment se eliminan del conjunto de datos utilizando la función *mutate()* y asignando el valor NULL a ambas columnas. Finalmente, el resultado de la unión completa se asigna a la variable encuesta.

Ahora bien, para tener como referencia el porcentaje de datos faltantes, se ejecuta el siguiente comando:

```{r}
encuesta %>% group_by(Zone) %>% 
  summarise(Income = sum(is.na(Income_missin) / n()))

encuesta %>% group_by(Sex) %>% 
  summarise(Income = sum(is.na(Income_missin) / n()))


```

## Imputación por la media no condicional.

La imputación por la media no condicional consiste en reemplazar los valores faltantes con la media aritmética de la variable completa, sin tener en cuenta ninguna otra variable. Es decir, la media se calcula a partir de todos los valores disponibles en la variable en cuestión, independientemente de las características de los demás datos.

Este método es bastante simple y rápido, y puede ser útil en ciertas situaciones, especialmente cuando la variable en cuestión no tiene una distribución muy sesgada o cuando los valores faltantes son relativamente pocos en comparación con el tamaño de la muestra. Sin embargo, el método de imputación por la media no condicional también tiene limitaciones y puede no ser adecuado en todas las situaciones, especialmente cuando hay sesgos o patrones en los datos faltantes o cuando los datos están altamente correlacionados. Adicionalmente, este método no afecta el promedio, pero si afecta la variabilidad, el sesgo y los percentiles. A continuación, se ejemplifica con los datos de ejemplo este método:


```{r, eval=TRUE}
promedio <- mean(encuesta$Income_missin, na.rm = TRUE)
encuesta %<>% dplyr::mutate(
    Income_imp = ifelse(is.na(Income_missin), 
                           promedio, Income_missin))
sum(is.na(encuesta$Income_imp))
```

En el código anterior la imputación se realiza utilizando la media aritmética de los valores no faltantes en *Income_missin* y se almacena en una nueva variable llamada *Income_imp*. A continuación, se describen cada una de las líneas del código: 

-   promedio <- mean(encuesta$Income_missin, na.rm = TRUE): esta línea calcula la media aritmética de los valores no faltantes en la columna *Income_missin* de la base de datos *encuesta* y la almacena en una variable llamada *promedio*. El argumento *na.rm = TRUE* se utiliza para excluir los valores faltantes en el cálculo de la media.

-   encuesta %<>%: este operador de *magrittr (%<>%)* se utiliza para asignar el resultado de la siguiente operación al objeto *encuesta*. Es equivalente a utilizar *encuesta <- encuesta %>%*.

-   mutate: esta función de *dplyr* se utiliza para crear una nueva columna en la base de datos *encuesta* con la imputación de los valores faltantes.

-   Income_imp = ifelse(is.na(Income_missin), promedio, Income_missin): esta línea utiliza la función *ifelse* para asignar el valor imputado a la columna *Income_imp* en la base de datos *encuesta*. Si un valor en la columna *Income_missin* es NA (es decir, faltante), se reemplaza con el valor de promedio. Si no es NA, se mantiene el valor original.

-   sum(is.na(encuesta$Income_imp)): esta línea cuenta el número de valores faltantes en la nueva *columna Income_imp* de la base de datos encuesta utilizando la función *sum* y *is.na*.


```{r, Media_1, echo=TRUE, eval=TRUE}
## Ordenando la base para gráfica 
dat_plot4 <- tidyr::gather(
  encuesta %>% dplyr::select(Zone,Sex,Income, Income_imp),
  key = "Caso", value = "Income2", -Zone,-Sex)

p1 <- ggplot(dat_plot4, aes(x = Income2, fill = Caso)) + 
  geom_density(alpha = 0.2) + theme_bw() +
   theme(legend.position = "bottom") +
  geom_vline(
    xintercept = mean(encuesta$Income), 
             col = "red") +
  geom_vline(
    xintercept = mean(encuesta$Income_imp), 
             col = "blue")
p1
```

En la gráfica anterior se puede observar que, a pesar de ser imputada la variable ingresos utilizando la media incondicional, la distribución real y la imputada cambia de manera significativa lo que demuestra que este método, para este conjunto de datos no es el más apropiado dado lo sesgado de la distribución de la variable ingresos.

Un caso similar al anterior ocurre si graficamos la variable ingreso por zona y sexo. A continuación, se muestra de manera gráfica los boxplot para revisar la distribución de los datos, arrojando nuevamente las conclusiones obtenidas con el gráfico anterior:

```{r, echo=TRUE, eval=TRUE}
p1 <- ggplot(dat_plot4, aes(x= Caso, y = Income2)) + 
   geom_hline(yintercept = mean(encuesta$Income),
              col = "red") +  geom_boxplot() +
  facet_grid(Zone~Sex) + theme_bw()

p1
```

## Imputación por la media condicional

El método de imputación por la media condicional es una técnica utilizada en el análisis de datos para tratar valores faltantes o perdidos en una variable numérica. A diferencia del método de imputación por la media no condicional, el método de imputación por la media condicional tiene en cuenta otras variables en el conjunto de datos al calcular la media.

La imputación por la media condicional se basa en la idea de que la media de una variable puede variar en función de los valores de otras variables. Por lo tanto, en lugar de simplemente reemplazar los valores faltantes con la media aritmética de la variable completa, se utiliza la media de la variable para grupos de observaciones que tienen valores similares en otras variables.

Por ejemplo, si se tiene una variable numérica llamada "Ingreso" y una variable categórica llamada "Educación", se podría utilizar la media de ingresos para cada nivel de educación para imputar los valores faltantes en la variable "Ingreso". De esta manera, se tiene en cuenta la relación entre la educación y el ingreso al realizar la imputación.

El método de imputación por la media condicional puede ser más preciso que el método de imputación por la media no condicional en situaciones en las que las variables están correlacionadas o cuando hay patrones de valores faltantes en los datos. Sin embargo, también puede ser más complicado y requiere más tiempo y recursos computacionales para implementar. A continuación, se ejemplifica la técnica de imputación utilizando la variable estrato (Stratum en la base de datos) para hacer el cálculo de los promedios por cada uno de los estratos y así poder imputar los datos faltantes. Asumiendo que hay una relación directa entre los estratos y los ingresos de los hogares:

```{r}
encuesta %<>% group_by(Stratum) %>%
  mutate( Income_imp = ifelse(is.na(Income_missin),
     mean(Income_missin, na.rm = TRUE),
     Income_missin)) %>% data.frame()
sum(is.na(encuesta$Income_imp))
encuesta %<>%
  mutate( Income_imp = ifelse(is.na(Income_imp), 
                           promedio, Income_imp))
sum(is.na(encuesta$Income_imp))
```

A continuación, se decribe el código computacional utilizado:

-   encuesta %<>% group_by(Stratum) %>%: este código utiliza la función *group_by* de *dplyr* para agrupar las observaciones de la base de datos encuesta por los niveles de la variable *Stratum*. El operador %>% se utiliza para concatenar este código con el siguiente código en una sola cadena de operaciones.

-   mutate: esta función de *dplyr* se utiliza para crear una nueva columna en la base de datos encuesta con la imputación de los valores faltantes.

-   Income_imp = ifelse(is.na(Income_missin), mean(Income_missin, na.rm = TRUE), Income_missin)): esta línea utiliza la función *ifelse* para asignar el valor imputado a la columna *Income_imp* en la base de datos encuesta. Si un valor en la columna *Income_missin* es NA (es decir, faltante), se reemplaza con la media aritmética de los valores no faltantes en *Income_missin* dentro del grupo correspondiente. Si no es NA, se mantiene el valor original.

-   sum(is.na(encuesta$Income_imp)): esta línea cuenta el número de valores faltantes en la nueva columna *Income_imp* de la base de datos encuesta utilizando la función *sum* y *is.na*.

-   encuesta %<>% mutate( Income_imp = ifelse(is.na(Income_imp), promedio, Income_imp)): este código utiliza la función *mutate* para crear una nueva columna en la base de datos encuesta y reemplazar cualquier valor faltante en la columna *Income_imp* con la media aritmética de los valores no faltantes en *Income_missin*. El valor de la media aritmética se almacena en una variable llamada promedio. Si un valor en la columna *Income_imp* no es NA, se mantiene el valor original.

-   sum(is.na(encuesta$Income_imp)): esta línea cuenta el número de valores faltantes en la nueva columna *Income_imp* de la base de datos encuesta utilizando la función *sum* y *is.na*.

A continuación, se calculan las medias y desviaciones estándar tanto para los datos imputados como los originales y así poder comparar le efecto de la imputación realizada:

```{r}
encuesta %>% summarise(
  Income_ = mean(Income),
  Income_sd = sd(Income),
  Income_imp_ = mean(Income_imp),
  Income_imp_sd = sd(Income_imp))
```

Para poder comparar los resultados, calculemos el sesgo relativo de la imputación el cual se calcula como sigue:

$$
BR=\frac{Income-Income_{imp}}{Income}\times100\%
$$

```{r}
100*(604.2494- 611.545)/604.2494
```

Como se puede observar, el sesgo relativo para el primedio de los ingresos es menor al 1.5%. Ahora bien, siguiendo la misma idea, el sesgo relativo para la desviación es:


```{r}
100*(513.1078- 488.7209)/513.1078
```

Lo que generó un sesgo relativo para la desviación estándar inferior al 5%. Ahora bien, si se realiza la imputación utilizando la media condicional agrupando por la variable zona, se tienen los siguientes resultados:

```{r}
encuesta %>%group_by(Zone) %>%  summarise(
  Income_ = mean(Income),
  Income_sd = sd(Income),
  Income_imp_ = mean(Income_imp),
  Income_imp_sd = sd(Income_imp))
```

Realizando el mismo ejercicio anterior, se obtienen sesgos relativos para la media de los ingresos para la zona rural de 1.87%:


```{r}
100*(469.1217- 477.9042)/469.1217
```

y para la zona urbana de 0.8%.:


```{r}
100*(730.8793- 736.7815)/730.8793
```

En ambos casos se observa una buena imputación de los ingresos. Ejercicio similar se puede realizar para sexo (Se le deja al lector realizar el cálculo del sesgo relativo).

```{r}
encuesta %>%group_by(Sex) %>%  summarise(
  Income_ = mean(Income),
  Income_sd = sd(Income),
  Income_imp_ = mean(Income_imp),
  Income_imp_sd = sd(Income_imp))
```

Ahora bien, para observar la distribución de los datos imputados en comparación con los no imputado se realizan las siguientes gráficas: 

```{r, echo=TRUE, eval=TRUE}

dat_plot5 <- tidyr::gather(
  encuesta %>% dplyr::select(Zone,Sex,Income, Income_imp),
  key = "Caso", value = "Income2", -Zone,-Sex)

p1 <- ggplot(dat_plot5, aes(x = Income2, fill = Caso)) + 
  geom_density(alpha = 0.2) + theme_bw() +
   theme(legend.position = "bottom") +
  geom_vline(
    xintercept = mean(encuesta$Income), 
             col = "red") +
  geom_vline(
    xintercept = mean(encuesta$Income_imp), 
             col = "blue")
p1
```

Se puede observar que de manera general, la distribución de las observaciones imputadas y originales tienen un comportamiento mejor que con la media no condicional.

Si se observa ahora la distribunción de los datos por zona y sexo, se puede observar también una buena imputación de las observaciones.

```{r, echo=TRUE, eval=TRUE}
p1 <- ggplot(dat_plot5, aes(x= Caso, y = Income2)) + 
   geom_hline(yintercept = mean(encuesta$Income),
              col = "red") +  geom_boxplot() +
  facet_grid(Zone~Sex) + theme_bw()
p1
```

## Imputación por Hot-deck y Cold-deck

La imputación *Hot deck* consiste en reemplazar los valores faltantes de una o más variables para un no encuestado (llamado receptor) con valores observados de un encuestado (el donante) que es similar al no encuestado con respecto a las características observadas en ambos casos.

La técnica se basa en la idea de que las observaciones similares pueden tener valores similares para las variables de interés. En el enfoque por hot-deck, se selecciona una observación donante que sea similar a la observación receptora en términos de características relevantes (por ejemplo, edad, género, ubicación geográfica, etc.), y se utiliza su valor observado para imputar el valor faltante en la observación receptora.

El término "hot-deck" se refiere a una tarjeta perforada que se utilizaba en los primeros sistemas informáticos para almacenar y recuperar datos. En el enfoque por hot-deck, las observaciones se organizan en una "pila" o "mazo" de tarjetas, y las observaciones similares se seleccionan de esta pila para imputar los valores faltantes.

La imputación por hot-deck es una técnica relativamente simple y eficaz para imputar valores faltantes en conjuntos de datos pequeños o medianos, y se utiliza comúnmente en encuestas y estudios de investigación social. Sin embargo, puede ser menos efectiva en conjuntos de datos grandes o complejos, donde puede ser difícil encontrar observaciones similares o donde las características relevantes son difíciles de definir o medir de manera confiable.

Por otro lado, el método llamado *Cold-deck* por analogía con *Hot-deck* consiste en reemplazar el valor faltante por valores de una fuente no relacionada con el conjunto de datos en consideración. El método de imputación Cold-deck es una técnica de imputación de datos faltantes que se basa en la sustitución de los valores faltantes por valores observados de una fuente externa, tal como un conjunto de datos históricos, registros administrativos u otras fuentes de datos secundarios.

A diferencia del método de imputación por hot-deck, que utiliza información de la propia muestra para imputar los valores faltantes, el método de imputación cold-deck se basa en la utilización de información externa para sustituir los valores faltantes. La fuente de datos externa se utiliza para imputar los valores faltantes en la muestra de estudio.

El término "cold-deck" hace referencia a la tarjeta perforada que se utilizaba en los primeros sistemas informáticos para almacenar y recuperar datos. En el método de imputación cold-deck, los valores faltantes se imputan a partir de los datos de la "pila fría" o "mazo frío" de tarjetas perforadas, que corresponden a los datos históricos o a la fuente externa de datos.

El método de imputación cold-deck se utiliza a menudo cuando la muestra de estudio es pequeña o no hay suficientes observaciones similares para aplicar el método de imputación por hot-deck. Sin embargo, el método de imputación cold-deck tiene algunas limitaciones, como la posibilidad de que los datos externos no sean representativos de la muestra de estudio y la posibilidad de introducir errores en los datos imputados si la fuente de datos externa no es fiable o no es adecuada para la variable de interés.


*Imputación por hot-deck*

Iniciamos los ejemplos en esta sección con el método hot-deck. A continuación, se presenta un código computacional que ejemplifica, para los datos que estamos usando en el capítulo, el uso del método hot-deck.

```{r}
donante <- which(!is.na(encuesta$Income_missin))
receptor <- which(is.na(encuesta$Income_missin))
encuesta$Income_imp <- encuesta$Income_missin
set.seed(1234)
for(ii in receptor){
don_ii <- sample(x = donante, size = 1)
encuesta$Income_imp[ii] <- encuesta$Income_missin[don_ii]}
sum(is.na(encuesta$Income_imp))
```

El código mostrado anteriormente se describe a continuación:

-   La primera línea del código selecciona las observaciones que no tienen valores faltantes en la variable "Income_missin" utilizando la función *which* y el operador *!* (not) *donante <- which(!is.na(encuesta$Income_missin))*

-   La segunda línea selecciona las observaciones que tienen valores faltantes en la variable "Income_missin" utilizando la función *which* y el operador *is.na*. *receptor <- which(is.na(encuesta$Income_missin))*

-   La tercera línea crea una nueva variable "Income_imp" en la encuesta, que se utilizará para almacenar los valores imputados *encuesta$Income_imp <- encuesta$Income_missin*

-   La cuarta línea utiliza la función *set.seed* para establecer una semilla aleatoria para asegurar la reproducibilidad del proceso de imputación. *set.seed(1234)*

-   Se utiliza un bucle *for* para iterar a través de cada observación receptora. Dentro del bucle, se utiliza la función *sample* para seleccionar una observación donante aleatoria de entre las observaciones que no tienen valores faltantes en la variable "Income_missin".

Una vez realizada la imputación, se calcula la media y la desviación de los datos completos e imputados:

```{r}
encuesta %>% summarise(
  Income_ = mean(Income),
  Income_sd = sd(Income),
  Income_imp_ = mean(Income_imp),
  Income_imp_sd = sd(Income_imp))
```

Como en los métodos de imputación anterior, calculemos el sesgo relativo de la imputación el cual fue de 2.3%:

```{r}
100*(604.2494-618.2937)/604.2494
```

Ahora bien, haciendo el mismo ejercicio, pero esta vez desagregada por zona tenemos:

```{r}
encuesta %>%group_by(Zone) %>%  summarise(
  Income_ = mean(Income),
  Income_sd = sd(Income),
  Income_imp_ = mean(Income_imp),
  Income_imp_sd = sd(Income_imp))
```

El sesgo relativo de la estimación en la zona rural es de 7.4% y en al zona urbana es de 0.7%.

```{r}
100*(469.1217-503.7127)/469.1217

100*(730.8793-725.6691)/730.8793
```

El mismo ejercicio se puede realizar por sexo:

```{r}
encuesta %>%group_by(Sex) %>%  summarise(
  Income_ = mean(Income),
  Income_sd = sd(Income),
  Income_imp_ = mean(Income_imp),
  Income_imp_sd = sd(Income_imp))
```

Como en los ejercicios anteriores, a continuación, se muestra la gráfica de la distribución de los datos tanto los completos como los imputados observándose que la distribución de los datos imputados es muy similar a la de los datos no imputados:

```{r, hot_deck_1, echo=TRUE, eval=TRUE}

dat_plot6 <- tidyr::gather(
  encuesta %>% dplyr::select(Zone,Sex,Income, Income_imp),
  key = "Caso", value = "Income2", -Zone,-Sex)

p1 <- ggplot(dat_plot6, aes(x = Income2, fill = Caso)) + 
  geom_density(alpha = 0.2) + theme_bw() +
   theme(legend.position = "bottom") +
  geom_vline(
    xintercept = mean(encuesta$Income), 
             col = "red") +
  geom_vline(
    xintercept = mean(encuesta$Income_imp), 
             col = "blue")
p1
```

El mismo ejercicio anterior se realiza por zona y sexo obteniendo resultados similares a los abtenidos en el gráfico anterior:

```{r, echo=TRUE, eval=TRUE}
p1 <- ggplot(dat_plot6, aes(x= Caso, y = Income2)) + 
   geom_hline(yintercept = mean(encuesta$Income),
              col = "red") +  geom_boxplot() +
  facet_grid(Zone~Sex) + theme_bw()
p1
```

A continuación, se implementa el método de imputación pero para la variable empleado. Los códigos computacionales son similares a los empleados con la variable ingresos:

```{r}
donante <- which(!is.na(encuesta$Income_missin))
receptor <- which(is.na(encuesta$Income_missin))
encuesta$Employment_imp <- encuesta$Employment_missin
(prop <- prop.table(
  table(na.omit(encuesta$Employment_missin))))

set.seed(1234)
imp <- sample(size = length(receptor),
  c("Unemployed", "Inactive","Employed"),
       prob = prop, replace = TRUE     )
encuesta$Employment_imp[receptor] <- imp 
sum(is.na(encuesta$Employment_imp))
```

Se le deja al lector realizar los ejercicios de comprobación gráfica, como se mostró a lo largo de esta sección.

## Imputación por regresión

La imputación por regresión es una técnica de análisis de datos que se utiliza para imputar valores faltantes en un conjunto de datos. Esta técnica se basa en la construcción de un modelo de regresión a partir de las variables $X$ disponibles en el conjunto de datos, que se utiliza para predecir los valores faltantes $Y$. Cuando se habla de predicción no se refiere a dar un valor futuro, se refiere a dar un valor a la información faltante.

Para llevar a cabo la imputación por regresión, se selecciona una variable objetivo que tenga valores faltantes y se identifican las variables predictoras que tienen una correlación significativa con la variable objetivo. Se ajusta un modelo de regresión utilizando las variables predictoras y la variable objetivo disponible, y se utilizan los coeficientes del modelo para predecir los valores faltantes de la variable objetivo.

Es importante destacar que la imputación por regresión es una técnica estadística avanzada que requiere conocimientos sólidos de análisis de datos y modelado estadístico. Además, su aplicación puede verse limitada por la calidad y la cantidad de los datos disponibles y por la distribución de los valores faltantes en el conjunto de datos. Por lo tanto, es importante utilizarla con precaución y tener en cuenta sus limitaciones.

Para ejemplificar, imputemos la variable ingreso y la variable empleados tomadno como covariables las variable zona, sexo y empleamiento. Para la primera variable se utiliza un modelo de regresión líneal múltiple y para el segundo. se utiliza un modelo multinomial (dada la naturaleza de la variable) como se muestra a continución:

```{r, message=TRUE}
require(nnet)
encuesta$Income_imp <- encuesta$Income_missin
encuesta$Employment_imp <- encuesta$Employment_missin
encuesta_obs <- filter(encuesta, !is.na(Income_missin))
encuesta_no_obs <- filter(encuesta, is.na(Income_missin))
mod <- lm(Income~Zone + Sex +Expenditure, data = encuesta_obs)
mod.mult <- multinom(Employment~Zone + Sex +Expenditure, data = encuesta_obs)
```

Una vez ajustado los modelos tanto para las variable ingreso como para empleados, se realiza el proceso de predicción como se muestra a continuación:

```{r}
imp <- predict(mod, encuesta_no_obs)
imp.mult <- predict(mod.mult, encuesta_no_obs, type =  "class")
encuesta_no_obs$Income_imp <- imp
encuesta_no_obs$Employment_imp <- imp.mult
encuesta <- bind_rows(encuesta_obs,encuesta_no_obs)
```

A continuación, se presenta el porcentaje de datos faltantes en la variable empleado:
```{r}
prop.table(table(encuesta$Employment_missin, useNA = "a"))
```

Se puede observar que hay un 20% de datos faltantes. Una vez se realiza la imputación, se redistribuyen esas observaciones en las demás categorías arrojando los siguientes resultados: 

```{r}
prop.table(table(encuesta$Employment_imp, useNA = "a"))
```

A modo de ejercicio, se realiza el cálculo del porcentaje de los valores faltante para la variable empleados por zona, antes y después de imputar, reconociendo que, los porcentajes marginales por zona no varían:

```{r}
library(printr)
library(kableExtra)

kable(prop.table( table(encuesta$Zone, encuesta$Employment_missin, useNA = "a")) %>%               addmargins())

kable(
prop.table( table(encuesta$Zone, encuesta$Employment_imp,useNA = "a")) %>% addmargins()
)
```

El mismo ejercicio anterior se realiza por sexo arrojando los siguientes resultados:

```{r}
kable(
  prop.table( table(encuesta$Sex, encuesta$Employment_missin, useNA = "a")) %>% addmargins()
)

kable(
prop.table( table(encuesta$Sex, encuesta$Employment_imp,useNA = "a")) %>% addmargins()
)
```


Para finalizar y como se ha realizado con los métodos anteriores, se hace el cálculo de la variable ingreso completa e imputada:

```{r}
encuesta %>% summarise(
  Income_ = mean(Income),
  Income_sd = sd(Income),
  Income_imp_ = mean(Income_imp),
  Income_imp_sd = sd(Income_imp))
```

Teniendo un sesgo relativo de 1.2%.

```{r}
100*(604.2494 - 611.7477)/604.2494
```

Haciendo el mismo ejercicio por zona tenemos:

```{r}
encuesta %>%group_by(Zone) %>%  summarise(
  Income_ = mean(Income),
  Income_sd = sd(Income),
  Income_imp_ = mean(Income_imp),
  Income_imp_sd = sd(Income_imp))
```

Con sesgos relativos para la zona rural de 1.5% y para urbano de 1%.

```{r}
100*(469.1217 - 476.1361)/469.1217

100*(730.8793 - 738.8311)/730.8793
```

Para la variable sexo, se puede realizar el mismo ejercicio anterior. Se le deja al lector hacer los cálculos pertinentes: 

```{r}
encuesta %>%group_by(Sex) %>%  summarise(
  Income_ = mean(Income),
  Income_sd = sd(Income),
  Income_imp_ = mean(Income_imp),
  Income_imp_sd = sd(Income_imp))
```

Por último, los ejercicios gráficos se realizan a continuación:


```{r, echo=TRUE, eval=TRUE}

dat_plot7 <- tidyr::gather(
  encuesta %>% dplyr::select(Zone,Sex,Income, Income_imp),
  key = "Caso", value = "Income2", -Zone,-Sex)

p1 <- ggplot(dat_plot7, aes(x = Income2, fill = Caso)) + 
  geom_density(alpha = 0.2) + theme_bw() +
   theme(legend.position = "bottom") +
  geom_vline(
    xintercept = mean(encuesta$Income), 
             col = "red") +
  geom_vline(
    xintercept = mean(encuesta$Income_imp), 
             col = "blue")
p1
```


```{r, regresion_2, echo=TRUE, eval=TRUE}
p1 <- ggplot(dat_plot7, aes(x= Caso, y = Income2)) + 
   geom_hline(yintercept = mean(encuesta$Income),
              col = "red") +  geom_boxplot() +
  facet_grid(Zone~Sex) + theme_bw()
p1
```

Obteniendo buenos resultados en el proceso de imputación como se pudo observar en las gráficas anteriores.

## Imputación por el vecino más cercano

La imputación por el vecino más cercano (K-nearest neighbor imputation en inglés) es una técnica de análisis de datos utilizada para estimar los valores faltantes en un conjunto de datos. En esta técnica, los valores faltantes se reemplazan por valores de otras observaciones que son similares a la observación con valores faltantes.

La imputación por el vecino más cercano se basa en la idea de que los registros similares tienden a tener valores similares para una determinada variable. La técnica consiste en encontrar los $k$ registros más similares a la observación con valores faltantes en función de las variables disponibles en el conjunto de datos y utilizar los valores de estas observaciones para estimar el valor faltante.

Para calcular la similitud entre observaciones, se pueden utilizar diferentes medidas de distancia, como la distancia euclidiana o la distancia de Manhattan. La técnica también permite ajustar el valor de $k$, que representa el número de vecinos más cercanos utilizados para estimar el valor faltante.

Es importante destacar que la imputación por el vecino más cercano es una técnica relativamente simple y fácil de implementar. Sin embargo, su eficacia puede verse limitada por la cantidad y la calidad de los datos disponibles, así como por la elección de los parámetros (como el valor de $k$ y la medida de distancia) que pueden afectar significativamente los resultados obtenidos. Por lo tanto, es importante evaluar cuidadosamente la calidad de los datos y los resultados obtenidos antes de utilizar esta técnica.

Teniendo en cuenta lo anterior, se presentan 3 pasos a tener en cuenta al momento de utilizar esta técnica:

-   **Paso 1**: Definir una magnitud de distancia (Distancia euclidiana,
    k-media, K-Medioides, entre otras).
-   **Paso 2**: Para la $i$-ésimo elemento identificar el donante, cual será el
    más cercano al receptor según la magnitud de distancia previamente definida.
-   **Paso 3**: Se imputa el valor faltante con la información del donante
    identificado previamente.

Para ejemplificar esta metología, se va a imputar la variable ingresos y empleado utilizando como variable de apoyo los gastos del individuo. Se utilizará como distancia la euclidiana.

```{r}
encuesta$Income_imp <- encuesta$Income_missin
encuesta$Employment_imp <- encuesta$Employment_missin
encuesta_obs <- filter(encuesta, !is.na(Income_missin))
encuesta_no_obs <- filter(encuesta, is.na(Income_missin))

for(ii in 1:nrow(encuesta_no_obs)){

Expen_ii <- encuesta_no_obs$Expenditure[[ii]]
don_ii <- which.min(abs(Expen_ii - encuesta_obs$Expenditure))
encuesta_no_obs$Income_imp[[ii]] <- encuesta_obs$Income_missin[[don_ii]]
encuesta_no_obs$Employment_imp[[ii]] <- encuesta_obs$Employment_missin[[don_ii]]
}

encuesta <- bind_rows(encuesta_obs,encuesta_no_obs)
```

Como se hizo la revisión anterior, se calculan los porcentajes de datos faltantes y se revisa nuevamente la distribución de la imputación en las categorías de la variable empleado.
```{r}
prop.table(table(encuesta$Employment_missin, useNA = "a"))

prop.table(table(encuesta$Employment_imp, useNA = "a"))

```

Haciendo el mismo ejercicio por zona se tiene:

```{r}
kable(
prop.table( table(encuesta$Zone, encuesta$Employment_missin, useNA = "a")) %>% addmargins()
)

kable(
prop.table( table(encuesta$Zone, encuesta$Employment_imp,useNA = "a")) %>% addmargins()
)
```

Al igual que en el caso anterior, la distribución marginal por zona no se altera. Ahora por sexo la distribución es la siguiente:

```{r}
kable(
prop.table( table(encuesta$Sex, encuesta$Employment_missin, useNA = "a")) %>% addmargins()
)

kable(
prop.table( table(encuesta$Sex, encuesta$Employment_imp,useNA = "a")) %>% addmargins()
)
```

Ahora, haciendo el cálculo del promedio de los ingresos para los datos completos y estimados se tienen los siguientes resultados:

```{r}
encuesta %>% summarise(
  Income_ = mean(Income),
  Income_sd = sd(Income),
  Income_imp_ = mean(Income_imp),
  Income_imp_sd = sd(Income_imp))
```

Se observa que hay una diferencia de 6 unidades monetarias entre el promedio real y el estimado. Realizando este mismo ejercicio por zona tenemos:

```{r}
encuesta %>%group_by(Zone) %>%  summarise(
  Income_ = mean(Income),
  Income_sd = sd(Income),
  Income_imp_ = mean(Income_imp),
  Income_imp_sd = sd(Income_imp))
```

Obteniéndose diferencias de 7 unidades monetarias en el ingreso para la zona rural y de 4 para la urbana. Este mismo ejercicio se realiza por sexo teniendo los siguientes resultados:

```{r}
encuesta %>%group_by(Sex) %>%  summarise(
  Income_ = mean(Income),
  Income_sd = sd(Income),
  Income_imp_ = mean(Income_imp),
  Income_imp_sd = sd(Income_imp))
```

Obteniéndose diferencias pequeñas entre el ingreso real y el estimado en ambos sexos.

```{r, Vecino_1, echo=TRUE, eval=TRUE}

dat_plot8 <- tidyr::gather(
  encuesta %>% dplyr::select(Zone,Sex,Income, Income_imp),
  key = "Caso", value = "Income2", -Zone,-Sex)

p1 <- ggplot(dat_plot8, aes(x = Income2, fill = Caso)) + 
  geom_density(alpha = 0.2) + theme_bw() +
   theme(legend.position = "bottom") +
  geom_vline(
    xintercept = mean(encuesta$Income), 
             col = "red") +
  geom_vline(
    xintercept = mean(encuesta$Income_imp), 
             col = "blue")
p1
```

Se puede observar que la distribución de los datos imputados son muy próximos que los datos reales. Haciendo este mismo ejercicio pero por zona y sexo se obtienen resultados similares a los anteriores:

```{r, Vecino_2, echo=TRUE, eval=TRUE}
p1 <- ggplot(dat_plot8, aes(x= Caso, y = Income2)) + 
   geom_hline(yintercept = mean(encuesta$Income),
              col = "red") +  geom_boxplot() +
  facet_grid(Zone~Sex) + theme_bw()
p1
```

## Imputación por el vecino más cercano con regresión

An las secciones anteriores se realizaron las descripciones delas técnicas: vecino más cercano e imputación vía regresión, a continuación, se presentan los pasos que se deben tener en cuenta para realizar la imputación utilizando el vecino más cernado mediante una regresión:

-   **Paso 1**: Ajustar un modelo de regresión.
-   **Paso 2**: Realizar la predicción de los valores observados y no
    observados.
-   **Paso 3**: Comparar las predicciones obtenidas para los valores observados
    y no observados.
-   **Paso 4**: Para la $i$-ésima observación identificar el donante con la
    menor distancia al receptor.
-   **Paso 5**: Reemplazar el valor faltante con la información proveniente del
    donante.

*NOTA* Se toma es la información observada en el donante.

A continuación, se ejemplifica la técnica imputando los ingresos en los hogares realizando un modelo en el cual se toman como covariables el sexo, la zona y los gastos:


```{r,eval=TRUE}
encuesta$Income_imp <- encuesta$Income_missin
encuesta$Employment_imp <- encuesta$Employment_missin
encuesta_obs <- filter(encuesta, !is.na(Income_missin))
encuesta_no_obs <- filter(encuesta, is.na(Income_missin))
mod <- lm(Income ~ Zone + Sex + Expenditure, data = encuesta_obs)

```

Luego, se predicen los valores observados y no observados con el modelo ajustado anteriormente y se imputa el valor faltante calculando las diferencias entre las predicciones de los datos observados y no observados:

```{r}
pred_Obs <- predict(mod, encuesta_obs)
pred_no_Obs <- predict(mod, encuesta_no_obs)

for(ii in 1:nrow(encuesta_no_obs)){

don_ii <- which.min(abs(pred_no_Obs[ii] - pred_Obs))
encuesta_no_obs$Income_imp[[ii]] <- encuesta_obs$Income_missin[[don_ii]]
encuesta_no_obs$Employment_imp[[ii]] <- encuesta_obs$Employment_missin[[don_ii]]
}

encuesta <- bind_rows(encuesta_obs,encuesta_no_obs)
```

Una vez imputada la información, se puede chequear el pocentaje de datos faltantes que habían y una vez impuatado, cómo cambia la distribución:

```{r}
kable(
prop.table(table(encuesta$Employment_missin, useNA = "a"))
)

kable(
prop.table(table(encuesta$Employment_imp, useNA = "a"))
)
```

El mismo ejercicio se puede realizar por zona:

```{r}
kable(
prop.table( table(encuesta$Zone, encuesta$Employment_missin, useNA = "a")) %>% addmargins()
)

kable(
prop.table( table(encuesta$Zone, encuesta$Employment_imp,useNA = "a")) %>% addmargins()
)
```

Y por sexo:

```{r}
kable(
prop.table( table(encuesta$Sex, encuesta$Employment_missin, useNA = "a")) %>% addmargins()
)

kable(
prop.table( table(encuesta$Sex, encuesta$Employment_imp,useNA = "a")) %>% addmargins()
)
```

Por último, se calcula la media de los ingresos y su desviación estándar para los datos completos e imputado como se ha realizado anteriormente:

```{r}
encuesta %>% summarise(
  Income_ = mean(Income),
  Income_sd = sd(Income),
  Income_imp_ = mean(Income_imp),
  Income_imp_sd = sd(Income_imp))
```

De la anterior imputación se puede observar que, la diferencia entre los datos reales y los imputados es cercano a 4 unidades monetarias.

El mismo ejercicio realizado por zona arroja los siguientes resultados:

```{r}
encuesta %>%group_by(Zone) %>%  summarise(
  Income_ = mean(Income),
  Income_sd = sd(Income),
  Income_imp_ = mean(Income_imp),
  Income_imp_sd = sd(Income_imp))
```

y se puede observar también que la diferencia entre los ingresos reales y los estimados en las dos zonas con inferiores a 6 unidades monetarias.

Por sexo, los resultados son los siguientes:

```{r}
encuesta %>%group_by(Sex) %>%  summarise(
  Income_ = mean(Income),
  Income_sd = sd(Income),
  Income_imp_ = mean(Income_imp),
  Income_imp_sd = sd(Income_imp))
```
Teniendo como diferencia máxima para la variable ingreso de 5 unidades monetarias. A continuación, se presentan la gráfica distribucional del ingreso real y del ingreso imputado por el método del vecino más cercano mediante un modelo. Se puede observar que, las dos distribuciones con muy similares.

```{r, echo=TRUE, eval=TRUE}
dat_plot9 <- tidyr::gather(
  encuesta %>% dplyr::select(Zone,Sex,Income, Income_imp),
  key = "Caso", value = "Income2", -Zone,-Sex)

p1 <- ggplot(dat_plot9, aes(x = Income2, fill = Caso)) + 
  geom_density(alpha = 0.2) + theme_bw() +
   theme(legend.position = "bottom") +
  geom_vline(
    xintercept = mean(encuesta$Income), 
             col = "red") +
  geom_vline(
    xintercept = mean(encuesta$Income_imp), 
             col = "blue")
p1
```

Realizando ahora unos boxplot por sexo y zona para la variable ingreso tanto la completa como la imputada se tiene:


```{r, echo=TRUE, eval=TRUE}
p1 <- ggplot(dat_plot9, aes(x= Caso, y = Income2)) + 
   geom_hline(yintercept = mean(encuesta$Income),
              col = "red") +  geom_boxplot() +
  facet_grid(Zone~Sex) + theme_bw()
p1
```
Se puede observar que los boxplot son muy similares.


## Introducción a la imputación múltiple.

La imputación múltiple, también conocida como "multiple imputations" en inglés, es una técnica estadística utilizada para tratar los datos faltantes o incompletos en un conjunto de datos. La imputación múltiple consiste en crear múltiples copias del conjunto de datos, donde los valores faltantes en cada copia son imputados utilizando modelos estadísticos. Estos modelos se basan en las relaciones entre las variables en el conjunto de datos y se utilizan para estimar los valores faltantes de manera plausible.

Luego de que se han creado múltiples copias completas del conjunto de datos, se realizan análisis separados en cada copia para generar resultados. Los resultados de cada análisis se combinan para obtener un único resultado final que refleje la incertidumbre causada por la imputación de los valores faltantes.

La imputación múltiple es una técnica poderosa para lidiar con los datos faltantes, ya que proporciona resultados más precisos y menos sesgados en comparación con otros métodos que simplemente eliminan las observaciones con valores faltantes. Sin embargo, la imputación múltiple es un proceso computacionalmente intensivo y requiere un conocimiento sólido de la teoría estadística para su implementación efectiva.

En este sentido, suponga entonces que existe un conjunto de $n$ datos que relaciona dos variables $X$, $Y$, a través del siguiente modelo de regresión simple:

$$y_i = \beta x_i + \varepsilon_i$$ 
Para todo individuo $i = 1, \ldots, n.$, de tal manera que los errores tienen distribución normal con $E(\varepsilon) = 0$ y $Var(\varepsilon) = \sigma ^2$.

Ahora bien, se debe tener en cuenta, para utilizar la metodología, los siguientes atributos:

-   Sea $Y_{Obs}$ los valores observados para un conjunto de individuos de
    tamaño $n_1$.
-   Sea $Y_{NoObs}$ los valores **NO** observados de la variable $Y$ de tamaño
    $n_0$, es decir, $n_1 + n_0 = n$.\
-   Suponga que sí fue posible observar los valores de la covariable $X$ para
    todos los individuos en la muestra.
    
A modo de ejemplificar la teoría, realicemos un ejercicio de simulación de la siguiente manera. Simular un conjunto de $n = 500$ datos con una pendiente $\beta = 10$ y con una dispersión de $\sigma = 2$. A su vez, el conjunto de datos tendrá $n_0 = 200$ valores faltantes en la variable respuesta.

El algoritmo de simulación es el siguiente:

```{r}
generar <- function(n = 500, n_0 = 200, 
                    beta = 10, sigma = 2){
  x <- runif(n)
  mu <- beta * x
  y <- mu + rnorm(n, mean = 0, sd = sigma)
  datos <- data.frame(x = x, y = y)
  faltantes <- sample(n, n_0)
  datos$faltantes <- "No"
  datos$faltantes[faltantes] <- "Si"
  datos$y.per <- y
  datos$y.per[faltantes] <- NA
  return(datos)
}
```

El código anterior realiza lo siguiente:

-   *generar <- function(n = 500, n_0 = 200, beta = 10, sigma = 2){*:Esta línea de código define la función "generar" con cuatro argumentos opcionales: n, n_0, beta y sigma.

-   *x <- runif(n)*: Esta línea genera una secuencia de n números aleatorios uniformemente distribuidos en el intervalo [0,1] y los asigna a la variable "x".

-   **mu <- beta * x**: Esta línea de código calcula la media condicional de "y" (la variable de respuesta) dada "x" utilizando el parámetro de pendiente "beta" y lo asigna a la variable "mu".

-   *y <- mu + rnorm(n, mean = 0, sd = sigma)*: Esta línea genera una variable de respuesta "y" a partir de la media condicional "mu" y agrega un error aleatorio generado a partir de una distribución normal con media cero y desviación estándar "sigma".

-   *datos <- data.frame(x = x, y = y)*: Esta línea combina las variables "x" e "y" en un data frame llamado "datos".

-   *faltantes <- sample(n, n_0)*: Esta línea genera una muestra aleatoria de "n_0" valores únicos desde un rango de 1 hasta "n" (la longitud de los datos) y los asigna a la variable "faltantes".

-   *datos$faltantes <- "No"*, *datos$faltantes[faltantes] <- "Si"*: Esta línea crea una nueva columna en el data frame "datos" llamada "faltantes" y la inicializa con valores "No" para todas las observaciones. Luego, establece los valores de esta columna en "Si" para las filas seleccionadas por la muestra aleatoria anterior.

-   *datos$y.per <- y*, *datos$y.per[faltantes] <- NA*: Esta línea crea una nueva columna en el data frame "datos" llamada "y.per" y la inicializa con los mismos valores que "y". Luego, establece los valores de esta columna en "NA" para las filas seleccionadas por la muestra aleatoria anterior, lo que simula valores faltantes en los datos de "y".

Una vez creada la función anterior, se genera la población usando una semilla para poder reproducirla: 

```{r}
set.seed(1234)
datos <- generar()
head(datos,12)
```

A continuación, se grafican la relación entre "x" y "y" y "x" y "y.per" notando que, la distribución entre las dos relaciones es muy similar.

```{r, echo=TRUE,eval=TRUE}
library(patchwork)
p1 <- ggplot(data = datos, aes(x = x, y = y)) +
  geom_point() + geom_smooth(formula = y~x , method = "lm")

p2 <- ggplot(data = datos, aes(x = x, y = y.per)) +
  geom_point() + geom_smooth(formula = y~x , method = "lm")
  
p1 | p1
```

Ahora, dado el 40% de valores faltantes, es necesario imputar dichos valores. Para esto, utilizaremos la técnica de imputación múltiple propuesta por **Rubin (1987)**. La idea consiste en generar $M > 1$ conjuntos de valores
para los datos faltantes. Al final, el valor *imputado* corresponderá al
promedio de esos $M$ valores.

Hay varias maneras de realizar la imputación, a continuación, se hace un listado:

-   **Ingenua**: Esta clase de imputación carece de aleatoriedad y por tanto, la
    varianza de $\beta$ va a ser subestimada.

-   **Bootstrap**: Se seleccionan $m$ muestras bootstrap, y para cada una se
    estiman los parámetros $\beta$ y $\sigma$ para generar $\dot{y}_i$. Al final
    se promedian los $m$ valores y se imputa el valor faltante.
    
-   **Bayesiana**: Se definen las distribuciones posteriores de $\beta$ y
    $\sigma$ para generar $M$ valores de estos parámetros y por tanto $M$
    valores de $\dot{y}_i$. Al final se promedian los $M$ valores y se imputa el
    valor faltante.

Dado que el interés es la estimación de la pendiente de la regresión lineal simple
$\beta$, entonces la esperanza estimada al utilizar la metodología de imputación
múltiple está dada por:

$$E(\hat{\beta} | Y_{obs}) = E(E(\hat{\beta} | Y_{obs}, Y_{mis}) | Y_{obs})$$

Esta expresión es estimada por el promedio de las $M$ estimaciones puntuales de
$\hat{\beta}$ sobre las $M$ imputaciones, dado por:

$$\bar{\hat{\beta}} = \frac{1}{M} \sum_{m = 1} ^ M \hat{\beta}_m$$

La varianza estimada al utilizar la metodología de imputación múltiple está dada
por la siguiente expresión: 

$$
V(\hat{\beta} | Y_{obs}) = E(V(\hat{\beta} | Y_{obs}, Y_{mis}) | Y_{obs}) +
V(E(\hat{\beta} | Y_{obs}, Y_{mis}) | Y_{obs}) 
$$
La primera parte de la anterior expresión se estima como el promedio de las
varianzas muestrales de $\hat{\beta}$ sobre las $M$ imputaciones, dado por:

$$\bar{U} = \frac{1}{M} \sum_{m = 1} ^ M Var(\beta)$$

El segundo término se estima como la varianza muestral de las $M$ estimaciones
puntuales de $\hat{\beta}$ sobre las $M$ imputaciones, dada por:

$$B = \frac{1}{M-1} \sum_{m = 1} ^ M (\hat{\beta}_m - \bar{\hat{\beta}})$$


Es necesario tener en cuenta un factor de corrección (puesto que $M$ es finito).
Por tanto, la estimación del segundo término viene dada por la siguiente
expresión: 
$$
(1 + \frac{1}{M}) B
$$

Por tanto, la varianza estimada es igual a:
$$\hat{V}(\hat{\beta} | Y_{obs}) = \bar{U} + (1 + \frac{1}{M}) B$$
A modo de ejemplo, a continuación, se crea una función que haga la estimación de los valores faltantes usando bootstrap:

```{r boot0, eval=TRUE, echo=TRUE}
im.bootstrap <- function(datos, M = 15){
  library(dplyr)
  n <- nrow(datos)
  datos1 <- na.omit(datos)
  n1 <- nrow(datos1)
  n0 <- n - n1
  Ind <- is.na(datos$y.per)
  faltantes.boot <- NULL
  beta1 <- NULL
  sigma1 <- NULL
  
  for (m in 1:M){
    datos.m <- dplyr::sample_n(datos1, n1, replace = TRUE)
    model1 <- lm(y ~ 0 + x, data = datos.m)
    beta <- model1$coeff
    sigma <- sqrt(anova(model1)[["Mean Sq"]][2])
    faltantes.boot <- rnorm(n0, datos$x[Ind] * beta, sd = sigma)
    datos$y.per[Ind] <-  faltantes.boot
    model.input <- lm(y.per ~ 0 + x, data = datos)
    beta1[m] <- model.input$coeff
    sigma1[m] <- summary(model.input)$coeff[2]
  }
  beta.input <- mean(beta1)
  u.bar <- mean(sigma1 ^ 2)
  B <- var(beta1)
  beta.sd <- sqrt(u.bar + B + B/M)
  result <- list(new = datos, beta = beta.input, sd = beta.sd)
}
```

La función anterior realiza internamente lo siguiente:

-   En la primera sección del código, desde *library(dplyr)* hasta *sigma1 <- NULL* se calcula el número total de observaciones "n", se eliminan las filas con valores faltantes y se calculan las longitudes de los datos "datos1" sin valores faltantes, "n1", y los datos faltantes "n0". También se crea una variable de índice "Ind" que indica qué observaciones tienen valores faltantes, y se inicializan varias variables que se usarán más adelante en la función.

-   Luego, en la sección del bucle *for* se realiza el proceso de imputación múltiple. Se itera "M" veces, donde en cada iteración se muestran "n1" filas de los datos sin valores faltantes "datos1" con reemplazo, y se ajusta un modelo de regresión lineal con "y" como respuesta y "x" como variable explicativa. Luego se calculan los coeficientes de la regresión y la desviación estándar de los residuos. A continuación, se generan valores de imputación aleatorios para las filas faltantes, utilizando la media condicional y la desviación estándar estimadas en la muestra. Estos valores de imputación se asignan a las filas faltantes en el data frame "datos". Finalmente, se ajusta un modelo de regresión lineal con la variable de respuesta imputada "y.per" como respuesta y "x" como variable explicativa. Se guardan los coeficientes y las desviaciones estándar de los residuos para cada iteración en las variables "beta1" y "sigma1", respectivamente. 

-   En la última sección del código se calcula el coeficiente de regresión promedio para las iteraciones, "beta.input", y se calcula la desviación estándar de "beta1" y por último, la estimación de la desviación estándar del beta.

Al aplicar la función sobre el conjunto de datos creado, se obtienen las
siguientes salidas:

```{r, message=FALSE}
datos <- generar()
im.bootstrap(datos)$beta
im.bootstrap(datos)$sd
head(im.bootstrap(datos)$new)
```

Nótese que existe una buena dispersión en los valores imputados.

```{r, echo=T, message=FALSE, warning=FALSE}
nuevos <- im.bootstrap(datos)$new
ggplot(data = nuevos, aes(x = x, y = y.per, color = faltantes)) + geom_point() 
```

Por otro lado, se ejemplificará la técnica de imputación múltiple para los datos de la encuesta que se utiliza de ejemplo en este texto:

```{r}
encuesta$Income_imp <- encuesta$Income_missin
encuesta$Employment_imp <- encuesta$Employment_missin
encuesta_obs <- filter(encuesta, !is.na(Income_missin))
encuesta_no_obs <- filter(encuesta, is.na(Income_missin))
n0 <- nrow(encuesta_no_obs)
n1 <- nrow(encuesta_obs)
```

Inicialmente, se extraen los datos a imputar y se calculan los tamaños de los datos observados y no observados.

```{r}
M = 10 
set.seed(1234)
for (ii in 1:M) {
vp <- paste0("Income_vp_",ii)
vp2 <- paste0("Employment_vp_",ii)

encuesta_temp <- encuesta_obs %>% sample_n(size = n1, replace = TRUE)

mod <- lm(Income~ Zone + Sex + Expenditure, data = encuesta_temp)
mod.mult <- multinom(Employment~Zone + Sex +Expenditure,data = encuesta_temp)

encuesta_no_obs[[vp]] <- predict(mod, encuesta_no_obs)
encuesta_obs[[vp]] <- encuesta_obs$Income

encuesta_no_obs[[vp2]] <- predict(mod.mult, encuesta_no_obs,type = "class")
encuesta_obs[[vp2]] <- encuesta_obs$Employment
}
```

El código anterior realiza lo siguiente:

-   Se crea una cadena de caracteres "vp" y "vp2" mediante la función *paste0()* concatenando la cadena "Income_vp_" y "Employment_vp_" respectivamente con el número de la iteración actual "ii".

-   Se crea una muestra aleatoria con reemplazo de tamaño n1 a partir de la base de datos "encuesta_obs" utilizando la función *sample_n()* del paquete *dplyr*.

-   Se ajusta un modelo de regresión lineal con la variable "Income" como respuesta y las variables "Zone", "Sex" y "Expenditure" como covariables utilizando la función *lm()*.

-   Se ajusta un modelo de regresión multinomial con la variable "Employment" como respuesta y las variables "Zone", "Sex" y "Expenditure" como covariables utilizando la función *multinom()* del paquete *nnet*.

-   Se utiliza el modelo ajustado en el punto 3 para predecir los valores de la variable "Income" en la base de datos "encuesta_no_obs" mediante la función *predict()*.

-   Se guarda en la base de datos "encuesta_obs" los valores verdaderos de la variable "Income".

-   Se utiliza el modelo ajustado en el punto 4 para predecir los valores de la variable "Employment" en la base de datos "encuesta_no_obs" mediante la función *predict()*.

-   Se guarda en la base de datos "encuesta_obs" los valores verdaderos de la variable "Employment".

-   Se repite el proceso para las siguientes iteraciones.

-   Al finalizar el bucle se obtendrán 20 nuevas variables en las bases de datos "encuesta_no_obs" y "encuesta_obs" correspondientes a las predicciones de "Income" y "Employment" respectivamente, para cada una de las 10 iteraciones del bucle.

Una vez corrido el código anterior, se seleccionan las variables de ingresos y sus 10 valores plausibles como se muestra a continuación:

```{r}
dplyr::select(encuesta_no_obs, Income, matches("Income_vp_"))[1:10,1:4]
```

A continuación, se grafica la distribución de los ingresos y los 10 valores plausibles observándose que, las distribuciones son muy similares:

```{r, Bootstrap1, echo=TRUE, eval=TRUE}
encuesta <- bind_rows(encuesta_obs, encuesta_no_obs)

dat_plot10 <- tidyr::gather(
  encuesta %>% dplyr::select(Zone,Sex,matches("Income_vp_")),
  key = "Caso", value = "Income2", -Zone,-Sex)

p1 <- ggplot(dat_plot10, aes(x = Income2, col = Caso)) + 
  geom_density(alpha = 0.2) + theme_bw() +
   theme(legend.position = "bottom") + geom_density(data = encuesta ,aes(x = Income), col =  "black", size = 1.2) 

p1
```
En el siguiente gráfico se presentan las frecuencias de los valores plausibles para la variable empleado. Se observa también que son muy aproximadas a la variable completa:
```{r, Bootstrap2, echo=TRUE, eval=TRUE}

dat_plot11 <- tidyr::gather(
  encuesta %>% 
  dplyr::select(Zone,Sex, Employment,matches("Employment_vp_")),
  key = "Caso", value = "Employment2", -Zone,-Sex) %>%
  group_by(Caso,Employment2) %>% tally() %>% 
  group_by(Caso) %>% mutate(prop = n/sum(n))

p1 <- ggplot(dat_plot11, 
        aes(x = Employment2, y = prop,
            fill = Caso, color="red")) + 
       geom_bar(stat="identity",
          position = position_dodge(width = 0.5))  +
   theme_bw() +
   theme(legend.position = "bottom") +
  scale_fill_manual(values = c("Employment" = "black"))
p1
```
Con los valores plausibles enocntrados anteriormente, se procede a definir el diseño muestral utilizado en este ejemplo y así poder hacer la estimación de los parámetros. A continuación, se define el diseño muestral: 

```{r}
library(srvyr)

diseno <- encuesta %>%
  as_survey_design(
    strata = Stratum,
    ids = PSU,
    weights = wk,
    nest = T
  )

```

Con el diseño anterior, se estiman los ingresos medios para cada valor plausible junto ocn su varianza, como se muestra a continuación:

```{r}
estimacion_vp <-  diseno %>% 
 summarise(
   vp1 = survey_mean(Income_vp_1, vartype = c("var")),
   vp2 = survey_mean(Income_vp_2, vartype = c("var")),
   vp3 = survey_mean(Income_vp_3, vartype = c("var")),
   vp4 = survey_mean(Income_vp_4, vartype = c("var")),
   vp5 = survey_mean(Income_vp_5, vartype = c("var")),
   vp6 = survey_mean(Income_vp_6, vartype = c("var")),
   vp7 = survey_mean(Income_vp_7, vartype = c("var")),
   vp8 = survey_mean(Income_vp_8, vartype = c("var")),
   vp9 = survey_mean(Income_vp_9, vartype = c("var")),
   vp10 =survey_mean(Income_vp_10, vartype = c("var")))
estimacion_vp
```

A continuación se presentan los datos anteriores discriminado por promedio y varianza:

```{r, echo=TRUE}
require(tidyr)
(estimacion_vp %<>% tidyr::gather() %>%  separate(key, c("vp", "estimacion")) %>% 
mutate(estimacion = ifelse(is.na(estimacion), "promedio","var" )) %>% spread(estimacion,value) %>% mutate(vp = 1:10))
```

Por último, para obtener la estimación de la media y su varianza utilizando la imputación múltiple, se realizan los siguientes cálculos que se derivan de las expresiones matemáticas antes mostradas:

```{r, echo=TRUE}
Media_vp = mean(estimacion_vp$promedio)
(Ubar = mean(estimacion_vp$var))
(B = var(estimacion_vp$promedio))
var_vp = Ubar + (1 + 1/M) 
(resultado <- data.frame(Media_vp, 
                        Media_vp_se = sqrt(var_vp)))
```

```{r}
estimacion_var_vp <-  diseno %>% 
  summarise_at(vars(matches("Income_vp")), 
               survey_var,  vartype = "var" )
             
```

Por otro lado, otro parámetro de interés es la varianza de los ingresos. Este parámetro permite medir la variabilidad de los ingresos de los ciudadanos de la base de datos de ejemplo. La forma de estimarla es la misma que para el promedio de los ingresos y se utilizarán los mismo códigos mostrados anteriormente, cambiando el parámetro a estimar:

```{r, echo = TRUE}
(estimacion_var_vp %<>% tidyr::gather() %>%
   separate(key, c("A", "B","vp", "estimacion")) %>% 
mutate(estimacion = ifelse(is.na(estimacion), "promedio","var" ),
       A = NULL, B = NULL, vp = as.numeric(vp)) %>% 
  spread(estimacion,value))
```

Por último, se utilizan las ecuaciones mostradas anteriormente:

```{r, echo=TRUE}
Media_var_vp = mean(estimacion_var_vp$promedio)
Ubar = mean(estimacion_var_vp$var)
B = var(estimacion_var_vp$promedio)
var_var_vp = Ubar + (1 + 1/M)*B 
resultado$var_vp <- Media_var_vp
resultado$var_vp_se <- sqrt(var_var_vp)
cbind(Media_var_vp, var_var_vp)
```

Otro parámetro de interés a estimar es la proporción. A continuación, se realizará la estimación de la proporción utilizando valores plausibles. Para ello se estimará la variable empleado, como se muestra a continuación:

```{r}
estimacion_prop_vp <- lapply(paste0("Employment_vp_",1:10),
       function(vp){diseno %>% group_by_at(vars(Employment = vp)) %>% 
  summarise(prop = survey_mean(vartype = "var"),.groups = "drop") %>%
         mutate(vp = vp)}) %>% bind_rows()
```

Se presenta la estimación de la proporción para cada uno de los 10 valores plausibles en cada categoría de la variable:

```{r, echo = TRUE}
(estimacion_prop_vp %<>% separate(vp, c("A", "B","vp")) %>% 
mutate(A = NULL, B = NULL, vp = as.numeric(vp)) %>%
  dplyr::select(vp,Employment:prop_var)) %>% slice(1:12L)
```

Por último, utilizando las ecuaciones de Rubin se obtiene la varianza estimada:

```{r, echo=TRUE}
resultado = estimacion_prop_vp %>% 
  group_by(Employment) %>% 
  summarise(prop_pv = mean(prop),
            Ubar = mean(prop_var),
            B = var(prop)) %>% 
  mutate(prop_pv_var = Ubar + (1 + 1/M)*B) |> 
  dplyr::select(Employment, prop_pv, prop_pv_var)
resultado

```
